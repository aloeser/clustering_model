{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import math\n",
    "import operator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is configured for TPCH (chunk size 65535) with scale factor 1, 60 seconds runtime, and at most 10 runs per query\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "\n",
    "BENCHMARK = \"TPCH\"\n",
    "CHUNK_SIZE = 65535\n",
    "\n",
    "if BENCHMARK == \"TPCH\":\n",
    "    SCALE_FACTOR = 1\n",
    "    RUNS = 10\n",
    "    TIME = 60\n",
    "    STATISTICS_PATH = f\"~/Dokumente/repos/example_plugin/TPC-H__SF_{SCALE_FACTOR}.000000__RUNS_{RUNS}__TIME_{TIME}\"\n",
    "elif BENCHMARK == \"TPCDS\":\n",
    "    SCALE_FACTOR = 1\n",
    "    RUNS = 1\n",
    "    TIME = 60\n",
    "    STATISTICS_PATH = f\"~/Dokumente/repos/example_plugin/TPC-DS__SF_{SCALE_FACTOR}.000000__RUNS_{RUNS}__TIME_{TIME}\"\n",
    "else:\n",
    "    raise Exception(\"Unknown benchmark: \" + BENCHMARK)\n",
    "\n",
    "print(f\"Model is configured for {BENCHMARK} (chunk size {CHUNK_SIZE}) with scale factor {SCALE_FACTOR}, {TIME} seconds runtime, and at most {RUNS} runs per query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ~/Dokumente/repos/example_plugin/TPC-H__SF_1.000000__RUNS_10__TIME_60/table_scans.csv\n"
     ]
    }
   ],
   "source": [
    "# Load table scan statistics\n",
    "\n",
    "path = f\"{STATISTICS_PATH}/table_scans.csv\"\n",
    "scans = pd.read_csv(path, sep='|')\n",
    "EXPECTED_SCAN_COUNT = len(scans)\n",
    "LOADED_CHUNK_SIZE = CHUNK_SIZE\n",
    "LOADED_BENCHMARK = BENCHMARK\n",
    "LOADED_SCALE_FACTOR = SCALE_FACTOR\n",
    "LOADED_RUNS = RUNS\n",
    "LOADED_TIME = TIME\n",
    "\n",
    "print(f\"Successfully loaded {path}\")\n",
    "\n",
    "def assert_correct_statistics_loaded():\n",
    "    assert BENCHMARK == LOADED_BENCHMARK, f\"The model is configured to use {BENCHMARK}, but {LOADED_BENCHMARK} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert SCALE_FACTOR == LOADED_SCALE_FACTOR, f\"The model is configured to use {SCALE_FACTOR} as scale factor, but data for a scale factor of {LOADED_SCALE_FACTOR} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert RUNS == LOADED_RUNS, f\"The model is configured to perform at most {RUNS} runs, but the currently loaded data had at most {LOADED_RUNS} runs.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert TIME == LOADED_TIME, f\"The model is configured to run for {TIME} seconds, but the currently data had a runtime of {LOADED_TIME} seconds.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert CHUNK_SIZE == LOADED_CHUNK_SIZE, f\"The model is configured to use {CHUNK_SIZE} as chunk_size, but data for a chunk size of {LOADED_CHUNK_SIZE} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert EXPECTED_SCAN_COUNT == len(scans), f\"There should be {EXPECTED_SCAN_COUNT} table scans, but there are only {len(scans)}\\nProbably one of the last commands reassigned it unintentionally\"\n",
    "    \n",
    "    assert 'OPERATOR_POINTER' in scans.columns, f\"the statistics in {STATISTICS_PATH} are outdated (column 'OPERATOR_POINTER' in table_scans.csv is missing). Please create them again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - looks like pruning was deactivated while the statistics were created\n"
     ]
    }
   ],
   "source": [
    "# Validate table scans\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "# To make sure pruning was not active,\n",
    "# first fetch table sizes,\n",
    "table_statistics = pd.read_csv(f\"{STATISTICS_PATH}/table_meta_data.csv\", sep='|')\n",
    "table_sizes = dict(zip(table_statistics.table_name, table_statistics.row_count))\n",
    "\n",
    "# then make sure INPUT_ROWS == table_size\n",
    "def input_size_matches(row):\n",
    "    #print(row)\n",
    "    \n",
    "    actual_row_count = row['INPUT_ROWS']\n",
    "    table = row['TABLE_NAME']\n",
    "    expected_row_count = table_sizes[table]\n",
    "    return expected_row_count == actual_row_count\n",
    "\n",
    "data_scans = scans[scans['COLUMN_TYPE'] == 'DATA']\n",
    "input_size_matches = data_scans.apply(input_size_matches, axis=1)\n",
    "all_sizes_match = reduce(np.logical_and, input_size_matches) #input_size_matches.apply()\n",
    "\n",
    "if not all_sizes_match:\n",
    "    raise Exception(\"The given statistics were probably created while pruning was active\")\n",
    "else:\n",
    "    print(\"OK - looks like pruning was deactivated while the statistics were created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for TPCH contain 436 table scans\n",
      "Of those, only 228 are useful for pruning\n",
      "TODO: For now, filtering on scans is deactivated. This is because all scans are needed to recognize OR-Chains. Models have to take care themselves whether a scan can contribute to pruning or not\n"
     ]
    }
   ],
   "source": [
    "# Append additional information to the table scans\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "print(f\"Statistics for {BENCHMARK} contain {len(scans)} table scans\")\n",
    "\n",
    "\n",
    "# Add statistics about selectivity and speed for each operator\n",
    "scans['selectivity'] = scans['OUTPUT_ROWS'] / scans['INPUT_ROWS']\n",
    "\n",
    "# TODO: Assumption that reading and writing a row have the same cost\n",
    "scans['time_per_row'] = scans['RUNTIME_NS'] / (scans['INPUT_ROWS'] + scans['OUTPUT_ROWS'])\n",
    "scans['time_per_input_row'] = scans['time_per_row']\n",
    "scans['time_per_output_row'] = scans['time_per_row']\n",
    "\n",
    "\n",
    "def determine_or_chains(table_scans):\n",
    "    table_scans['part_of_or_chain'] = False\n",
    "    \n",
    "    single_table_scans = table_scans.groupby(['QUERY_HASH', 'TABLE_NAME', 'OPERATOR_POINTER'])\n",
    "    \n",
    "    for _, scans in single_table_scans:            \n",
    "        input_row_frequencies = Counter(scans.INPUT_ROWS)\n",
    "        or_input_sizes = set([input_size for input_size, frequency in input_row_frequencies.items() if frequency > 1])\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df['INPUT_ROWS'] = scans['INPUT_ROWS']\n",
    "        df['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "        df['part_of_or_chain'] = scans.apply(lambda row: row['INPUT_ROWS'] in or_input_sizes, axis=1)\n",
    "\n",
    "        for _ in range(len(scans)):\n",
    "            or_input_sizes |= set(df[df['part_of_or_chain']].OUTPUT_ROWS.unique())\n",
    "            df['part_of_or_chain'] = df.apply(lambda row: row['INPUT_ROWS'] in or_input_sizes, axis=1)\n",
    "\n",
    "        or_chains = list(df[df['part_of_or_chain']].index)\n",
    "        table_scans.iloc[or_chains, table_scans.columns.get_loc('part_of_or_chain')] = True\n",
    "    \n",
    "    return table_scans\n",
    "\n",
    "# Hyrise does not use scans that are part of an OR-chain for pruning\n",
    "scans = determine_or_chains(scans)\n",
    "\n",
    "\n",
    "# Like scans are not useful if they start with %\n",
    "# TODO what if they dont start with % and contain more than one % ? -> up to first % prunable, but is it used?\n",
    "def benefits_from_sorting(row):    \n",
    "    description = row['DESCRIPTION']\n",
    "    if \"ColumnLike\" in description:\n",
    "        words = description.split()\n",
    "        like_criteria = words[-1]\n",
    "        assert \"%\" in like_criteria, f\"LIKE operators should have an %, but found none in {like_criteria}\"\n",
    "        return like_criteria[1] != '%'\n",
    "    elif \"ExpressionEvaluator\" in description and \" IN \" in description:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "scans['benefits_from_sorting'] = scans.apply(benefits_from_sorting, axis=1)\n",
    "# TODO: valid atm, but feels a bit hacky to assume not benefitting from sorted segments -> not benefitting from pruning\n",
    "scans['useful_for_pruning'] = scans.apply(lambda row: not row['part_of_or_chain'] and row['benefits_from_sorting'] , axis=1)\n",
    "EXPECTED_SCAN_COUNT = len(scans)\n",
    "print(f\"Of those, only {len(scans[scans['useful_for_pruning']])} are useful for pruning\")\n",
    "\n",
    "print(\"TODO: For now, filtering on scans is deactivated. This is because all scans are needed to recognize OR-Chains. Models have to take care themselves whether a scan can contribute to pruning or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test OK\n"
     ]
    }
   ],
   "source": [
    "def test_determine_or_chains():\n",
    "    test = pd.DataFrame()\n",
    "    test['QUERY_HASH'] = pd.Series(['1']*3  + ['2']*4)\n",
    "    test['TABLE_NAME'] = pd.Series(['lineitem']*3  + ['part']*4)\n",
    "    test['OPERATOR_POINTER'] = pd.Series(['0x1'] + ['0x2']*2 + ['0x3']*4)\n",
    "    test['COLUMN_NAME'] = pd.Series(['l_shipdate', 'l_shipdate', 'l_discount', 'p_brand', 'p_type', 'p_type', 'p_size'])\n",
    "    test['INPUT_ROWS'] = pd.Series( [6001215, 6001215, 200000, 200000, 199000, 199000, 50000])\n",
    "    test['OUTPUT_ROWS'] = pd.Series([ 400000,  300000, 200000, 199000,      0,  50000, 20000])\n",
    "    test_result = determine_or_chains(test)\n",
    "    assert len(test_result) == 7, \"should not filter out any rows\"    \n",
    "    assert len(test_result[test_result['part_of_or_chain']]) == 3, \"expected 3 scans, got\\n\" + str(test_result)\n",
    "    assert list(test_result['part_of_or_chain']) == [False]*4 + [True]*3\n",
    "    print(\"Test OK\")\n",
    "\n",
    "test_determine_or_chains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16297317"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scans['RUNTIME_NS'] - scans['SINGLE_RUNTIME_NS']).max()\n",
    "# TODO can the actual runtime be that much greater than the runtime on the original table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load query frequency information\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def get_query_frequencies():\n",
    "    plan_cache = pd.read_csv(f\"{STATISTICS_PATH}/plan_cache.csv\", sep='|')\n",
    "    return dict(zip(plan_cache.QUERY_HASH, plan_cache.EXECUTION_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load column statistics - especially interesting: number of distinct values, and columns sorted during statistics creation\n",
    "\n",
    "# Returns a 2-level-dictionary: distinct_values[TABLE][COLUMN] = number_of_distinct_values\n",
    "def get_distinct_values_count():        \n",
    "    # Code\n",
    "    column_statistics_df = pd.read_csv(f\"{STATISTICS_PATH}/column_meta_data.csv\", sep='|')\n",
    "    column_statistics_df['distinct_values'] = np.int32(column_statistics_df['distinct_values'])\n",
    "    tables_and_columns = column_statistics_df.groupby('table_name')\n",
    "    distinct_values = {table: dict(zip(column_df.column_name, column_df.distinct_values)) for table, column_df in tables_and_columns }\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    num_tables = len(distinct_values)\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        assert num_tables == 8, f\"TPCH has 8 tables, but got {num_tables}\"\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        assert num_tables == 24, f\"TPCDS has 24 tables, but got {num_tables}\"\n",
    "    else:\n",
    "        assert False, \"Insert a benchmark specific check here\"\n",
    "    \n",
    "    return distinct_values\n",
    "\n",
    "# Returns a dictionary: sorted_columns_during_creation[TABLE] = [column1, column2, ...]\n",
    "def get_sorted_columns_during_creation():\n",
    "    # Code\n",
    "    column_statistics_df = pd.read_csv(f\"{STATISTICS_PATH}/column_meta_data.csv\", sep='|')\n",
    "    globally_sorted_columns = column_statistics_df[column_statistics_df['is_globally_sorted'] == 1]\n",
    "    \n",
    "    tables_and_columns = globally_sorted_columns.groupby('table_name')\n",
    "    globally_sorted_columns = {table: list(column_df.column_name) for table, column_df in tables_and_columns }\n",
    "    \n",
    "    return globally_sorted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOINS ###\n",
    "\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def load_join_statistics():\n",
    "    def line_looks_suspicious(row):\n",
    "        right_table_name = row['RIGHT_TABLE_NAME']    \n",
    "        if pd.isnull(right_table_name):\n",
    "            pass\n",
    "        elif row['RIGHT_TABLE_ROW_COUNT'] > table_sizes[row['RIGHT_TABLE_NAME']]:\n",
    "            return True\n",
    "\n",
    "        left_table_name = row['LEFT_TABLE_NAME']\n",
    "        if pd.isnull(left_table_name):\n",
    "            pass\n",
    "        elif row['LEFT_TABLE_ROW_COUNT'] > table_sizes[row['LEFT_TABLE_NAME']]:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def validate_joins(joins):\n",
    "        is_suspicious = joins.apply(line_looks_suspicious, axis=1)\n",
    "        suspicious_joins = joins[is_suspicious]\n",
    "        assert len(suspicious_joins) < 3, f\"there are {len(suspicious_joins)} suspicious joins:\\n{suspicious_joins[['JOIN_MODE', 'LEFT_TABLE_NAME', 'LEFT_COLUMN_NAME', 'LEFT_TABLE_ROW_COUNT', 'RIGHT_TABLE_NAME', 'RIGHT_COLUMN_NAME', 'RIGHT_TABLE_ROW_COUNT', 'PROBE_TABLE', 'PROBE_COLUMN', 'OUTPUT_ROWS']]}\"\n",
    "    \n",
    "    joins = pd.read_csv(f\"{STATISTICS_PATH}/joins.csv\", sep=',')\n",
    "    validate_joins(joins)\n",
    "                                                                                           \n",
    "    return joins\n",
    "\n",
    "#load_join_statistics().iloc[9:10][['JOIN_MODE', 'LEFT_TABLE_NAME', 'LEFT_COLUMN_NAME', 'LEFT_TABLE_ROW_COUNT', 'RIGHT_TABLE_NAME', 'RIGHT_COLUMN_NAME', 'RIGHT_TABLE_ROW_COUNT', 'PROBE_TABLE', 'PROBE_COLUMN', 'OUTPUT_ROWS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractModel:\n",
    "    \n",
    "    def __init__(self, query_frequencies, table_name, table_scans, correlations={}):\n",
    "        self.query_frequencies = query_frequencies\n",
    "        self.table_name = table_name\n",
    "        self.table_scans = table_scans\n",
    "        self.correlations = correlations\n",
    "        \n",
    "    def query_frequency(self, query_hash):\n",
    "        return self.query_frequencies[query_hash]\n",
    "        \n",
    "    def extract_scan_columns(self):\n",
    "        useful_scans = self.table_scans[self.table_scans['useful_for_pruning']]\n",
    "        interesting_scan_columns = list(useful_scans['COLUMN_NAME'].unique())\n",
    "        \n",
    "        return interesting_scan_columns\n",
    "    \n",
    "    def extract_join_columns(self):\n",
    "        interesting_join_probe_columns = list(self.joins[self.joins['PROBE_TABLE'] == self.table_name]['PROBE_COLUMN'].unique())\n",
    "        interesting_join_build_columns = list(self.joins[self.joins['BUILD_TABLE'] == self.table_name]['BUILD_COLUMN'].unique())        \n",
    "        \n",
    "        return self.uniquify(interesting_join_probe_columns + interesting_join_build_columns)\n",
    "    \n",
    "    def extract_interesting_columns(self):        \n",
    "        return self.uniquify(self.extract_scan_columns() + self.extract_join_columns())\n",
    "    \n",
    "    def round_up_to_next_multiple(self, number_to_round, base_for_multiple):\n",
    "        quotient = number_to_round // base_for_multiple\n",
    "        if number_to_round % base_for_multiple != 0:\n",
    "            quotient += 1\n",
    "        return quotient * base_for_multiple        \n",
    "\n",
    "    def uniquify(self, seq):\n",
    "            seen = set()\n",
    "            return [x for x in seq if not (x in seen or seen.add(x))]    \n",
    "    \n",
    "    # return a list of possible clusterings\n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartitionerModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, query_frequencies, table_name, table_scans, table_size, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation):\n",
    "        super().__init__(query_frequencies, table_name, table_scans, correlations)\n",
    "        self.table_size = table_size\n",
    "        self.distinct_values = distinct_values\n",
    "        self.target_chunksize = target_chunksize\n",
    "        self.joins = joins\n",
    "        self.sorted_columns_during_creation = sorted_columns_during_creation\n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        print(interesting_columns)\n",
    "        \n",
    "        clustering_columns = itertools.product(interesting_columns, interesting_columns)\n",
    "        #clustering_columns = itertools.product(interesting_columns, interesting_columns, interesting_columns)\n",
    "        clustering_columns = filter(lambda x: x[0] <= x[1], clustering_columns)\n",
    "        #clustering_columns = filter(lambda x: x[1] <= x[2], clustering_columns)\n",
    "        clustering_columns = [self.uniquify(clustering) for clustering in clustering_columns]\n",
    "        sort_columns = interesting_columns        \n",
    "        clusterings_with_runtimes = reduce(lambda x,y: x+y,[self.estimate_total_runtime(clustering_cols, sort_columns) for clustering_cols in clustering_columns])\n",
    "        clusterings_with_runtimes.sort(key=lambda x: x[2], reverse=False)\n",
    "        \n",
    "        return clusterings_with_runtimes[0:first_k]\n",
    "        \n",
    "    def estimate_table_scan_runtimes(self, clustering_columns, sorting_columns, split_factors, total_runtimes):        \n",
    "        def compute_unprunable_parts(row, split_factors):\n",
    "            def clustering_columns_correlated_to(column):\n",
    "                return [clustering_column for clustering_column in clustering_columns if column in self.correlations.get(clustering_column, {})]\n",
    "            \n",
    "            def correlates_to_clustering_column(column):\n",
    "                return len(clustering_columns_correlated_to(column)) > 0\n",
    "\n",
    "            column_name = row['COLUMN_NAME']\n",
    "\n",
    "            if not row['useful_for_pruning']:\n",
    "                selectivity = 1\n",
    "            elif column_name in clustering_columns:\n",
    "                scan_selectivity = row['selectivity']\n",
    "                split_factor = split_factors[clustering_columns.index(column_name)]\n",
    "                selectivity =  self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor)\n",
    "            elif correlates_to_clustering_column(column_name):\n",
    "                scan_selectivity = row['selectivity']\n",
    "                correlated_clustering_columns = clustering_columns_correlated_to(column_name)\n",
    "                \n",
    "                # ToDo this is hacky, but for now assume there is just one correlated column\n",
    "                assert len(correlated_clustering_columns) == 1, f\"expected just 1 correlated clustering column, but got {len(correlated_clustering_columns)}\"\n",
    "                \n",
    "                split_factor = split_factors[clustering_columns.index(correlated_clustering_columns[0])]\n",
    "                selectivity = min(1, 1.2 * self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor))\n",
    "            else:\n",
    "                selectivity = 1\n",
    "            \n",
    "            return selectivity\n",
    "        \n",
    "        def compute_runtimes(row, sorting_column):\n",
    "            assert row['estimated_input_rows'] > 1, row\n",
    "            assert row['runtime_per_input_row'] > 0, row\n",
    "            assert row['runtime_per_output_row'] > 0, row\n",
    "            input_row_count = row['estimated_input_rows']\n",
    "            \n",
    "            if row['COLUMN_NAME'] == sorting_column and row['benefits_from_sorting']:\n",
    "                # TODO is this the best way to simulate sorted access?\n",
    "                input_row_count = np.log2(input_row_count)\n",
    "\n",
    "            runtime = input_row_count * row['runtime_per_input_row'] + row['OUTPUT_ROWS'] * row['runtime_per_output_row']\n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        scans_per_query = self.table_scans.sort_values(['INPUT_ROWS'], ascending=False).groupby(['QUERY_HASH', 'OPERATOR_POINTER'])\n",
    "        for _, scans in scans_per_query:\n",
    "            number_of_scans = len(scans)\n",
    "            assert number_of_scans > 0 and number_of_scans < 25, f\"weird scan length: {number_of_scans}\\nScans:\\n{scans}\"\n",
    "            # TODO: kinda unrealistic assumption: everything not in the table scan result can be pruned\n",
    "                          \n",
    "            unprunable_parts = scans.apply(compute_unprunable_parts, axis=1, args=(split_factors,))            \n",
    "            unprunable_part = unprunable_parts.product()\n",
    "            assert unprunable_part > 0, \"no unprunable part\"\n",
    "            \n",
    "            estimated_pruned_table_size = self.round_up_to_next_multiple(unprunable_part * self.table_size, CHUNK_SIZE)\n",
    "            \n",
    "            runtimes = pd.DataFrame()\n",
    "            runtimes['QUERY_HASH'] = scans['QUERY_HASH']\n",
    "            runtimes['runtime_per_input_row'] = scans['time_per_input_row']\n",
    "            runtimes['runtime_per_output_row'] = scans['time_per_output_row']\n",
    "            runtimes['COLUMN_NAME'] = scans['COLUMN_NAME']\n",
    "            runtimes['benefits_from_sorting'] = scans['benefits_from_sorting']\n",
    "            # the pruned table inputs should be reflected in 'estimated_input_rows'\n",
    "            runtimes['estimated_input_rows'] = scans.apply(lambda x: x['INPUT_ROWS'], axis=1)\n",
    "            runtimes['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "\n",
    "            runtimes.iloc[0, runtimes.columns.get_loc('estimated_input_rows')] = estimated_pruned_table_size                                    \n",
    "            assert runtimes['estimated_input_rows'].iloc[0] == estimated_pruned_table_size, f\"value is {runtimes.iloc[0]['estimated_input_rows']}, but should be {estimated_pruned_table_size}\"\n",
    "            # TODO modify input sizes of subsequent scans\n",
    "            \n",
    "            for sorting_column in sorting_columns:\n",
    "                scan_runtimes = runtimes.apply(compute_runtimes, axis=1, args=(sorting_column,))\n",
    "                total_runtimes[sorting_column] += scan_runtimes.sum()\n",
    "\n",
    "    def estimate_join_runtimes(self, clustering_columns, sorting_columns, total_runtimes):                \n",
    "        def estimate_join_runtime(row, sorting_column):\n",
    "                        \n",
    "            if \"JoinHash\" in row['DESCRIPTION']:\n",
    "                probe_column = row['PROBE_COLUMN']\n",
    "                if row['PROBE_TABLE'] == self.table_name:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    probe_column_is_sorted = row['PROBE_SORTED'] and probe_column == sorting_column\n",
    "                    probe_column_is_clustered = row['PROBE_SORTED'] and probe_column in clustering_columns\n",
    "                else:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(row['PROBE_TABLE'], {})\n",
    "                    probe_column_is_sorted = probe_column_was_sorted\n",
    "                    probe_column_is_clustered = probe_column_was_sorted\n",
    "                    \n",
    "                build_column = row['BUILD_COLUMN']\n",
    "                if row['BUILD_TABLE'] == self.table_name:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    build_column_is_sorted = row['BUILD_SORTED'] and build_column == sorting_column\n",
    "                    build_column_is_clustered = row['BUILD_SORTED'] and build_column in clustering_columns\n",
    "                else:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(row['BUILD_TABLE'], {})\n",
    "                    build_column_is_sorted = build_column_was_sorted\n",
    "                    build_column_is_clustered = build_column_was_sorted\n",
    "\n",
    "                time_materialize = row['MATERIALIZE']\n",
    "                \n",
    "                probe_weight = 2\n",
    "                build_weight = 2\n",
    "                if probe_column_was_sorted:\n",
    "                    probe_weight = 1\n",
    "                if build_column_was_sorted:\n",
    "                    build_weight = 1\n",
    "                \n",
    "                \n",
    "                probe_table_size = row['PROBE_TABLE_SIZE']\n",
    "                build_table_size = row['BUILD_TABLE_SIZE']\n",
    "                total_table_size = probe_weight * probe_table_size + build_weight * build_table_size\n",
    "                \n",
    "                time_materialize_probe = time_materialize * (probe_weight * probe_table_size / total_table_size)\n",
    "                time_materialize_build = time_materialize - time_materialize_probe\n",
    "                \n",
    "                \n",
    "                def get_materialize_factor(was_sorted, is_sorted, is_clustered):\n",
    "                    materialize_factor = 1\n",
    "                    if is_sorted and is_clustered:\n",
    "                        if not was_sorted:\n",
    "                            materialize_factor = 0.5\n",
    "                        else:\n",
    "                            materialize_factor = 1\n",
    "                    elif is_sorted or is_clustered:\n",
    "                        if not was_sorted:\n",
    "                            materialize_factor = 0.55\n",
    "                        else:\n",
    "                            materialize_factor = 1.1\n",
    "                    elif was_sorted:\n",
    "                        # probe column is now neither sorted nor clustered\n",
    "                        materialize_factor = 2\n",
    "                    else:\n",
    "                        # default case: was not sorted before, and is neither sorted nor clustered now. No change\n",
    "                        materialize_factor = 1\n",
    "                        \n",
    "                    return materialize_factor\n",
    "                \n",
    "                materialize_probe_factor = get_materialize_factor(probe_column_was_sorted, probe_column_is_sorted, probe_column_is_clustered)\n",
    "                materialize_build_factor = get_materialize_factor(build_column_was_sorted, build_column_is_sorted, build_column_is_clustered)\n",
    "                \n",
    "                time_materialize = time_materialize_probe * materialize_probe_factor + time_materialize_build *  materialize_build_factor\n",
    "                \n",
    "\n",
    "                # unchanged\n",
    "                time_cluster = row['CLUSTER']\n",
    "                \n",
    "                # unchanged\n",
    "                time_build = row['BUILD']\n",
    "                \n",
    "                            \n",
    "                time_probe = row['PROBE']\n",
    "                probe_factor = 1\n",
    "                if probe_column_is_sorted and probe_column_is_clustered:\n",
    "                    if not probe_column_was_sorted:\n",
    "                        probe_factor = 0.7\n",
    "                    else:\n",
    "                        probe_factor = 1\n",
    "                elif probe_column_is_sorted or probe_column_is_clustered:\n",
    "                    if not probe_column_was_sorted:\n",
    "                        probe_factor = 0.9\n",
    "                    else:\n",
    "                        probe_factor = 1.1\n",
    "                elif probe_column_was_sorted:\n",
    "                    # probe column is now neither sorted nor clustered\n",
    "                    probe_factor = 1.4\n",
    "                \n",
    "                time_probe *= probe_factor                \n",
    "                \n",
    "                # unchanged\n",
    "                time_write_output = row['WRITE_OUTPUT']\n",
    "                \n",
    "                \n",
    "                \n",
    "                # TODO: how to deal with the difference between RUNTIME_NS and sum(stage_runtimes)?\n",
    "                runtime = time_materialize + time_cluster + time_build + time_probe + time_write_output\n",
    "            else:\n",
    "                runtime = row['RUNTIME_NS']\n",
    "                \n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        for sorting_column in sorting_columns:\n",
    "            join_runtimes = self.joins.apply(estimate_join_runtime, axis=1, args=(sorting_column,))\n",
    "            total_runtimes[sorting_column] += join_runtimes.sum()\n",
    "                \n",
    "    def estimate_total_runtime(self, clustering_columns, sorting_columns):\n",
    "        #print(f\"testing clustering {clustering_columns} with sorting columns {sorting_columns}\")\n",
    "        split_factors = self.determine_split_factors(clustering_columns)            \n",
    "        total_runtimes = {sorting_column: 0 for sorting_column in sorting_columns}\n",
    "        self.estimate_table_scan_runtimes(clustering_columns, sorting_columns, split_factors, total_runtimes)\n",
    "        self.estimate_join_runtimes(clustering_columns, sorting_columns, total_runtimes)\n",
    "        \n",
    "        clusterings = [[list(zip(clustering_columns, split_factors)), sorting_column, np.int64(total_runtimes[sorting_column])] for sorting_column in sorting_columns]\n",
    "        return clusterings\n",
    "    \n",
    "    def determine_split_factors(self, clustering_columns):\n",
    "        approximate_split_factor = self.table_size / self.target_chunksize\n",
    "        individual_distinct_values = [self.distinct_values[column] for column in clustering_columns]        \n",
    "        log_distinct_values = [math.ceil(0.5+np.log2(x)) for x in individual_distinct_values]\n",
    "        log_distinct_values_product = reduce(operator.mul, log_distinct_values, 1)\n",
    "        assert log_distinct_values_product > 0, \"cannot have a distinct value count of 0\"\n",
    "        \n",
    "        global_modification_factor = approximate_split_factor / log_distinct_values_product\n",
    "        num_dimensions = len(clustering_columns)\n",
    "        individual_modification_factor = np.power(global_modification_factor, 1.0 / num_dimensions)    \n",
    "        split_factors = [math.ceil(x * individual_modification_factor) for x in log_distinct_values]\n",
    "        \n",
    "        # testing\n",
    "        actual_split_factor = reduce(operator.mul, split_factors, 1)\n",
    "        assert actual_split_factor > 0, \"there was a split up factor of 0\"\n",
    "        estimated_chunksize = self.table_size / actual_split_factor\n",
    "        assert estimated_chunksize <= self.target_chunksize, \"chunks should be smaller, not larger than target_chunksize\"\n",
    "        allowed_percentage = 0.55\n",
    "        if estimated_chunksize < allowed_percentage * self.target_chunksize:\n",
    "            print(f\"Warning: chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\")\n",
    "        #assert estimated_chunksize >= allowed_percentage * self.target_chunksize, f\"chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\"\n",
    "        \n",
    "        return split_factors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not computing clustering for customer, as it has only 150000 rows\n",
      "['o_orderstatus', 'o_orderdate', 'o_orderkey', 'o_custkey']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e4632db3d8e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclusterings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mcreate_benchmark_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# TODO:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-e4632db3d8e6>\u001b[0m in \u001b[0;36mcreate_benchmark_configs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPartitionerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_table_scans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistinct_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobe_side_joins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_columns_during_creation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mtable_clusterings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtable_clustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable_clusterings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_benchmark_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-482a958e2fd8>\u001b[0m in \u001b[0;36msuggest_clustering\u001b[0;34m(self, first_k)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mclustering_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniquify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msort_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteresting_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mclusterings_with_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_total_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering_cols\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mclusterings_with_runtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-482a958e2fd8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mclustering_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniquify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msort_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteresting_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mclusterings_with_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_total_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering_cols\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mclusterings_with_runtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-482a958e2fd8>\u001b[0m in \u001b[0;36mestimate_total_runtime\u001b[0;34m(self, clustering_columns, sorting_columns)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mtotal_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msorting_column\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msorting_column\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_table_scan_runtimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_factors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_runtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_join_runtimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_runtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mclusterings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_runtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorting_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msorting_column\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-482a958e2fd8>\u001b[0m in \u001b[0;36mestimate_join_runtimes\u001b[0;34m(self, clustering_columns, sorting_columns, total_runtimes)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msorting_column\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mjoin_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate_join_runtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorting_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mtotal_runtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorting_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mjoin_runtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6485\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6486\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                                           \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                                           labels=labels)\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-482a958e2fd8>\u001b[0m in \u001b[0;36mestimate_join_runtime\u001b[0;34m(row, sorting_column)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0mtime_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROBE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0mprobe_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprobe_column_is_sorted\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mprobe_column_is_clustered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4370\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'getitem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   2854\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2856\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2858\u001b[0m             \u001b[0;31m# we can raise here if we are definitive that this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "def extract_probe_side_joins(joins, table_name):\n",
    "    return joins[joins['PROBE_TABLE'] == table_name]\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 92 * SCALE_FACTOR]],\n",
    "            'orders': [['o_orderdate', 23 * SCALE_FACTOR]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_benchmark_configs():\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    clusterings = {\"default\" : default_benchmark_config()}\n",
    "    query_frequencies = get_query_frequencies()\n",
    "    \n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    for table_name in table_names:\n",
    "        start_time_table = datetime.now()\n",
    "        single_table_scans = extract_single_table(scans, table_name)\n",
    "        probe_side_joins = joins#extract_probe_side_joins(joins, table_name)\n",
    "        table_size = table_sizes[table_name]\n",
    "        if table_size <= 3 * CHUNK_SIZE:\n",
    "            print(f\"Not computing clustering for {table_name}, as it has only {table_size} rows\")\n",
    "            continue\n",
    "\n",
    "        model = PartitionerModel(query_frequencies, table_name, single_table_scans, table_size, distinct_values[table_name], CHUNK_SIZE, correlations.get(table_name, {}), probe_side_joins, sorted_columns_during_creation)\n",
    "        table_clusterings = model.suggest_clustering(3)\n",
    "        for table_clustering in table_clusterings:\n",
    "            config = default_benchmark_config()\n",
    "            config[table_name] = format_table_clustering(table_clustering)\n",
    "            config_name = get_config_name(config)\n",
    "            clusterings[config_name] = config\n",
    "        end_time_table = datetime.now()\n",
    "        print(f\"Done computing clustering for {table_name} ({end_time_table - start_time_table})\")\n",
    "\n",
    "            \n",
    "    end_time = datetime.now()\n",
    "    print(f\"Computed all clusterings in {end_time - start_time}\")\n",
    "    \n",
    "    return clusterings\n",
    "\n",
    "create_benchmark_configs()\n",
    "\n",
    "# TODO:\n",
    "#  joins costs are multiplied with 0\n",
    "#  still, the model suggests some join columns - why? are they useful for pruning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTableMdcModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, max_dimensions, query_frequencies, table_name, table_scans, table_sizes, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation):\n",
    "        super().__init__(query_frequencies, table_name, table_scans, correlations)\n",
    "        self.max_dimensions = max_dimensions\n",
    "        self.table_sizes = table_sizes       \n",
    "        self.table_size = table_sizes[table_name]\n",
    "        self.distinct_values = distinct_values\n",
    "        self.target_chunksize = target_chunksize\n",
    "        self.joins = joins\n",
    "        self.sorted_columns_during_creation = sorted_columns_during_creation\n",
    "        \n",
    "        self.join_column_names = self.extract_join_columns()\n",
    "        self.scan_column_names = self.extract_scan_columns()\n",
    "        \n",
    "    def is_join_column(self, column_name):\n",
    "        return column_name in self.join_column_names\n",
    "    \n",
    "    def is_scan_column(self, column_name):\n",
    "        return column_name in self.scan_column_names\n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        print(interesting_columns)\n",
    "        clustering_columns = itertools.combinations_with_replacement(interesting_columns, self.max_dimensions)\n",
    "        clustering_columns = [self.uniquify(clustering) for clustering in clustering_columns]\n",
    "        sort_columns = interesting_columns        \n",
    "        clusterings_with_runtimes = reduce(lambda x,y: x+y,[self.estimate_total_runtime(clustering_cols, sort_columns) for clustering_cols in clustering_columns])\n",
    "        clusterings_with_runtimes.sort(key=lambda x: x[2], reverse=False)\n",
    "        \n",
    "        return clusterings_with_runtimes[0:first_k]\n",
    "    \n",
    "    \n",
    "    def estimate_distinct_values_per_chunk(self, column, clustering_columns, sorting_column, dimension_cardinalities):\n",
    "        raise NotImplementedError(\"Each model should provide this function\")\n",
    "        \n",
    "    def estimate_distinct_values_per_chunk_at_statistics_time(self, column, table):        \n",
    "        if column in self.sorted_columns_during_creation.get(table, {}):\n",
    "            # Column was globally sorted\n",
    "            average_count_per_distinct_value = self.table_sizes[table] / self.distinct_values[table][column]\n",
    "            return math.ceil(self.target_chunksize / average_count_per_distinct_value)\n",
    "        else:\n",
    "            # Column was not globally sorted\n",
    "            total_distinct_values = self.distinct_values[table][column]\n",
    "            return min(total_distinct_values, self.target_chunksize)        \n",
    "    \n",
    "    def estimate_table_scan_runtimes(self, clustering_columns, sorting_columns, split_factors, total_runtimes):        \n",
    "        def compute_unprunable_parts(row, split_factors):\n",
    "            def clustering_columns_correlated_to(column):\n",
    "                return [clustering_column for clustering_column in clustering_columns if column in self.correlations.get(clustering_column, {})]\n",
    "            \n",
    "            def correlates_to_clustering_column(column):\n",
    "                return len(clustering_columns_correlated_to(column)) > 0\n",
    "\n",
    "            column_name = row['COLUMN_NAME']\n",
    "\n",
    "            if not row['useful_for_pruning']:\n",
    "                selectivity = 1\n",
    "            elif column_name in clustering_columns:\n",
    "                scan_selectivity = row['selectivity']\n",
    "                split_factor = split_factors[clustering_columns.index(column_name)]\n",
    "                selectivity =  self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor)\n",
    "            elif correlates_to_clustering_column(column_name):\n",
    "                scan_selectivity = row['selectivity']\n",
    "                correlated_clustering_columns = clustering_columns_correlated_to(column_name)\n",
    "                \n",
    "                # ToDo this is hacky, but for now assume there is just one correlated column\n",
    "                assert len(correlated_clustering_columns) == 1, f\"expected just 1 correlated clustering column, but got {len(correlated_clustering_columns)}\"\n",
    "                \n",
    "                split_factor = split_factors[clustering_columns.index(correlated_clustering_columns[0])]\n",
    "                selectivity = min(1, 1.2 * self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor))\n",
    "            else:\n",
    "                selectivity = 1\n",
    "            \n",
    "            return selectivity\n",
    "        \n",
    "        def compute_runtimes(row, sorting_column):\n",
    "            assert row['estimated_input_rows'] > 1, row\n",
    "            assert row['runtime_per_input_row'] > 0, row\n",
    "            assert row['runtime_per_output_row'] > 0, row\n",
    "            input_row_count = row['estimated_input_rows']\n",
    "            \n",
    "            if row['COLUMN_NAME'] == sorting_column and row['benefits_from_sorting']:\n",
    "                # TODO is this the best way to simulate sorted access?\n",
    "                input_row_count = np.log2(input_row_count)\n",
    "\n",
    "            runtime = input_row_count * row['runtime_per_input_row'] + row['OUTPUT_ROWS'] * row['runtime_per_output_row']\n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        scans_per_query = self.table_scans.sort_values(['INPUT_ROWS'], ascending=False).groupby(['QUERY_HASH', 'OPERATOR_POINTER'])\n",
    "        for _, scans in scans_per_query:\n",
    "            number_of_scans = len(scans)\n",
    "            assert number_of_scans > 0 and number_of_scans < 25, f\"weird scan length: {number_of_scans}\\nScans:\\n{scans}\"\n",
    "            # TODO: kinda unrealistic assumption: everything not in the table scan result can be pruned\n",
    "                          \n",
    "            unprunable_parts = scans.apply(compute_unprunable_parts, axis=1, args=(split_factors,))            \n",
    "            unprunable_part = unprunable_parts.product()\n",
    "            assert unprunable_part > 0, \"no unprunable part\"\n",
    "            \n",
    "            estimated_pruned_table_size = self.round_up_to_next_multiple(unprunable_part * self.table_size, CHUNK_SIZE)\n",
    "            \n",
    "            runtimes = pd.DataFrame()\n",
    "            runtimes['QUERY_HASH'] = scans['QUERY_HASH']\n",
    "            runtimes['runtime_per_input_row'] = scans['time_per_input_row']\n",
    "            runtimes['runtime_per_output_row'] = scans['time_per_output_row']\n",
    "            runtimes['COLUMN_NAME'] = scans['COLUMN_NAME']\n",
    "            runtimes['benefits_from_sorting'] = scans['benefits_from_sorting']\n",
    "            # the pruned table inputs should be reflected in 'estimated_input_rows'\n",
    "            runtimes['estimated_input_rows'] = scans['INPUT_ROWS']\n",
    "            runtimes['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "\n",
    "            runtimes.iloc[0, runtimes.columns.get_loc('estimated_input_rows')] = estimated_pruned_table_size                                    \n",
    "            assert runtimes['estimated_input_rows'].iloc[0] == estimated_pruned_table_size, f\"value is {runtimes.iloc[0]['estimated_input_rows']}, but should be {estimated_pruned_table_size}\"\n",
    "            # TODO modify input sizes of subsequent scans\n",
    "            \n",
    "            for sorting_column in sorting_columns:\n",
    "                scan_runtimes = runtimes.apply(compute_runtimes, axis=1, args=(sorting_column,))\n",
    "                total_runtimes[sorting_column] += scan_runtimes.sum()\n",
    "\n",
    "    def estimate_join_runtimes(self, clustering_columns, sorting_columns, dimension_cardinalities, total_runtimes):\n",
    "        def estimate_join_runtime(row, sorting_column):\n",
    "                        \n",
    "            if \"JoinHash\" in row['DESCRIPTION']:\n",
    "                probe_column = row['PROBE_COLUMN']\n",
    "                if row['PROBE_TABLE'] == self.table_name:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    probe_column_is_sorted = row['PROBE_SORTED'] and probe_column == sorting_column\n",
    "                else:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(row['PROBE_TABLE'], {})\n",
    "                    probe_column_is_sorted = probe_column_was_sorted\n",
    "                    \n",
    "                build_column = row['BUILD_COLUMN']\n",
    "                if row['BUILD_TABLE'] == self.table_name:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    build_column_is_sorted = row['BUILD_SORTED'] and build_column == sorting_column\n",
    "                else:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(row['BUILD_TABLE'], {})\n",
    "                    build_column_is_sorted = build_column_was_sorted\n",
    "\n",
    "                time_materialize = row['MATERIALIZE']\n",
    "\n",
    "                probe_weight = 2\n",
    "                build_weight = 2\n",
    "                if probe_column_was_sorted:\n",
    "                    probe_weight = 1\n",
    "                if build_column_was_sorted:\n",
    "                    build_weight = 1\n",
    "\n",
    "                probe_table_size = row['PROBE_TABLE_SIZE']\n",
    "                build_table_size = row['BUILD_TABLE_SIZE']\n",
    "                total_table_size = probe_weight * probe_table_size + build_weight * build_table_size\n",
    "                \n",
    "                time_materialize_probe = time_materialize * (probe_weight * probe_table_size / total_table_size)\n",
    "                time_materialize_build = time_materialize - time_materialize_probe\n",
    "                \n",
    "                def get_materialize_factor(column, was_globally_sorted, is_sorted, expected_distinct_value_count):\n",
    "                    # Assumption: \"was_sorted\" implies global sortedness, i.e., both clustering and chunkwise sorting\n",
    "                    # This is true when the clustering produced by the table generator is used by the plan cache exporter\n",
    "                    # If the data has been re-clustered before the plan cache exporter runs, there has to be some system inside Hyrise which tracks the current clustering config\n",
    "                    \n",
    "                    # Sortedness seems to yield a speed up of approx. 1.6, regardless of the number of distinct values\n",
    "                    SORT_SPEEDUP = 1.6\n",
    "                    sortedness_factor = 1                    \n",
    "                    was_sorted = was_globally_sorted\n",
    "                    if was_sorted:\n",
    "                        sortedness_factor *= SORT_SPEEDUP\n",
    "                    if is_sorted:\n",
    "                        sortedness_factor /= SORT_SPEEDUP\n",
    "                    \n",
    "\n",
    "                    # The influence of clustering depends on the number of distinct values\n",
    "                    CLUSTERING_SPEEDUP_LOW = 1.84\n",
    "                    CLUSTERING_SPEEDUP_HIGH = 1\n",
    "                    clustering_factor = 1\n",
    "                    statistics_time_distinct_value_count = self.estimate_distinct_values_per_chunk_at_statistics_time(column, self.table_name);\n",
    "                    clustering_factor *= self.interpolate(CLUSTERING_SPEEDUP_LOW, CLUSTERING_SPEEDUP_HIGH, statistics_time_distinct_value_count / self.target_chunksize)\n",
    "                    clustering_factor /= self.interpolate(CLUSTERING_SPEEDUP_LOW, CLUSTERING_SPEEDUP_HIGH, expected_distinct_value_count / self.target_chunksize)\n",
    "                        \n",
    "                    return sortedness_factor * clustering_factor\n",
    "                \n",
    "                if row['PROBE_TABLE'] == self.table_name:\n",
    "                    expected_distinct_values_probe = self.estimate_distinct_values_per_chunk(probe_column, clustering_columns, sorting_column, dimension_cardinalities)\n",
    "                    materialize_probe_factor = get_materialize_factor(probe_column, probe_column_was_sorted, probe_column_is_sorted, expected_distinct_values_probe)\n",
    "                else:\n",
    "                    materialize_probe_factor = 1\n",
    "                    \n",
    "                if row['BUILD_TABLE'] == self.table_name:\n",
    "                    expected_distinct_values_build = self.estimate_distinct_values_per_chunk(build_column, clustering_columns, sorting_column, dimension_cardinalities)\n",
    "                    materialize_build_factor = get_materialize_factor(build_column, build_column_was_sorted, build_column_is_sorted, expected_distinct_values_build)\n",
    "                else:\n",
    "                    materialize_build_factor = 1\n",
    "                \n",
    "                time_materialize = time_materialize_probe * materialize_probe_factor + time_materialize_build *  materialize_build_factor\n",
    "\n",
    "\n",
    "                # unchanged\n",
    "                time_cluster = row['CLUSTER']\n",
    "                \n",
    "                # unchanged\n",
    "                time_build = row['BUILD']\n",
    "                \n",
    "                            \n",
    "                time_probe = row['PROBE']\n",
    "                probe_factor = 1\n",
    "                #if probe_column_is_sorted and probe_column_is_clustered:\n",
    "                #    if not probe_column_was_sorted:\n",
    "                #        probe_factor = 0.7\n",
    "                #    else:\n",
    "                #        probe_factor = 1\n",
    "                #elif probe_column_is_sorted or probe_column_is_clustered:\n",
    "                #    if not probe_column_was_sorted:\n",
    "                #        probe_factor = 0.9\n",
    "                #    else:\n",
    "                #        probe_factor = 1.1\n",
    "                #elif probe_column_was_sorted:\n",
    "                #    # probe column is now neither sorted nor clustered\n",
    "                #    probe_factor = 1.4\n",
    "                \n",
    "                time_probe *= probe_factor                \n",
    "                \n",
    "                # unchanged\n",
    "                time_write_output = row['WRITE_OUTPUT']\n",
    "                \n",
    "                \n",
    "                \n",
    "                # TODO: how to deal with the difference between RUNTIME_NS and sum(stage_runtimes)?\n",
    "                runtime = time_materialize + time_cluster + time_build + time_probe + time_write_output\n",
    "            else:\n",
    "                runtime = row['RUNTIME_NS']\n",
    "                \n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        for sorting_column in sorting_columns:\n",
    "            join_runtimes = self.joins.apply(estimate_join_runtime, axis=1, args=(sorting_column,))\n",
    "            total_runtimes[sorting_column] += join_runtimes.sum()\n",
    "                \n",
    "    def estimate_total_runtime(self, clustering_columns, sorting_columns):\n",
    "        #print(f\"testing clustering {clustering_columns} with sorting columns {sorting_columns}\")\n",
    "        dimension_cardinalities = self.get_dimension_cardinalities(clustering_columns)\n",
    "        total_runtimes = {sorting_column: 0 for sorting_column in sorting_columns}\n",
    "        self.estimate_table_scan_runtimes(clustering_columns, sorting_columns, dimension_cardinalities, total_runtimes)\n",
    "        self.estimate_join_runtimes(clustering_columns, sorting_columns, dimension_cardinalities, total_runtimes)\n",
    "        \n",
    "        clusterings = [[list(zip(clustering_columns, dimension_cardinalities)), sorting_column, np.int64(total_runtimes[sorting_column])] for sorting_column in sorting_columns]\n",
    "        return clusterings\n",
    "    \n",
    "    def get_dimension_cardinalities(self, clustering_columns):\n",
    "        raise NotImplementedError(\"Subclasses must override this function\")\n",
    "        \n",
    "    def interpolate(self, low, high, percentage):\n",
    "        assert percentage >= 0 and percentage <= 1, f\"percentage must between 0 and 1, but is {percentage}\"\n",
    "        return (1 - percentage) * low + (percentage * high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisjointClustersModel(SingleTableMdcModel):\n",
    "    \n",
    "    def __init__(self, max_dimensions, query_frequencies, table_name, table_scans, table_sizes, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation):\n",
    "        super().__init__(max_dimensions, query_frequencies, table_name, table_scans, table_sizes, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation)\n",
    "        \n",
    "    # This function should only be called for the own table, not for others\n",
    "    def estimate_distinct_values_per_chunk(self, column, clustering_columns, chunk_sorting_column, dimension_cardinalities):\n",
    "        total_distinct_values = self.distinct_values[self.table_name][column]\n",
    "        \n",
    "        if column in clustering_columns:\n",
    "            index = clustering_columns.index(column)\n",
    "            clusters_for_column = dimension_cardinalities[index]\n",
    "            return min(self.target_chunksize, total_distinct_values / clusters_for_column)\n",
    "        else:\n",
    "            # TODO cluster wise sorting\n",
    "            return min(self.target_chunksize, total_distinct_values)\n",
    "            \n",
    "\n",
    "    def get_dimension_cardinalities(self, clustering_columns):\n",
    "        # ToDo what if we aim at less than number of chunks clusters, i.e. multiple chunks per cluster?\n",
    "        target_cluster_count = int(1.1 * self.table_size / self.target_chunksize)\n",
    "        # idea: fixed size for join columns, variable amount for scan columns\n",
    "        \n",
    "        join_columns = list(filter(lambda x: self.is_join_column(x), clustering_columns))\n",
    "        scan_columns = list(filter(lambda x: self.is_scan_column(x), clustering_columns))\n",
    "        intersecting_columns = set(join_columns).intersection(set(scan_columns))\n",
    "        assert len(intersecting_columns) == 0, f\"The following columns are used as both join and scan column: {intersecting_columns}\"\n",
    "        \n",
    "        if len(scan_columns) == 0:\n",
    "            CLUSTERS_PER_JOIN_COLUMN = math.ceil(math.pow(target_cluster_count, 1/len(join_columns)))\n",
    "        else: \n",
    "            CLUSTERS_PER_JOIN_COLUMN = 3;\n",
    "        # Assumption: uniform distribution (in the sense that every cluster actually exists)\n",
    "        num_join_clusters = math.pow(CLUSTERS_PER_JOIN_COLUMN, len(join_columns))\n",
    "        assert num_join_clusters <= 1.5 * target_cluster_count, f\"Would get {num_join_clusters} clusters for join columns, but aimed at at most {target_cluster_count} clusters\"\n",
    "    \n",
    "        # only applies to scan columns\n",
    "        desired_scan_clusters_count = math.ceil(target_cluster_count / num_join_clusters)\n",
    "        individual_distinct_values = [self.distinct_values[self.table_name][column] for column in scan_columns]\n",
    "        log_distinct_values = [math.ceil(0.5+np.log2(x)) for x in individual_distinct_values]\n",
    "        log_distinct_values_product = reduce(operator.mul, log_distinct_values, 1)\n",
    "        assert log_distinct_values_product > 0, \"cannot have a distinct value count of 0\"\n",
    "\n",
    "        global_modification_factor = desired_scan_clusters_count / log_distinct_values_product\n",
    "        num_scan_dimensions = len(scan_columns)\n",
    "        individual_modification_factor = np.power(global_modification_factor, 1.0 / max(1, num_scan_dimensions))\n",
    "        \n",
    "        join_column_cluster_counts = [CLUSTERS_PER_JOIN_COLUMN] * len(join_columns)\n",
    "        scan_column_cluster_counts = [math.ceil(x * individual_modification_factor) for x in log_distinct_values]\n",
    "        \n",
    "        \n",
    "        # Merge join and scan columns\n",
    "        join_index = 0\n",
    "        scan_index = 0\n",
    "        cluster_counts = []\n",
    "        for clustering_column in clustering_columns:\n",
    "            if clustering_column in join_columns:\n",
    "                cluster_counts.append(join_column_cluster_counts[join_index])\n",
    "                join_index += 1\n",
    "            elif clustering_column in scan_columns:\n",
    "                cluster_counts.append(scan_column_cluster_counts[scan_index])\n",
    "                scan_index += 1\n",
    "        assert join_index == len(join_columns), f\"Processed the wrong number of join columns: {join_index} instead of {len(join_column_cluster_counts)}\"\n",
    "        assert scan_index == len(scan_columns), f\"Processed the wrong number of scan columns: {scan_index} instead of {len(scan_column_cluster_counts)}\"\n",
    "        assert len(cluster_counts) == len(clustering_columns), f\"Expected {len(clustering_columns)} cluster counts, but got {len(cluster_counts)}\"\n",
    "        \n",
    "        # testing\n",
    "        actual_cluster_count = reduce(operator.mul, cluster_counts, 1)\n",
    "        assert actual_cluster_count > 0, \"there was a split up factor of 0\"\n",
    "        assert actual_cluster_count <= 1.5 * target_cluster_count, f\"Wanted at most {target_cluster_count} clusters, but got {actual_cluster_count}\\nConfig: {clustering_columns}\\nCluster sizes: {cluster_counts}\"\n",
    "        estimated_chunksize = self.table_size / actual_cluster_count\n",
    "        assert estimated_chunksize <= self.target_chunksize, \"chunks should be smaller, not larger than target_chunksize\"\n",
    "        allowed_percentage = 0.55\n",
    "        if estimated_chunksize < allowed_percentage * self.target_chunksize:\n",
    "            print(f\"Warning: chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\")\n",
    "        #assert estimated_chunksize >= allowed_percentage * self.target_chunksize, f\"chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\"\n",
    "        \n",
    "        return cluster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 2]],\n",
    "            'orders': [['o_orderdate', 2]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_model(table_name, max_dimensions=2):    \n",
    "    query_frequencies = get_query_frequencies()\n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    start_time_table = datetime.now()\n",
    "    single_table_scans = extract_single_table(scans, table_name)\n",
    "\n",
    "    model = DisjointClustersModel(max_dimensions, query_frequencies, table_name, single_table_scans, table_sizes, distinct_values, CHUNK_SIZE, correlations.get(table_name, {}), joins, sorted_columns_during_creation)\n",
    "    return model\n",
    "\n",
    "model = create_model(\"lineitem\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#model.suggest_clustering(20)\n",
    "model.estimate_distinct_values_per_chunk_at_statistics_time(\"l_orderkey\", \"lineitem\")\n",
    "model.estimate_distinct_values_per_chunk(\"l_suppkey\", [\"l_suppkey\", \"l_partkey\"], \"l_orderkey\", [10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l_shipdate', 'l_quantity', 'l_discount', 'l_receiptdate', 'l_suppkey', 'l_orderkey', 'l_partkey']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[('l_orderkey', 100)], 'l_orderkey', 28450524667],\n",
       " [[('l_orderkey', 100)], 'l_partkey', 29385627412],\n",
       " [[('l_partkey', 100)], 'l_orderkey', 29754892608],\n",
       " [[('l_orderkey', 100)], 'l_shipdate', 29931519645],\n",
       " [[('l_suppkey', 10), ('l_partkey', 10)], 'l_orderkey', 29949952405],\n",
       " [[('l_orderkey', 10), ('l_partkey', 10)], 'l_orderkey', 30046068897],\n",
       " [[('l_orderkey', 100)], 'l_suppkey', 30247041889],\n",
       " [[('l_orderkey', 100)], 'l_receiptdate', 30379625243],\n",
       " [[('l_orderkey', 100)], 'l_discount', 30465102407],\n",
       " [[('l_orderkey', 100)], 'l_quantity', 30493319875],\n",
       " [[('l_shipdate', 34), ('l_suppkey', 3)], 'l_orderkey', 30856631879],\n",
       " [[('l_receiptdate', 34), ('l_suppkey', 3)], 'l_orderkey', 30859749933],\n",
       " [[('l_shipdate', 18), ('l_discount', 6)], 'l_orderkey', 30914280495],\n",
       " [[('l_discount', 6), ('l_receiptdate', 18)], 'l_orderkey', 30914382661],\n",
       " [[('l_shipdate', 100)], 'l_orderkey', 30916923369],\n",
       " [[('l_receiptdate', 100)], 'l_orderkey', 30921930097],\n",
       " [[('l_shipdate', 34), ('l_orderkey', 3)], 'l_orderkey', 30929014046],\n",
       " [[('l_shipdate', 34), ('l_partkey', 3)], 'l_orderkey', 30929014046],\n",
       " [[('l_shipdate', 14), ('l_quantity', 8)], 'l_orderkey', 30931217550],\n",
       " [[('l_quantity', 8), ('l_receiptdate', 14)], 'l_orderkey', 30931540171]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.suggest_clustering(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 2]],\n",
    "            'orders': [['o_orderdate', 2]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_benchmark_configs():    \n",
    "    start_time = datetime.now()\n",
    "    clusterings = {\"default\" : default_benchmark_config()}\n",
    "    query_frequencies = get_query_frequencies()\n",
    "    \n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    for table_name in table_names:\n",
    "        start_time_table = datetime.now()\n",
    "        single_table_scans = extract_single_table(scans, table_name)\n",
    "        table_size = table_sizes[table_name]\n",
    "        if table_size <= 3 * CHUNK_SIZE:\n",
    "            print(f\"Not computing clustering for {table_name}, as it has only {table_size} rows\")\n",
    "            continue\n",
    "\n",
    "        model = DisjointClustersModel(query_frequencies, table_name, single_table_scans, table_size, distinct_values, CHUNK_SIZE, correlations.get(table_name, {}), joins, sorted_columns_during_creation)\n",
    "        table_clusterings = model.suggest_clustering(3)\n",
    "        for table_clustering in table_clusterings:\n",
    "            config = default_benchmark_config()\n",
    "            config[table_name] = format_table_clustering(table_clustering)\n",
    "            config_name = get_config_name(config)\n",
    "            clusterings[config_name] = config\n",
    "        end_time_table = datetime.now()\n",
    "        print(f\"Done computing clustering for {table_name} ({end_time_table - start_time_table})\")\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print(f\"Computed all clusterings in {end_time - start_time}\")\n",
    "    \n",
    "    return clusterings\n",
    "\n",
    "create_benchmark_configs()\n",
    "\n",
    "# TODO:\n",
    "#  joins costs are multiplied with 0\n",
    "#  still, the model suggests some join columns - why? are they useful for pruning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outdated code fragments (older model versions) are kept below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"This assertion failure only serves to stop execution here when clicking Cells->Run all. You can safely ignore it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, table_scans, correlations = {}):\n",
    "        super().__init__(table_scans, correlations)        \n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        pairs = itertools.product(interesting_columns, interesting_columns)                \n",
    "        total_runtimes = [self.estimate_total_runtime(self.table_scans, clustering_columns) for clustering_columns in pairs]\n",
    "        total_runtimes.sort(key=lambda x: x[1], reverse=False)\n",
    "        \n",
    "        return total_runtimes[0:first_k]\n",
    "        \n",
    "    \n",
    "    def estimate_total_runtime(self, single_table, clustering_columns):\n",
    "        total_runtime = 0\n",
    "        \n",
    "        pruning_col = clustering_columns[0]\n",
    "        sorted_col = clustering_columns[1]\n",
    "        def compute_runtime(row):\n",
    "            col_name = row['COLUMN_NAME']\n",
    "            if pruning_col == sorted_col:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_log_runtime']\n",
    "                else:\n",
    "                    if col_name in self.correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "            else:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_runtime']\n",
    "                elif col_name == sorted_col:\n",
    "                    # TODO: should this be affected by correlation?\n",
    "                    # we will get less chunks, so a linear scan should be close to optimal_runtime,\n",
    "                    # but log time should beat it anyway\n",
    "                    return row['log_runtime']\n",
    "                else:\n",
    "                    if col_name in self.correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "                    \n",
    "        effective_runtime = single_table.apply(compute_runtime, axis=1)\n",
    "        return [clustering_columns, effective_runtime.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store additional statistics\n",
    "# TODO keep?\n",
    "\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def round_up_to_chunksize(row):\n",
    "    if row['OUTPUT_ROWS'] % CHUNK_SIZE == 0:\n",
    "        return row['OUTPUT_ROWS']\n",
    "    else:\n",
    "        return row['OUTPUT_ROWS'] + (CHUNK_SIZE - (row['OUTPUT_ROWS'] % CHUNK_SIZE))\n",
    "\n",
    "scans['pruned_minimum_input_rows'] = scans.apply(round_up_to_chunksize, axis=1)\n",
    "\n",
    "scans['selectivity'] = scans['OUTPUT_ROWS'] / scans['INPUT_ROWS']\n",
    "scans['actual_selectivity'] = scans['SINGLE_OUTPUT_ROWS'] / scans['SINGLE_INPUT_ROWS']\n",
    "\n",
    "scans['time_per_ir'] = scans['RUNTIME_NS'] / scans['INPUT_ROWS']\n",
    "scans['time_per_or'] = scans['RUNTIME_NS'] / scans['OUTPUT_ROWS']\n",
    "\n",
    "# optimal runtime assuming perfect pruning, but not sortedness\n",
    "scans['optimal_runtime'] = scans['time_per_ir'] * scans['pruned_minimum_input_rows']\n",
    "scans['runtime_gain'] = scans['RUNTIME_NS'] - scans['optimal_runtime']\n",
    "\n",
    "\n",
    "# log runtime for sorted columns\n",
    "scans['log_runtime'] = np.log2(scans['RUNTIME_NS'])\n",
    "scans['optimal_log_runtime'] = np.log2(1+scans['optimal_runtime'])\n",
    "scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAIN_COLUMN = 'runtime_gain'\n",
    "\n",
    "scans_groupby_columnname = scans.groupby(['TABLE_NAME', 'COLUMN_NAME'])\n",
    "sum_of_gains = pd.DataFrame(scans_groupby_columnname[GAIN_COLUMN].sum())\n",
    "sum_of_gains.sort_values(by=['TABLE_NAME', GAIN_COLUMN], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "if BENCHMARK == \"TPCH\":\n",
    "    TABLE = \"lineitem\"\n",
    "else:    \n",
    "    TABLE = \"customer_demographics\"\n",
    "\n",
    "import itertools\n",
    "\n",
    "def extract_single_table(table_name):\n",
    "    return scans[scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def extract_interesting_columns(df):\n",
    "    return list(df['COLUMN_NAME'].unique())\n",
    "\n",
    "\n",
    "correlations = {\n",
    "    'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "    'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "    'l_commitdate': ['l_receiptdate', 'l_shipdate']\n",
    "}\n",
    "#correlations = {}\n",
    "def table_sorting_options(table_name):\n",
    "    single_table = extract_single_table(table_name)\n",
    "    interesting_cols = extract_interesting_columns(single_table)\n",
    "    pairs = itertools.product(interesting_cols, interesting_cols)\n",
    "    \n",
    "    total_times = []\n",
    "    for pair in pairs:\n",
    "        pruning_col = pair[0]\n",
    "        sorted_col = pair[1]\n",
    "\n",
    "        def compute_runtime(row):\n",
    "            col_name = row['COLUMN_NAME']\n",
    "            if pruning_col == sorted_col:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_log_runtime']\n",
    "                else:\n",
    "                    if col_name in correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "            else:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_runtime']\n",
    "                elif col_name == sorted_col:\n",
    "                    # TODO: should this be affected by correlation?\n",
    "                    # we will get less chunks, so a linear scan should be close to optimal_runtime,\n",
    "                    # but log time should beat it anyway\n",
    "                    return row['log_runtime']\n",
    "                else:\n",
    "                    if col_name in correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "        effective_runtime = single_table.apply(compute_runtime, axis=1)\n",
    "        total_times.append([pair, effective_runtime.sum()])    \n",
    "    total_times = pd.DataFrame(total_times, columns=['columns', 'time'])    \n",
    "    return total_times\n",
    "\n",
    "options = table_sorting_options(TABLE)\n",
    "options.sort_values(by=['time'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates = pd.read_csv(f\"{STATISTICS_PATH}/aggregates.csv\", sep=',')\n",
    "\n",
    "# it looks like column names are mixed up.\n",
    "# COLUMN_NAME -> actually GROUP_BY_COLUMN_COUNT\n",
    "# GROUP_BY_COLUMN_COUNT -> actually AGGREGATE_COLUMN_COUNT\n",
    "# AGGREGATE_COLUMN_COUNT -> actually COLUMN_NAME\n",
    "\n",
    "COL_NAME = 'AGGREGATE_COLUMN_COUNT'\n",
    "GROUPBY_COL = 'COLUMN_NAME'\n",
    "AGG_COL = 'GROUP_BY_COLUMN_COUNT'\n",
    "\n",
    "# All aggregates have to read the entire table, so we cannot skip chunks.\n",
    "# But getting all groups consecutive could provide a speedup\n",
    "# As a result, we care only about aggregates with group by columns\n",
    "\n",
    "interesting_aggregates = aggregates[aggregates[GROUPBY_COL] > 0]\n",
    "stats = interesting_aggregates.groupby(['TABLE_NAME', COL_NAME])\n",
    "out_columns = pd.DataFrame(stats['OUTPUT_ROWS'].max())\n",
    "out_columns.sort_values(by=['TABLE_NAME', 'OUTPUT_ROWS'], ascending=[True, False])\n",
    "aggregates[aggregates['COLUMN_TYPE'] == 'DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_time_per_column = scans.groupby(['COLUMN_NAME'])\n",
    "accumulated_scan_times = pd.DataFrame(scan_time_per_column['RUNTIME_NS'].sum())\n",
    "total_scan_runtime = accumulated_scan_times['RUNTIME_NS'].sum()\n",
    "assert total_scan_runtime == scans['RUNTIME_NS'].sum(), f\"{total_scan_runtime}, {scans['RUNTIME_NS'].sum()}\"\n",
    "print(f\"total scan runtime: {total_scan_runtime}\")\n",
    "\n",
    "scan_time_per_column_prunable = scans[scans['useful_for_pruning']].groupby(['COLUMN_NAME'])\n",
    "accumulated_prunable_scan_times = pd.DataFrame(scan_time_per_column_prunable['RUNTIME_NS'].sum())\n",
    "total_prunable_scan_runtime = accumulated_prunable_scan_times['RUNTIME_NS'].sum()\n",
    "print(f\"total prunable scan runtime: {total_prunable_scan_runtime}\")\n",
    "print(f\"{100*total_prunable_scan_runtime/total_scan_runtime}% of scan runtime amount to prunable scans\")\n",
    "\n",
    "accumulated_scan_times.sort_values(['RUNTIME_NS'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "joins = load_join_statistics()\n",
    "\n",
    "print(joins['PROBE_COLUMN'].unique())\n",
    "\n",
    "join_time_per_column = joins.groupby(['PROBE_COLUMN'])\n",
    "\n",
    "accumulated_join_times = pd.DataFrame(join_time_per_column['RUNTIME_NS'].sum())\n",
    "print(len(accumulated_join_times))\n",
    "total_join_runtime = accumulated_join_times['RUNTIME_NS'].sum()\n",
    "#assert total_join_runtime == joins['RUNTIME_NS'].sum(), f\"{total_join_runtime},{joins['RUNTIME_NS'].sum()}\"\n",
    "print(f\"total join runtime: {total_join_runtime}\")\n",
    "\n",
    "joins[joins.apply(lambda x : x['PROBE_COLUMN'] not in ['o_custkey' ,'n_nationkey' ,'s_nationkey' ,'l_suppkey', 's_suppkey',\n",
    " 'l_orderkey', 'o_orderkey', 'p_partkey' ,'l_partkey' ,'ps_suppkey',\n",
    " 'c_nationkey' ,'r_regionkey' ,'c_custkey' ,'ps_partkey'] ,axis=1)]\n",
    "\n",
    "print(f\"for {BENCHMARK}, joins take about {total_join_runtime / total_scan_runtime} times longer than table scans\")\n",
    "accumulated_join_times.sort_values(['RUNTIME_NS'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
