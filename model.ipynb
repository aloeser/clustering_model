{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import math\n",
    "import operator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is configured for TPCH (chunk size 65535) with scale factor 1, 60 seconds runtime, and at most 10 runs per query\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "\n",
    "BENCHMARK = \"TPCH\"\n",
    "CHUNK_SIZE = 65535\n",
    "\n",
    "if BENCHMARK == \"TPCH\":\n",
    "    SCALE_FACTOR = 1\n",
    "    RUNS = 10\n",
    "    TIME = 60\n",
    "    STATISTICS_PATH = f\"~/Dokumente/repos/example_plugin/TPC-H__SF_{SCALE_FACTOR}.000000__RUNS_{RUNS}__TIME_{TIME}\"\n",
    "elif BENCHMARK == \"TPCDS\":\n",
    "    SCALE_FACTOR = 1\n",
    "    RUNS = 1\n",
    "    TIME = 60\n",
    "    STATISTICS_PATH = f\"~/Dokumente/repos/example_plugin/TPC-DS__SF_{SCALE_FACTOR}.000000__RUNS_{RUNS}__TIME_{TIME}\"\n",
    "else:\n",
    "    raise Exception(\"Unknown benchmark: \" + BENCHMARK)\n",
    "\n",
    "print(f\"Model is configured for {BENCHMARK} (chunk size {CHUNK_SIZE}) with scale factor {SCALE_FACTOR}, {TIME} seconds runtime, and at most {RUNS} runs per query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ~/Dokumente/repos/example_plugin/TPC-H__SF_1.000000__RUNS_10__TIME_60/table_scans.csv\n"
     ]
    }
   ],
   "source": [
    "# Load table scan statistics\n",
    "\n",
    "path = f\"{STATISTICS_PATH}/table_scans.csv\"\n",
    "scans = pd.read_csv(path, sep='|')\n",
    "EXPECTED_SCAN_COUNT = len(scans)\n",
    "LOADED_CHUNK_SIZE = CHUNK_SIZE\n",
    "LOADED_BENCHMARK = BENCHMARK\n",
    "LOADED_SCALE_FACTOR = SCALE_FACTOR\n",
    "LOADED_RUNS = RUNS\n",
    "LOADED_TIME = TIME\n",
    "\n",
    "print(f\"Successfully loaded {path}\")\n",
    "\n",
    "def assert_correct_statistics_loaded():\n",
    "    assert BENCHMARK == LOADED_BENCHMARK, f\"The model is configured to use {BENCHMARK}, but {LOADED_BENCHMARK} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert SCALE_FACTOR == LOADED_SCALE_FACTOR, f\"The model is configured to use {SCALE_FACTOR} as scale factor, but data for a scale factor of {LOADED_SCALE_FACTOR} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert RUNS == LOADED_RUNS, f\"The model is configured to perform at most {RUNS} runs, but the currently loaded data had at most {LOADED_RUNS} runs.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert TIME == LOADED_TIME, f\"The model is configured to run for {TIME} seconds, but the currently data had a runtime of {LOADED_TIME} seconds.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert CHUNK_SIZE == LOADED_CHUNK_SIZE, f\"The model is configured to use {CHUNK_SIZE} as chunk_size, but data for a chunk size of {LOADED_CHUNK_SIZE} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert EXPECTED_SCAN_COUNT == len(scans), f\"There should be {EXPECTED_SCAN_COUNT} table scans, but there are only {len(scans)}\\nProbably one of the last commands reassigned it unintentionally\"\n",
    "    \n",
    "    assert 'OPERATOR_POINTER' in scans.columns, f\"the statistics in {STATISTICS_PATH} are outdated (column 'OPERATOR_POINTER' in table_scans.csv is missing). Please create them again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - looks like pruning was deactivated while the statistics were created\n"
     ]
    }
   ],
   "source": [
    "# Validate table scans\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "# To make sure pruning was not active,\n",
    "# first fetch table sizes,\n",
    "table_statistics = pd.read_csv(f\"{STATISTICS_PATH}/table_meta_data.csv\", sep='|')\n",
    "table_sizes = dict(zip(table_statistics.table_name, table_statistics.row_count))\n",
    "\n",
    "# then make sure INPUT_ROWS == table_size\n",
    "def input_size_matches(row):\n",
    "    #print(row)\n",
    "    \n",
    "    actual_row_count = row['INPUT_ROWS']\n",
    "    table = row['TABLE_NAME']\n",
    "    expected_row_count = table_sizes[table]\n",
    "    return expected_row_count == actual_row_count\n",
    "\n",
    "data_scans = scans[scans['COLUMN_TYPE'] == 'DATA']\n",
    "input_size_matches = data_scans.apply(input_size_matches, axis=1)\n",
    "all_sizes_match = reduce(np.logical_and, input_size_matches) #input_size_matches.apply()\n",
    "\n",
    "if not all_sizes_match:\n",
    "    raise Exception(\"The given statistics were probably created while pruning was active\")\n",
    "else:\n",
    "    print(\"OK - looks like pruning was deactivated while the statistics were created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for TPCH contain 436 table scans\n",
      "Of those, only 228 are useful for pruning\n",
      "TODO: For now, filtering on scans is deactivated. This is because all scans are needed to recognize OR-Chains. Models have to take care themselves whether a scan can contribute to pruning or not\n"
     ]
    }
   ],
   "source": [
    "# Append additional information to the table scans\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "print(f\"Statistics for {BENCHMARK} contain {len(scans)} table scans\")\n",
    "\n",
    "\n",
    "# Add statistics about selectivity and speed for each operator\n",
    "scans['selectivity'] = scans['OUTPUT_ROWS'] / scans['INPUT_ROWS']\n",
    "\n",
    "# TODO: Assumption that reading and writing a row have the same cost\n",
    "scans['time_per_row'] = scans['RUNTIME_NS'] / (scans['INPUT_ROWS'] + scans['OUTPUT_ROWS'])\n",
    "scans['time_per_input_row'] = scans['time_per_row']\n",
    "scans['time_per_output_row'] = scans['time_per_row']\n",
    "\n",
    "\n",
    "def determine_or_chains(table_scans):\n",
    "    table_scans['part_of_or_chain'] = False\n",
    "    \n",
    "    single_table_scans = table_scans.groupby(['QUERY_HASH', 'TABLE_NAME', 'OPERATOR_POINTER'])\n",
    "    \n",
    "    for _, scans in single_table_scans:            \n",
    "        input_row_frequencies = Counter(scans.INPUT_ROWS)\n",
    "        or_input_sizes = set([input_size for input_size, frequency in input_row_frequencies.items() if frequency > 1])\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df['INPUT_ROWS'] = scans['INPUT_ROWS']\n",
    "        df['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "        df['part_of_or_chain'] = scans.apply(lambda row: row['INPUT_ROWS'] in or_input_sizes, axis=1)\n",
    "\n",
    "        for _ in range(len(scans)):\n",
    "            or_input_sizes |= set(df[df['part_of_or_chain']].OUTPUT_ROWS.unique())\n",
    "            df['part_of_or_chain'] = df.apply(lambda row: row['INPUT_ROWS'] in or_input_sizes, axis=1)\n",
    "\n",
    "        or_chains = list(df[df['part_of_or_chain']].index)\n",
    "        table_scans.iloc[or_chains, table_scans.columns.get_loc('part_of_or_chain')] = True\n",
    "    \n",
    "    return table_scans\n",
    "\n",
    "# Hyrise does not use scans that are part of an OR-chain for pruning\n",
    "scans = determine_or_chains(scans)\n",
    "\n",
    "\n",
    "# Like scans are not useful if they start with %\n",
    "# TODO what if they dont start with % and contain more than one % ? -> up to first % prunable, but is it used?\n",
    "def benefits_from_sorting(row):    \n",
    "    description = row['DESCRIPTION']\n",
    "    if \"ColumnLike\" in description:\n",
    "        words = description.split()\n",
    "        like_criteria = words[-1]\n",
    "        assert \"%\" in like_criteria, f\"LIKE operators should have an %, but found none in {like_criteria}\"\n",
    "        return like_criteria[1] != '%'\n",
    "    elif \"ExpressionEvaluator\" in description and \" IN \" in description:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "scans['benefits_from_sorting'] = scans.apply(benefits_from_sorting, axis=1)\n",
    "# TODO: valid atm, but feels a bit hacky to assume not benefitting from sorted segments -> not benefitting from pruning\n",
    "scans['useful_for_pruning'] = scans.apply(lambda row: not row['part_of_or_chain'] and row['benefits_from_sorting'] , axis=1)\n",
    "EXPECTED_SCAN_COUNT = len(scans)\n",
    "print(f\"Of those, only {len(scans[scans['useful_for_pruning']])} are useful for pruning\")\n",
    "\n",
    "print(\"TODO: For now, filtering on scans is deactivated. This is because all scans are needed to recognize OR-Chains. Models have to take care themselves whether a scan can contribute to pruning or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test OK\n"
     ]
    }
   ],
   "source": [
    "def test_determine_or_chains():\n",
    "    test = pd.DataFrame()\n",
    "    test['QUERY_HASH'] = pd.Series(['1']*3  + ['2']*4)\n",
    "    test['TABLE_NAME'] = pd.Series(['lineitem']*3  + ['part']*4)\n",
    "    test['OPERATOR_POINTER'] = pd.Series(['0x1'] + ['0x2']*2 + ['0x3']*4)\n",
    "    test['COLUMN_NAME'] = pd.Series(['l_shipdate', 'l_shipdate', 'l_discount', 'p_brand', 'p_type', 'p_type', 'p_size'])\n",
    "    test['INPUT_ROWS'] = pd.Series( [6001215, 6001215, 200000, 200000, 199000, 199000, 50000])\n",
    "    test['OUTPUT_ROWS'] = pd.Series([ 400000,  300000, 200000, 199000,      0,  50000, 20000])\n",
    "    test_result = determine_or_chains(test)\n",
    "    assert len(test_result) == 7, \"should not filter out any rows\"    \n",
    "    assert len(test_result[test_result['part_of_or_chain']]) == 3, \"expected 3 scans, got\\n\" + str(test_result)\n",
    "    assert list(test_result['part_of_or_chain']) == [False]*4 + [True]*3\n",
    "    print(\"Test OK\")\n",
    "\n",
    "test_determine_or_chains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104114384"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scans['RUNTIME_NS'] - scans['SINGLE_RUNTIME_NS']).max()\n",
    "# TODO can the actual runtime be that much greater than the runtime on the original table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load query frequency information\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def get_query_frequencies():\n",
    "    plan_cache = pd.read_csv(f\"{STATISTICS_PATH}/plan_cache.csv\", sep='|')\n",
    "    return dict(zip(plan_cache.QUERY_HASH, plan_cache.EXECUTION_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load column statistics - especially interesting: number of distinct values, and columns sorted during statistics creation\n",
    "\n",
    "# Returns a 2-level-dictionary: distinct_values[TABLE][COLUMN] = number_of_distinct_values\n",
    "def get_distinct_values_count():        \n",
    "    # Code\n",
    "    column_statistics_df = pd.read_csv(f\"{STATISTICS_PATH}/column_meta_data.csv\", sep='|')\n",
    "    column_statistics_df['distinct_values'] = np.int32(column_statistics_df['distinct_values'])\n",
    "    tables_and_columns = column_statistics_df.groupby('table_name')\n",
    "    distinct_values = {table: dict(zip(column_df.column_name, column_df.distinct_values)) for table, column_df in tables_and_columns }\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    num_tables = len(distinct_values)\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        assert num_tables == 8, f\"TPCH has 8 tables, but got {num_tables}\"\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        assert num_tables == 24, f\"TPCDS has 24 tables, but got {num_tables}\"\n",
    "    else:\n",
    "        assert False, \"Insert a benchmark specific check here\"\n",
    "    \n",
    "    return distinct_values\n",
    "\n",
    "# Returns a dictionary: sorted_columns_during_creation[TABLE] = [column1, column2, ...]\n",
    "def get_sorted_columns_during_creation():\n",
    "    # Code\n",
    "    column_statistics_df = pd.read_csv(f\"{STATISTICS_PATH}/column_meta_data.csv\", sep='|')\n",
    "    globally_sorted_columns = column_statistics_df[column_statistics_df['is_globally_sorted'] == 1]\n",
    "    \n",
    "    tables_and_columns = globally_sorted_columns.groupby('table_name')\n",
    "    globally_sorted_columns = {table: list(column_df.column_name) for table, column_df in tables_and_columns }\n",
    "    \n",
    "    return globally_sorted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOINS ###\n",
    "\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def load_join_statistics():\n",
    "    def line_looks_suspicious(row):\n",
    "        right_table_name = row['RIGHT_TABLE_NAME']    \n",
    "        if pd.isnull(right_table_name):\n",
    "            pass\n",
    "        elif row['RIGHT_TABLE_ROW_COUNT'] > table_sizes[row['RIGHT_TABLE_NAME']]:\n",
    "            return True\n",
    "\n",
    "        left_table_name = row['LEFT_TABLE_NAME']\n",
    "        if pd.isnull(left_table_name):\n",
    "            pass\n",
    "        elif row['LEFT_TABLE_ROW_COUNT'] > table_sizes[row['LEFT_TABLE_NAME']]:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def validate_joins(joins):\n",
    "        is_suspicious = joins.apply(line_looks_suspicious, axis=1)\n",
    "        suspicious_joins = joins[is_suspicious]\n",
    "        assert len(suspicious_joins) < 3, f\"there are {len(suspicious_joins)} suspicious joins:\\n{suspicious_joins[['JOIN_MODE', 'LEFT_TABLE_NAME', 'LEFT_COLUMN_NAME', 'LEFT_TABLE_ROW_COUNT', 'RIGHT_TABLE_NAME', 'RIGHT_COLUMN_NAME', 'RIGHT_TABLE_ROW_COUNT', 'PROBE_TABLE', 'PROBE_COLUMN', 'OUTPUT_ROWS']]}\"\n",
    "    \n",
    "    joins = pd.read_csv(f\"{STATISTICS_PATH}/joins.csv\", sep=',')\n",
    "    validate_joins(joins)\n",
    "                                                                                           \n",
    "    return joins\n",
    "\n",
    "#load_join_statistics().iloc[9:10][['JOIN_MODE', 'LEFT_TABLE_NAME', 'LEFT_COLUMN_NAME', 'LEFT_TABLE_ROW_COUNT', 'RIGHT_TABLE_NAME', 'RIGHT_COLUMN_NAME', 'RIGHT_TABLE_ROW_COUNT', 'PROBE_TABLE', 'PROBE_COLUMN', 'OUTPUT_ROWS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractModel:\n",
    "    \n",
    "    def __init__(self, query_frequencies, table_name, table_scans, correlations={}):\n",
    "        self.query_frequencies = query_frequencies\n",
    "        self.table_name = table_name\n",
    "        self.table_scans = table_scans\n",
    "        self.correlations = correlations\n",
    "        \n",
    "    def query_frequency(self, query_hash):\n",
    "        return self.query_frequencies[query_hash]\n",
    "        \n",
    "    def extract_scan_columns(self):\n",
    "        useful_scans = self.table_scans[self.table_scans['useful_for_pruning']]\n",
    "        interesting_scan_columns = list(useful_scans['COLUMN_NAME'].unique())\n",
    "        \n",
    "        return interesting_scan_columns\n",
    "    \n",
    "    def extract_join_columns(self):\n",
    "        interesting_join_probe_columns = list(self.joins[self.joins['PROBE_TABLE'] == self.table_name]['PROBE_COLUMN'].unique())\n",
    "        interesting_join_build_columns = list(self.joins[self.joins['BUILD_TABLE'] == self.table_name]['BUILD_COLUMN'].unique())        \n",
    "        \n",
    "        return self.uniquify(interesting_join_probe_columns + interesting_join_build_columns)\n",
    "    \n",
    "    def extract_interesting_columns(self):        \n",
    "        return self.uniquify(self.extract_scan_columns() + self.extract_join_columns())\n",
    "    \n",
    "    def round_up_to_next_multiple(self, number_to_round, base_for_multiple):\n",
    "        quotient = number_to_round // base_for_multiple\n",
    "        if number_to_round % base_for_multiple != 0:\n",
    "            quotient += 1\n",
    "        return quotient * base_for_multiple        \n",
    "\n",
    "    def uniquify(self, seq):\n",
    "            seen = set()\n",
    "            return [x for x in seq if not (x in seen or seen.add(x))]    \n",
    "    \n",
    "    # return a list of possible clusterings\n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTableMdcModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, query_frequencies, table_name, table_scans, table_size, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation):\n",
    "        super().__init__(query_frequencies, table_name, table_scans, correlations)\n",
    "        self.table_size = table_size\n",
    "        self.distinct_values = distinct_values\n",
    "        self.target_chunksize = target_chunksize\n",
    "        self.joins = joins\n",
    "        self.sorted_columns_during_creation = sorted_columns_during_creation\n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        print(interesting_columns)\n",
    "        \n",
    "        clustering_columns = itertools.product(interesting_columns, interesting_columns)\n",
    "        #clustering_columns = itertools.product(interesting_columns, interesting_columns, interesting_columns)\n",
    "        clustering_columns = filter(lambda x: x[0] <= x[1], clustering_columns)\n",
    "        #clustering_columns = filter(lambda x: x[1] <= x[2], clustering_columns)\n",
    "        clustering_columns = [self.uniquify(clustering) for clustering in clustering_columns]\n",
    "        sort_columns = interesting_columns        \n",
    "        clusterings_with_runtimes = reduce(lambda x,y: x+y,[self.estimate_total_runtime(clustering_cols, sort_columns) for clustering_cols in clustering_columns])\n",
    "        clusterings_with_runtimes.sort(key=lambda x: x[2], reverse=False)\n",
    "        \n",
    "        return clusterings_with_runtimes[0:first_k]\n",
    "        \n",
    "    def estimate_table_scan_runtimes(self, clustering_columns, sorting_columns, split_factors, total_runtimes):        \n",
    "        def compute_unprunable_parts(row, split_factors):\n",
    "            def clustering_columns_correlated_to(column):\n",
    "                return [clustering_column for clustering_column in clustering_columns if column in self.correlations.get(clustering_column, {})]\n",
    "            \n",
    "            def correlates_to_clustering_column(column):\n",
    "                return len(clustering_columns_correlated_to(column)) > 0\n",
    "\n",
    "            column_name = row['COLUMN_NAME']\n",
    "\n",
    "            if not row['useful_for_pruning']:\n",
    "                selectivity = 1\n",
    "            elif column_name in clustering_columns:\n",
    "                scan_selectivity = row['selectivity']\n",
    "                split_factor = split_factors[clustering_columns.index(column_name)]\n",
    "                selectivity =  self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor)\n",
    "            elif correlates_to_clustering_column(column_name):\n",
    "                scan_selectivity = row['selectivity']\n",
    "                correlated_clustering_columns = clustering_columns_correlated_to(column_name)\n",
    "                \n",
    "                # ToDo this is hacky, but for now assume there is just one correlated column\n",
    "                assert len(correlated_clustering_columns) == 1, f\"expected just 1 correlated clustering column, but got {len(correlated_clustering_columns)}\"\n",
    "                \n",
    "                split_factor = split_factors[clustering_columns.index(correlated_clustering_columns[0])]\n",
    "                selectivity = min(1, 1.2 * self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor))\n",
    "            else:\n",
    "                selectivity = 1\n",
    "            \n",
    "            return selectivity\n",
    "        \n",
    "        def compute_runtimes(row, sorting_column):\n",
    "            assert row['estimated_input_rows'] > 1, row\n",
    "            assert row['runtime_per_input_row'] > 0, row\n",
    "            assert row['runtime_per_output_row'] > 0, row\n",
    "            input_row_count = row['estimated_input_rows']\n",
    "            \n",
    "            if row['COLUMN_NAME'] == sorting_column and row['benefits_from_sorting']:\n",
    "                # TODO is this the best way to simulate sorted access?\n",
    "                input_row_count = np.log2(input_row_count)\n",
    "\n",
    "            runtime = input_row_count * row['runtime_per_input_row'] + row['OUTPUT_ROWS'] * row['runtime_per_output_row']\n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        scans_per_query = self.table_scans.sort_values(['INPUT_ROWS'], ascending=False).groupby(['QUERY_HASH', 'OPERATOR_POINTER'])\n",
    "        for _, scans in scans_per_query:\n",
    "            number_of_scans = len(scans)\n",
    "            assert number_of_scans > 0 and number_of_scans < 25, f\"weird scan length: {number_of_scans}\\nScans:\\n{scans}\"\n",
    "            # TODO: kinda unrealistic assumption: everything not in the table scan result can be pruned\n",
    "                          \n",
    "            unprunable_parts = scans.apply(compute_unprunable_parts, axis=1, args=(split_factors,))            \n",
    "            unprunable_part = unprunable_parts.product()\n",
    "            assert unprunable_part > 0, \"no unprunable part\"\n",
    "            \n",
    "            estimated_pruned_table_size = self.round_up_to_next_multiple(unprunable_part * self.table_size, CHUNK_SIZE)\n",
    "            \n",
    "            runtimes = pd.DataFrame()\n",
    "            runtimes['QUERY_HASH'] = scans['QUERY_HASH']\n",
    "            runtimes['runtime_per_input_row'] = scans['time_per_input_row']\n",
    "            runtimes['runtime_per_output_row'] = scans['time_per_output_row']\n",
    "            runtimes['COLUMN_NAME'] = scans['COLUMN_NAME']\n",
    "            runtimes['benefits_from_sorting'] = scans['benefits_from_sorting']\n",
    "            # the pruned table inputs should be reflected in 'estimated_input_rows'\n",
    "            runtimes['estimated_input_rows'] = scans.apply(lambda x: x['INPUT_ROWS'], axis=1)\n",
    "            runtimes['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "\n",
    "            runtimes.iloc[0, runtimes.columns.get_loc('estimated_input_rows')] = estimated_pruned_table_size                                    \n",
    "            assert runtimes['estimated_input_rows'].iloc[0] == estimated_pruned_table_size, f\"value is {runtimes.iloc[0]['estimated_input_rows']}, but should be {estimated_pruned_table_size}\"\n",
    "            # TODO modify input sizes of subsequent scans\n",
    "            \n",
    "            for sorting_column in sorting_columns:\n",
    "                scan_runtimes = runtimes.apply(compute_runtimes, axis=1, args=(sorting_column,))\n",
    "                total_runtimes[sorting_column] += scan_runtimes.sum()\n",
    "\n",
    "    def estimate_join_runtimes(self, clustering_columns, sorting_columns, total_runtimes):                \n",
    "        def estimate_join_runtime(row, sorting_column):\n",
    "                        \n",
    "            if \"JoinHash\" in row['DESCRIPTION']:\n",
    "                probe_column = row['PROBE_COLUMN']\n",
    "                if row['PROBE_TABLE'] == self.table_name:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    probe_column_is_sorted = row['PROBE_SORTED'] and probe_column == sorting_column\n",
    "                    probe_column_is_clustered = row['PROBE_SORTED'] and probe_column in clustering_columns\n",
    "                else:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(row['PROBE_TABLE'], {})\n",
    "                    probe_column_is_sorted = probe_column_was_sorted\n",
    "                    probe_column_is_clustered = probe_column_was_sorted\n",
    "                    \n",
    "                build_column = row['BUILD_COLUMN']\n",
    "                if row['BUILD_TABLE'] == self.table_name:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    build_column_is_sorted = row['BUILD_SORTED'] and build_column == sorting_column\n",
    "                    build_column_is_clustered = row['BUILD_SORTED'] and build_column in clustering_columns\n",
    "                else:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(row['BUILD_TABLE'], {})\n",
    "                    build_column_is_sorted = build_column_was_sorted\n",
    "                    build_column_is_clustered = build_column_was_sorted\n",
    "\n",
    "                time_materialize = row['MATERIALIZE']\n",
    "                \n",
    "                probe_weight = 2\n",
    "                build_weight = 2\n",
    "                if probe_column_was_sorted:\n",
    "                    probe_weight = 1\n",
    "                if build_column_was_sorted:\n",
    "                    build_weight = 1\n",
    "                \n",
    "                \n",
    "                probe_table_size = row['PROBE_TABLE_SIZE']\n",
    "                build_table_size = row['BUILD_TABLE_SIZE']\n",
    "                total_table_size = probe_weight * probe_table_size + build_weight * build_table_size\n",
    "                \n",
    "                time_materialize_probe = time_materialize * (probe_weight * probe_table_size / total_table_size)\n",
    "                time_materialize_build = time_materialize - time_materialize_probe\n",
    "                \n",
    "                \n",
    "                def get_materialize_factor(was_sorted, is_sorted, is_clustered):\n",
    "                    materialize_factor = 1\n",
    "                    if is_sorted and is_clustered:\n",
    "                        if not was_sorted:\n",
    "                            materialize_factor = 0.5\n",
    "                        else:\n",
    "                            materialize_factor = 1\n",
    "                    elif is_sorted or is_clustered:\n",
    "                        if not was_sorted:\n",
    "                            materialize_factor = 0.55\n",
    "                        else:\n",
    "                            materialize_factor = 1.1\n",
    "                    elif was_sorted:\n",
    "                        # probe column is now neither sorted nor clustered\n",
    "                        materialize_factor = 2\n",
    "                    else:\n",
    "                        # default case: was not sorted before, and is neither sorted nor clustered now. No change\n",
    "                        materialize_factor = 1\n",
    "                        \n",
    "                    return materialize_factor\n",
    "                \n",
    "                materialize_probe_factor = get_materialize_factor(probe_column_was_sorted, probe_column_is_sorted, probe_column_is_clustered)\n",
    "                materialize_build_factor = get_materialize_factor(build_column_was_sorted, build_column_is_sorted, build_column_is_clustered)\n",
    "                \n",
    "                time_materialize = time_materialize_probe * materialize_probe_factor + time_materialize_build *  materialize_build_factor\n",
    "                \n",
    "\n",
    "                # unchanged\n",
    "                time_cluster = row['CLUSTER']\n",
    "                \n",
    "                # unchanged\n",
    "                time_build = row['BUILD']\n",
    "                \n",
    "                            \n",
    "                time_probe = row['PROBE']\n",
    "                probe_factor = 1\n",
    "                if probe_column_is_sorted and probe_column_is_clustered:\n",
    "                    if not probe_column_was_sorted:\n",
    "                        probe_factor = 0.7\n",
    "                    else:\n",
    "                        probe_factor = 1\n",
    "                elif probe_column_is_sorted or probe_column_is_clustered:\n",
    "                    if not probe_column_was_sorted:\n",
    "                        probe_factor = 0.9\n",
    "                    else:\n",
    "                        probe_factor = 1.1\n",
    "                elif probe_column_was_sorted:\n",
    "                    # probe column is now neither sorted nor clustered\n",
    "                    probe_factor = 1.4\n",
    "                \n",
    "                time_probe *= probe_factor                \n",
    "                \n",
    "                # unchanged\n",
    "                time_write_output = row['WRITE_OUTPUT']\n",
    "                \n",
    "                \n",
    "                \n",
    "                # TODO: how to deal with the difference between RUNTIME_NS and sum(stage_runtimes)?\n",
    "                runtime = time_materialize + time_cluster + time_build + time_probe + time_write_output\n",
    "            else:\n",
    "                runtime = row['RUNTIME_NS']\n",
    "                \n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        for sorting_column in sorting_columns:\n",
    "            join_runtimes = self.joins.apply(estimate_join_runtime, axis=1, args=(sorting_column,))\n",
    "            total_runtimes[sorting_column] += join_runtimes.sum()\n",
    "                \n",
    "    def estimate_total_runtime(self, clustering_columns, sorting_columns):\n",
    "        #print(f\"testing clustering {clustering_columns} with sorting columns {sorting_columns}\")\n",
    "        split_factors = self.determine_split_factors(clustering_columns)            \n",
    "        total_runtimes = {sorting_column: 0 for sorting_column in sorting_columns}\n",
    "        self.estimate_table_scan_runtimes(clustering_columns, sorting_columns, split_factors, total_runtimes)\n",
    "        self.estimate_join_runtimes(clustering_columns, sorting_columns, total_runtimes)\n",
    "        \n",
    "        clusterings = [[list(zip(clustering_columns, split_factors)), sorting_column, np.int64(total_runtimes[sorting_column])] for sorting_column in sorting_columns]\n",
    "        return clusterings\n",
    "    \n",
    "    def determine_split_factors(self, clustering_columns):\n",
    "        approximate_split_factor = self.table_size / self.target_chunksize\n",
    "        individual_distinct_values = [self.distinct_values[column] for column in clustering_columns]        \n",
    "        log_distinct_values = [math.ceil(0.5+np.log2(x)) for x in individual_distinct_values]\n",
    "        log_distinct_values_product = reduce(operator.mul, log_distinct_values, 1)\n",
    "        assert log_distinct_values_product > 0, \"cannot have a distinct value count of 0\"\n",
    "        \n",
    "        global_modification_factor = approximate_split_factor / log_distinct_values_product\n",
    "        num_dimensions = len(clustering_columns)\n",
    "        individual_modification_factor = np.power(global_modification_factor, 1.0 / num_dimensions)    \n",
    "        split_factors = [math.ceil(x * individual_modification_factor) for x in log_distinct_values]\n",
    "        \n",
    "        # testing\n",
    "        actual_split_factor = reduce(operator.mul, split_factors, 1)\n",
    "        assert actual_split_factor > 0, \"there was a split up factor of 0\"\n",
    "        estimated_chunksize = self.table_size / actual_split_factor\n",
    "        assert estimated_chunksize <= self.target_chunksize, \"chunks should be smaller, not larger than target_chunksize\"\n",
    "        allowed_percentage = 0.55\n",
    "        if estimated_chunksize < allowed_percentage * self.target_chunksize:\n",
    "            print(f\"Warning: chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\")\n",
    "        #assert estimated_chunksize >= allowed_percentage * self.target_chunksize, f\"chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\"\n",
    "        \n",
    "        return split_factors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not computing clustering for customer, as it has only 150000 rows\n",
      "['o_orderstatus', 'o_orderdate', 'o_orderkey', 'o_custkey']\n",
      "Done computing clustering for orders (0:00:10.260482)\n",
      "Not computing clustering for nation, as it has only 25 rows\n",
      "['p_name', 'p_type', 'p_brand', 'p_container', 'p_size', 'p_partkey']\n",
      "Warning: chunks should not be too much smaller than target_chunksize: 33333.333333333336 < 0.55 * 65535\n",
      "Warning: chunks should not be too much smaller than target_chunksize: 33333.333333333336 < 0.55 * 65535\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9c4902f5c26b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclusterings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mcreate_benchmark_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# TODO:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-9c4902f5c26b>\u001b[0m in \u001b[0;36mcreate_benchmark_configs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleTableMdcModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_table_scans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistinct_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobe_side_joins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_columns_during_creation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mtable_clusterings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtable_clustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable_clusterings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_benchmark_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d3c4efa2ad3>\u001b[0m in \u001b[0;36msuggest_clustering\u001b[0;34m(self, first_k)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mclustering_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniquify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msort_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteresting_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mclusterings_with_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_total_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering_cols\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mclusterings_with_runtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d3c4efa2ad3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mclustering_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniquify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msort_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteresting_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mclusterings_with_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_total_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering_cols\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mclusterings_with_runtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d3c4efa2ad3>\u001b[0m in \u001b[0;36mestimate_total_runtime\u001b[0;34m(self, clustering_columns, sorting_columns)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0msplit_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetermine_split_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mtotal_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msorting_column\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msorting_column\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_table_scan_runtimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_factors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_runtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_join_runtimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_runtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d3c4efa2ad3>\u001b[0m in \u001b[0;36mestimate_table_scan_runtimes\u001b[0;34m(self, clustering_columns, sorting_columns, split_factors, total_runtimes)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mruntimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OUTPUT_ROWS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OUTPUT_ROWS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mruntimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'estimated_input_rows'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimated_pruned_table_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mruntimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimated_input_rows'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mestimated_pruned_table_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"value is {runtimes.iloc[0]['estimated_input_rows']}, but should be {estimated_pruned_table_size}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# TODO modify input sizes of subsequent scans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# maybe partial set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtake_split_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# if there is only one block/type, still have to take split path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_is_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5164\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5167\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5125\u001b[0m         \"\"\"\n\u001b[1;32m   5126\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5127\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5162\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5164\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mis_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;31m# Warning, consolidation needs to get checked upstairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mnew_blklocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "def extract_probe_side_joins(joins, table_name):\n",
    "    return joins[joins['PROBE_TABLE'] == table_name]\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 92 * SCALE_FACTOR]],\n",
    "            'orders': [['o_orderdate', 23 * SCALE_FACTOR]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_benchmark_configs():\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    clusterings = {\"default\" : default_benchmark_config()}\n",
    "    query_frequencies = get_query_frequencies()\n",
    "    \n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    for table_name in table_names:\n",
    "        start_time_table = datetime.now()\n",
    "        single_table_scans = extract_single_table(scans, table_name)\n",
    "        probe_side_joins = joins#extract_probe_side_joins(joins, table_name)\n",
    "        table_size = table_sizes[table_name]\n",
    "        if table_size <= 3 * CHUNK_SIZE:\n",
    "            print(f\"Not computing clustering for {table_name}, as it has only {table_size} rows\")\n",
    "            continue\n",
    "\n",
    "        model = SingleTableMdcModel(query_frequencies, table_name, single_table_scans, table_size, distinct_values[table_name], CHUNK_SIZE, correlations.get(table_name, {}), probe_side_joins, sorted_columns_during_creation)\n",
    "        table_clusterings = model.suggest_clustering(3)\n",
    "        for table_clustering in table_clusterings:\n",
    "            config = default_benchmark_config()\n",
    "            config[table_name] = format_table_clustering(table_clustering)\n",
    "            config_name = get_config_name(config)\n",
    "            clusterings[config_name] = config\n",
    "        end_time_table = datetime.now()\n",
    "        print(f\"Done computing clustering for {table_name} ({end_time_table - start_time_table})\")\n",
    "\n",
    "            \n",
    "    end_time = datetime.now()\n",
    "    print(f\"Computed all clusterings in {end_time - start_time}\")\n",
    "    \n",
    "    return clusterings\n",
    "\n",
    "create_benchmark_configs()\n",
    "\n",
    "# TODO:\n",
    "#  joins costs are multiplied with 0\n",
    "#  still, the model suggests some join columns - why? are they useful for pruning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 2]],\n",
    "            'orders': [['o_orderdate', 2]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_model(table_name, max_dimensions=2):    \n",
    "    query_frequencies = get_query_frequencies()\n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    start_time_table = datetime.now()\n",
    "    single_table_scans = extract_single_table(scans, table_name)\n",
    "    table_size = table_sizes[table_name]\n",
    "\n",
    "    model = DisjointClustersModel(max_dimensions, query_frequencies, table_name, single_table_scans, table_size, distinct_values[table_name], CHUNK_SIZE, correlations.get(table_name, {}), joins, sorted_columns_during_creation)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisjointClustersModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, max_dimensions, query_frequencies, table_name, table_scans, table_size, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation):\n",
    "        super().__init__(query_frequencies, table_name, table_scans, correlations)\n",
    "        self.max_dimensions = max_dimensions\n",
    "        self.table_size = table_size\n",
    "        self.distinct_values = distinct_values\n",
    "        self.target_chunksize = target_chunksize\n",
    "        self.joins = joins\n",
    "        self.sorted_columns_during_creation = sorted_columns_during_creation\n",
    "        \n",
    "        self.join_column_names = self.extract_join_columns()\n",
    "        self.scan_column_names = self.extract_scan_columns()\n",
    "        \n",
    "    def is_join_column(self, column_name):\n",
    "        return column_name in self.join_column_names\n",
    "    \n",
    "    def is_scan_column(self, column_name):\n",
    "        return column_name in self.scan_column_names\n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        print(interesting_columns)\n",
    "        clustering_columns = itertools.combinations_with_replacement(interesting_columns, self.max_dimensions)\n",
    "        clustering_columns = [self.uniquify(clustering) for clustering in clustering_columns]\n",
    "        sort_columns = interesting_columns        \n",
    "        clusterings_with_runtimes = reduce(lambda x,y: x+y,[self.estimate_total_runtime(clustering_cols, sort_columns) for clustering_cols in clustering_columns])\n",
    "        clusterings_with_runtimes.sort(key=lambda x: x[2], reverse=False)\n",
    "        \n",
    "        return clusterings_with_runtimes[0:first_k]\n",
    "        \n",
    "    def estimate_table_scan_runtimes(self, clustering_columns, sorting_columns, split_factors, total_runtimes):        \n",
    "        def compute_unprunable_parts(row, split_factors):\n",
    "            def clustering_columns_correlated_to(column):\n",
    "                return [clustering_column for clustering_column in clustering_columns if column in self.correlations.get(clustering_column, {})]\n",
    "            \n",
    "            def correlates_to_clustering_column(column):\n",
    "                return len(clustering_columns_correlated_to(column)) > 0\n",
    "\n",
    "            column_name = row['COLUMN_NAME']\n",
    "\n",
    "            if not row['useful_for_pruning']:\n",
    "                selectivity = 1\n",
    "            elif column_name in clustering_columns:\n",
    "                scan_selectivity = row['selectivity']\n",
    "                split_factor = split_factors[clustering_columns.index(column_name)]\n",
    "                selectivity =  self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor)\n",
    "            elif correlates_to_clustering_column(column_name):\n",
    "                scan_selectivity = row['selectivity']\n",
    "                correlated_clustering_columns = clustering_columns_correlated_to(column_name)\n",
    "                \n",
    "                # ToDo this is hacky, but for now assume there is just one correlated column\n",
    "                assert len(correlated_clustering_columns) == 1, f\"expected just 1 correlated clustering column, but got {len(correlated_clustering_columns)}\"\n",
    "                \n",
    "                split_factor = split_factors[clustering_columns.index(correlated_clustering_columns[0])]\n",
    "                selectivity = min(1, 1.2 * self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor))\n",
    "            else:\n",
    "                selectivity = 1\n",
    "            \n",
    "            return selectivity\n",
    "        \n",
    "        def compute_runtimes(row, sorting_column):\n",
    "            assert row['estimated_input_rows'] > 1, row\n",
    "            assert row['runtime_per_input_row'] > 0, row\n",
    "            assert row['runtime_per_output_row'] > 0, row\n",
    "            input_row_count = row['estimated_input_rows']\n",
    "            \n",
    "            if row['COLUMN_NAME'] == sorting_column and row['benefits_from_sorting']:\n",
    "                # TODO is this the best way to simulate sorted access?\n",
    "                input_row_count = np.log2(input_row_count)\n",
    "\n",
    "            runtime = input_row_count * row['runtime_per_input_row'] + row['OUTPUT_ROWS'] * row['runtime_per_output_row']\n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        scans_per_query = self.table_scans.sort_values(['INPUT_ROWS'], ascending=False).groupby(['QUERY_HASH', 'OPERATOR_POINTER'])\n",
    "        for _, scans in scans_per_query:\n",
    "            number_of_scans = len(scans)\n",
    "            assert number_of_scans > 0 and number_of_scans < 25, f\"weird scan length: {number_of_scans}\\nScans:\\n{scans}\"\n",
    "            # TODO: kinda unrealistic assumption: everything not in the table scan result can be pruned\n",
    "                          \n",
    "            unprunable_parts = scans.apply(compute_unprunable_parts, axis=1, args=(split_factors,))            \n",
    "            unprunable_part = unprunable_parts.product()\n",
    "            assert unprunable_part > 0, \"no unprunable part\"\n",
    "            \n",
    "            estimated_pruned_table_size = self.round_up_to_next_multiple(unprunable_part * self.table_size, CHUNK_SIZE)\n",
    "            \n",
    "            runtimes = pd.DataFrame()\n",
    "            runtimes['QUERY_HASH'] = scans['QUERY_HASH']\n",
    "            runtimes['runtime_per_input_row'] = scans['time_per_input_row']\n",
    "            runtimes['runtime_per_output_row'] = scans['time_per_output_row']\n",
    "            runtimes['COLUMN_NAME'] = scans['COLUMN_NAME']\n",
    "            runtimes['benefits_from_sorting'] = scans['benefits_from_sorting']\n",
    "            # the pruned table inputs should be reflected in 'estimated_input_rows'\n",
    "            runtimes['estimated_input_rows'] = scans.apply(lambda x: x['INPUT_ROWS'], axis=1)\n",
    "            runtimes['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "\n",
    "            runtimes.iloc[0, runtimes.columns.get_loc('estimated_input_rows')] = estimated_pruned_table_size                                    \n",
    "            assert runtimes['estimated_input_rows'].iloc[0] == estimated_pruned_table_size, f\"value is {runtimes.iloc[0]['estimated_input_rows']}, but should be {estimated_pruned_table_size}\"\n",
    "            # TODO modify input sizes of subsequent scans\n",
    "            \n",
    "            for sorting_column in sorting_columns:\n",
    "                scan_runtimes = runtimes.apply(compute_runtimes, axis=1, args=(sorting_column,))\n",
    "                total_runtimes[sorting_column] += scan_runtimes.sum()\n",
    "\n",
    "    def estimate_join_runtimes(self, clustering_columns, sorting_columns, total_runtimes):                \n",
    "        def estimate_join_runtime(row, sorting_column):\n",
    "                        \n",
    "            if \"JoinHash\" in row['DESCRIPTION']:\n",
    "                probe_column = row['PROBE_COLUMN']\n",
    "                if row['PROBE_TABLE'] == self.table_name:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    probe_column_is_sorted = row['PROBE_SORTED'] and probe_column == sorting_column\n",
    "                    probe_column_is_clustered = row['PROBE_SORTED'] and probe_column in clustering_columns\n",
    "                else:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(row['PROBE_TABLE'], {})\n",
    "                    probe_column_is_sorted = probe_column_was_sorted\n",
    "                    probe_column_is_clustered = probe_column_was_sorted\n",
    "                    \n",
    "                build_column = row['BUILD_COLUMN']\n",
    "                if row['BUILD_TABLE'] == self.table_name:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    build_column_is_sorted = row['BUILD_SORTED'] and build_column == sorting_column\n",
    "                    build_column_is_clustered = row['BUILD_SORTED'] and build_column in clustering_columns\n",
    "                else:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(row['BUILD_TABLE'], {})\n",
    "                    build_column_is_sorted = build_column_was_sorted\n",
    "                    build_column_is_clustered = build_column_was_sorted\n",
    "\n",
    "                time_materialize = row['MATERIALIZE']\n",
    "                \n",
    "                probe_weight = 2\n",
    "                build_weight = 2\n",
    "                if probe_column_was_sorted:\n",
    "                    probe_weight = 1\n",
    "                if build_column_was_sorted:\n",
    "                    build_weight = 1\n",
    "                \n",
    "                \n",
    "                probe_table_size = row['PROBE_TABLE_SIZE']\n",
    "                build_table_size = row['BUILD_TABLE_SIZE']\n",
    "                total_table_size = probe_weight * probe_table_size + build_weight * build_table_size\n",
    "                \n",
    "                time_materialize_probe = time_materialize * (probe_weight * probe_table_size / total_table_size)\n",
    "                time_materialize_build = time_materialize - time_materialize_probe\n",
    "                \n",
    "                \n",
    "                def get_materialize_factor(was_sorted, is_sorted, is_clustered):\n",
    "                    materialize_factor = 1\n",
    "                    if is_sorted and is_clustered:\n",
    "                        if not was_sorted:\n",
    "                            materialize_factor = 0.5\n",
    "                        else:\n",
    "                            materialize_factor = 1\n",
    "                    elif is_sorted or is_clustered:\n",
    "                        if not was_sorted:\n",
    "                            materialize_factor = 0.55\n",
    "                        else:\n",
    "                            materialize_factor = 1.1\n",
    "                    elif was_sorted:\n",
    "                        # probe column is now neither sorted nor clustered\n",
    "                        materialize_factor = 2\n",
    "                    else:\n",
    "                        # default case: was not sorted before, and is neither sorted nor clustered now. No change\n",
    "                        materialize_factor = 1\n",
    "                        \n",
    "                    return materialize_factor\n",
    "                \n",
    "                materialize_probe_factor = get_materialize_factor(probe_column_was_sorted, probe_column_is_sorted, probe_column_is_clustered)\n",
    "                materialize_build_factor = get_materialize_factor(build_column_was_sorted, build_column_is_sorted, build_column_is_clustered)\n",
    "                \n",
    "                time_materialize = time_materialize_probe * materialize_probe_factor + time_materialize_build *  materialize_build_factor\n",
    "                \n",
    "\n",
    "                # unchanged\n",
    "                time_cluster = row['CLUSTER']\n",
    "                \n",
    "                # unchanged\n",
    "                time_build = row['BUILD']\n",
    "                \n",
    "                            \n",
    "                time_probe = row['PROBE']\n",
    "                probe_factor = 1\n",
    "                if probe_column_is_sorted and probe_column_is_clustered:\n",
    "                    if not probe_column_was_sorted:\n",
    "                        probe_factor = 0.7\n",
    "                    else:\n",
    "                        probe_factor = 1\n",
    "                elif probe_column_is_sorted or probe_column_is_clustered:\n",
    "                    if not probe_column_was_sorted:\n",
    "                        probe_factor = 0.9\n",
    "                    else:\n",
    "                        probe_factor = 1.1\n",
    "                elif probe_column_was_sorted:\n",
    "                    # probe column is now neither sorted nor clustered\n",
    "                    probe_factor = 1.4\n",
    "                \n",
    "                time_probe *= probe_factor                \n",
    "                \n",
    "                # unchanged\n",
    "                time_write_output = row['WRITE_OUTPUT']\n",
    "                \n",
    "                \n",
    "                \n",
    "                # TODO: how to deal with the difference between RUNTIME_NS and sum(stage_runtimes)?\n",
    "                runtime = time_materialize + time_cluster + time_build + time_probe + time_write_output\n",
    "            else:\n",
    "                runtime = row['RUNTIME_NS']\n",
    "                \n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        for sorting_column in sorting_columns:\n",
    "            join_runtimes = self.joins.apply(estimate_join_runtime, axis=1, args=(sorting_column,))\n",
    "            total_runtimes[sorting_column] += join_runtimes.sum()\n",
    "                \n",
    "    def estimate_total_runtime(self, clustering_columns, sorting_columns):\n",
    "        #print(f\"testing clustering {clustering_columns} with sorting columns {sorting_columns}\")\n",
    "        cluster_counts = self.determine_cluster_counts(clustering_columns)            \n",
    "        total_runtimes = {sorting_column: 0 for sorting_column in sorting_columns}\n",
    "        self.estimate_table_scan_runtimes(clustering_columns, sorting_columns, cluster_counts, total_runtimes)\n",
    "        self.estimate_join_runtimes(clustering_columns, sorting_columns, total_runtimes)\n",
    "        \n",
    "        clusterings = [[list(zip(clustering_columns, cluster_counts)), sorting_column, np.int64(total_runtimes[sorting_column])] for sorting_column in sorting_columns]\n",
    "        return clusterings\n",
    "    \n",
    "    def determine_cluster_counts(self, clustering_columns):\n",
    "        # ToDo what if we aim at less than number of chunks clusters, i.e. multiple chunks per cluster?\n",
    "        target_cluster_count = int(1.1 * self.table_size / self.target_chunksize)\n",
    "        # idea: fixed size for join columns, variable amount for scan columns\n",
    "        \n",
    "        join_columns = list(filter(lambda x: self.is_join_column(x), clustering_columns))\n",
    "        scan_columns = list(filter(lambda x: self.is_scan_column(x), clustering_columns))\n",
    "        intersecting_columns = set(join_columns).intersection(set(scan_columns))\n",
    "        assert len(intersecting_columns) == 0, f\"The following columns are used as both join and scan column: {intersecting_columns}\"\n",
    "        \n",
    "        if len(scan_columns) == 0:\n",
    "            CLUSTERS_PER_JOIN_COLUMN = math.ceil(math.pow(target_cluster_count, 1/len(join_columns)))\n",
    "        else: \n",
    "            CLUSTERS_PER_JOIN_COLUMN = 3;\n",
    "        # Assumption: uniform distribution (in the sense that every cluster actually exists)\n",
    "        num_join_clusters = math.pow(CLUSTERS_PER_JOIN_COLUMN, len(join_columns))\n",
    "        assert num_join_clusters <= 1.5 * target_cluster_count, f\"Would get {num_join_clusters} clusters for join columns, but aimed at at most {target_cluster_count} clusters\"\n",
    "    \n",
    "        # only applies to scan columns\n",
    "        desired_scan_clusters_count = math.ceil(target_cluster_count / num_join_clusters)\n",
    "        individual_distinct_values = [self.distinct_values[column] for column in scan_columns]\n",
    "        log_distinct_values = [math.ceil(0.5+np.log2(x)) for x in individual_distinct_values]\n",
    "        log_distinct_values_product = reduce(operator.mul, log_distinct_values, 1)\n",
    "        assert log_distinct_values_product > 0, \"cannot have a distinct value count of 0\"\n",
    "\n",
    "        global_modification_factor = desired_scan_clusters_count / log_distinct_values_product\n",
    "        num_scan_dimensions = len(scan_columns)\n",
    "        individual_modification_factor = np.power(global_modification_factor, 1.0 / max(1, num_scan_dimensions))\n",
    "        \n",
    "        join_column_cluster_counts = [CLUSTERS_PER_JOIN_COLUMN] * len(join_columns)\n",
    "        scan_column_cluster_counts = [math.ceil(x * individual_modification_factor) for x in log_distinct_values]\n",
    "        \n",
    "        \n",
    "        # Merge join and scan columns\n",
    "        join_index = 0\n",
    "        scan_index = 0\n",
    "        cluster_counts = []\n",
    "        for clustering_column in clustering_columns:\n",
    "            if clustering_column in join_columns:\n",
    "                cluster_counts.append(join_column_cluster_counts[join_index])\n",
    "                join_index += 1\n",
    "            elif clustering_column in scan_columns:\n",
    "                cluster_counts.append(scan_column_cluster_counts[scan_index])\n",
    "                scan_index += 1\n",
    "        assert join_index == len(join_columns), f\"Processed the wrong number of join columns: {join_index} instead of {len(join_column_cluster_counts)}\"\n",
    "        assert scan_index == len(scan_columns), f\"Processed the wrong number of scan columns: {scan_index} instead of {len(scan_column_cluster_counts)}\"\n",
    "        assert len(cluster_counts) == len(clustering_columns), f\"Expected {len(clustering_columns)} cluster counts, but got {len(cluster_counts)}\"\n",
    "        \n",
    "        # testing\n",
    "        actual_cluster_count = reduce(operator.mul, cluster_counts, 1)\n",
    "        assert actual_cluster_count > 0, \"there was a split up factor of 0\"\n",
    "        assert actual_cluster_count <= 1.5 * target_cluster_count, f\"Wanted at most {target_cluster_count} clusters, but got {actual_cluster_count}\\nConfig: {clustering_columns}\\nCluster sizes: {cluster_counts}\"\n",
    "        estimated_chunksize = self.table_size / actual_cluster_count\n",
    "        assert estimated_chunksize <= self.target_chunksize, \"chunks should be smaller, not larger than target_chunksize\"\n",
    "        allowed_percentage = 0.55\n",
    "        if estimated_chunksize < allowed_percentage * self.target_chunksize:\n",
    "            print(f\"Warning: chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\")\n",
    "        #assert estimated_chunksize >= allowed_percentage * self.target_chunksize, f\"chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\"\n",
    "        \n",
    "        return cluster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l_shipdate', 'l_quantity', 'l_discount', 'l_receiptdate', 'l_suppkey', 'l_orderkey', 'l_partkey']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[('l_shipdate', 4), ('l_suppkey', 3), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26385936866],\n",
       " [[('l_receiptdate', 4),\n",
       "   ('l_suppkey', 3),\n",
       "   ('l_orderkey', 3),\n",
       "   ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26399322584],\n",
       " [[('l_shipdate', 12), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26666941325],\n",
       " [[('l_shipdate', 12), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26666941325],\n",
       " [[('l_shipdate', 12), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26666941325],\n",
       " [[('l_receiptdate', 4),\n",
       "   ('l_suppkey', 3),\n",
       "   ('l_orderkey', 3),\n",
       "   ('l_partkey', 3)],\n",
       "  'l_shipdate',\n",
       "  26669096560],\n",
       " [[('l_receiptdate', 12), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26672516068],\n",
       " [[('l_receiptdate', 12), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26672516068],\n",
       " [[('l_receiptdate', 12), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26672516068],\n",
       " [[('l_shipdate', 6), ('l_discount', 2), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26674531277],\n",
       " [[('l_shipdate', 4), ('l_suppkey', 3), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_shipdate',\n",
       "  26676651289],\n",
       " [[('l_discount', 4), ('l_suppkey', 3), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26677873766],\n",
       " [[('l_discount', 2),\n",
       "   ('l_receiptdate', 6),\n",
       "   ('l_orderkey', 3),\n",
       "   ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26681054764],\n",
       " [[('l_shipdate', 5), ('l_quantity', 3), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26694644294],\n",
       " [[('l_quantity', 3),\n",
       "   ('l_receiptdate', 5),\n",
       "   ('l_orderkey', 3),\n",
       "   ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26701167780],\n",
       " [[('l_quantity', 4), ('l_suppkey', 3), ('l_orderkey', 3), ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26702250622],\n",
       " [[('l_shipdate', 4),\n",
       "   ('l_receiptdate', 4),\n",
       "   ('l_orderkey', 3),\n",
       "   ('l_partkey', 3)],\n",
       "  'l_orderkey',\n",
       "  26721955281],\n",
       " [[('l_suppkey', 5), ('l_orderkey', 5), ('l_partkey', 5)],\n",
       "  'l_orderkey',\n",
       "  26771616056],\n",
       " [[('l_suppkey', 5), ('l_orderkey', 5), ('l_partkey', 5)],\n",
       "  'l_orderkey',\n",
       "  26771616056],\n",
       " [[('l_suppkey', 5), ('l_orderkey', 5), ('l_partkey', 5)],\n",
       "  'l_orderkey',\n",
       "  26771616056]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(\"lineitem\", 4)\n",
    "model.suggest_clustering(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not computing clustering for customer, as it has only 150000 rows\n",
      "['o_orderstatus', 'o_orderdate', 'o_orderkey', 'o_custkey']\n",
      "Done computing clustering for orders (0:00:09.662568)\n",
      "Not computing clustering for nation, as it has only 25 rows\n",
      "['p_name', 'p_type', 'p_brand', 'p_container', 'p_size', 'p_partkey']\n",
      "Warning: chunks should not be too much smaller than target_chunksize: 33333.333333333336 < 0.55 * 65535\n",
      "Warning: chunks should not be too much smaller than target_chunksize: 33333.333333333336 < 0.55 * 65535\n",
      "Warning: chunks should not be too much smaller than target_chunksize: 33333.333333333336 < 0.55 * 65535\n",
      "Warning: chunks should not be too much smaller than target_chunksize: 33333.333333333336 < 0.55 * 65535\n",
      "Warning: chunks should not be too much smaller than target_chunksize: 33333.333333333336 < 0.55 * 65535\n",
      "Warning: chunks should not be too much smaller than target_chunksize: 33333.333333333336 < 0.55 * 65535\n",
      "Done computing clustering for part (0:00:32.685082)\n",
      "Not computing clustering for region, as it has only 5 rows\n",
      "['l_shipdate', 'l_quantity', 'l_discount', 'l_receiptdate', 'l_suppkey', 'l_orderkey', 'l_partkey']\n",
      "Done computing clustering for lineitem (0:00:40.875373)\n",
      "Not computing clustering for supplier, as it has only 10000 rows\n",
      "Computed all clusterings in 0:01:23.580248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'lineitem': [['l_shipdate', 2]], 'orders': [['o_orderdate', 2]]},\n",
       " 'l_shipdate-2_o_custkey-5_o_orderkey-6_o_orderdate-1': {'lineitem': [['l_shipdate',\n",
       "    2]],\n",
       "  'orders': [('o_custkey', 5), ('o_orderkey', 6), ('o_orderdate', 1)]},\n",
       " 'l_shipdate-2_o_custkey-5_o_orderkey-6': {'lineitem': [['l_shipdate', 2]],\n",
       "  'orders': [('o_custkey', 5), ('o_orderkey', 6)]},\n",
       " 'l_shipdate-2_o_orderdate-4_o_orderkey-7_o_custkey-1': {'lineitem': [['l_shipdate',\n",
       "    2]],\n",
       "  'orders': [('o_orderdate', 4), ('o_orderkey', 7), ('o_custkey', 1)]},\n",
       " 'l_shipdate-2_o_orderdate-2_p_name-2_p_partkey-2_p_type-1': {'lineitem': [['l_shipdate',\n",
       "    2]],\n",
       "  'orders': [['o_orderdate', 2]],\n",
       "  'part': [('p_name', 2), ('p_partkey', 2), ('p_type', 1)]},\n",
       " 'l_shipdate-2_o_orderdate-2_p_partkey-3_p_size-2_p_type-1': {'lineitem': [['l_shipdate',\n",
       "    2]],\n",
       "  'orders': [['o_orderdate', 2]],\n",
       "  'part': [('p_partkey', 3), ('p_size', 2), ('p_type', 1)]},\n",
       " 'l_shipdate-2_o_orderdate-2_p_name-2_p_partkey-2_p_brand-1': {'lineitem': [['l_shipdate',\n",
       "    2]],\n",
       "  'orders': [['o_orderdate', 2]],\n",
       "  'part': [('p_name', 2), ('p_partkey', 2), ('p_brand', 1)]},\n",
       " 'l_orderkey-11_l_partkey-9_l_orderkey-1_o_orderdate-2': {'lineitem': [('l_orderkey',\n",
       "    11),\n",
       "   ('l_partkey', 9),\n",
       "   ('l_orderkey', 1)],\n",
       "  'orders': [['o_orderdate', 2]]},\n",
       " 'l_orderkey-11_l_partkey-9_l_shipdate-1_o_orderdate-2': {'lineitem': [('l_orderkey',\n",
       "    11),\n",
       "   ('l_partkey', 9),\n",
       "   ('l_shipdate', 1)],\n",
       "  'orders': [['o_orderdate', 2]]},\n",
       " 'l_orderkey-13_l_shipdate-8_l_partkey-1_o_orderdate-2': {'lineitem': [('l_orderkey',\n",
       "    13),\n",
       "   ('l_shipdate', 8),\n",
       "   ('l_partkey', 1)],\n",
       "  'orders': [['o_orderdate', 2]]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 2]],\n",
    "            'orders': [['o_orderdate', 2]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_benchmark_configs():    \n",
    "    start_time = datetime.now()\n",
    "    clusterings = {\"default\" : default_benchmark_config()}\n",
    "    query_frequencies = get_query_frequencies()\n",
    "    \n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    for table_name in table_names:\n",
    "        start_time_table = datetime.now()\n",
    "        single_table_scans = extract_single_table(scans, table_name)\n",
    "        table_size = table_sizes[table_name]\n",
    "        if table_size <= 3 * CHUNK_SIZE:\n",
    "            print(f\"Not computing clustering for {table_name}, as it has only {table_size} rows\")\n",
    "            continue\n",
    "\n",
    "        model = DisjointClustersModel(query_frequencies, table_name, single_table_scans, table_size, distinct_values[table_name], CHUNK_SIZE, correlations.get(table_name, {}), joins, sorted_columns_during_creation)\n",
    "        table_clusterings = model.suggest_clustering(3)\n",
    "        for table_clustering in table_clusterings:\n",
    "            config = default_benchmark_config()\n",
    "            config[table_name] = format_table_clustering(table_clustering)\n",
    "            config_name = get_config_name(config)\n",
    "            clusterings[config_name] = config\n",
    "        end_time_table = datetime.now()\n",
    "        print(f\"Done computing clustering for {table_name} ({end_time_table - start_time_table})\")\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print(f\"Computed all clusterings in {end_time - start_time}\")\n",
    "    \n",
    "    return clusterings\n",
    "\n",
    "create_benchmark_configs()\n",
    "\n",
    "# TODO:\n",
    "#  joins costs are multiplied with 0\n",
    "#  still, the model suggests some join columns - why? are they useful for pruning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outdated code fragments (older model versions) are kept below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, table_scans, correlations = {}):\n",
    "        super().__init__(table_scans, correlations)        \n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        pairs = itertools.product(interesting_columns, interesting_columns)                \n",
    "        total_runtimes = [self.estimate_total_runtime(self.table_scans, clustering_columns) for clustering_columns in pairs]\n",
    "        total_runtimes.sort(key=lambda x: x[1], reverse=False)\n",
    "        \n",
    "        return total_runtimes[0:first_k]\n",
    "        \n",
    "    \n",
    "    def estimate_total_runtime(self, single_table, clustering_columns):\n",
    "        total_runtime = 0\n",
    "        \n",
    "        pruning_col = clustering_columns[0]\n",
    "        sorted_col = clustering_columns[1]\n",
    "        def compute_runtime(row):\n",
    "            col_name = row['COLUMN_NAME']\n",
    "            if pruning_col == sorted_col:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_log_runtime']\n",
    "                else:\n",
    "                    if col_name in self.correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "            else:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_runtime']\n",
    "                elif col_name == sorted_col:\n",
    "                    # TODO: should this be affected by correlation?\n",
    "                    # we will get less chunks, so a linear scan should be close to optimal_runtime,\n",
    "                    # but log time should beat it anyway\n",
    "                    return row['log_runtime']\n",
    "                else:\n",
    "                    if col_name in self.correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "                    \n",
    "        effective_runtime = single_table.apply(compute_runtime, axis=1)\n",
    "        return [clustering_columns, effective_runtime.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_HASH</th>\n",
       "      <th>COLUMN_TYPE</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>INPUT_ROWS</th>\n",
       "      <th>OUTPUT_ROWS</th>\n",
       "      <th>RUNTIME_NS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>SINGLE_INPUT_ROWS</th>\n",
       "      <th>SINGLE_OUTPUT_ROWS</th>\n",
       "      <th>...</th>\n",
       "      <th>benefits_from_sorting</th>\n",
       "      <th>useful_for_pruning</th>\n",
       "      <th>pruned_minimum_input_rows</th>\n",
       "      <th>actual_selectivity</th>\n",
       "      <th>time_per_ir</th>\n",
       "      <th>time_per_or</th>\n",
       "      <th>optimal_runtime</th>\n",
       "      <th>runtime_gain</th>\n",
       "      <th>log_runtime</th>\n",
       "      <th>optimal_log_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bac00c0bdbf62ea</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>customer</td>\n",
       "      <td>c_phone</td>\n",
       "      <td>681435</td>\n",
       "      <td>190499</td>\n",
       "      <td>182312504</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (SUBSTR(c_...</td>\n",
       "      <td>1500000</td>\n",
       "      <td>419123</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>196605</td>\n",
       "      <td>0.279415</td>\n",
       "      <td>267.542031</td>\n",
       "      <td>957.026042</td>\n",
       "      <td>5.260010e+07</td>\n",
       "      <td>1.297124e+08</td>\n",
       "      <td>27.441838</td>\n",
       "      <td>25.648562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2687bf4da454552b</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>customer</td>\n",
       "      <td>c_phone</td>\n",
       "      <td>681352</td>\n",
       "      <td>190434</td>\n",
       "      <td>184210492</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (SUBSTR(c_...</td>\n",
       "      <td>1500000</td>\n",
       "      <td>419793</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>196605</td>\n",
       "      <td>0.279862</td>\n",
       "      <td>270.360243</td>\n",
       "      <td>967.319344</td>\n",
       "      <td>5.315418e+07</td>\n",
       "      <td>1.310563e+08</td>\n",
       "      <td>27.456780</td>\n",
       "      <td>25.663680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2bd757c748d34189</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>customer</td>\n",
       "      <td>c_phone</td>\n",
       "      <td>681223</td>\n",
       "      <td>190942</td>\n",
       "      <td>186800722</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (SUBSTR(c_...</td>\n",
       "      <td>1500000</td>\n",
       "      <td>419992</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>196605</td>\n",
       "      <td>0.279995</td>\n",
       "      <td>274.213763</td>\n",
       "      <td>978.311330</td>\n",
       "      <td>5.391180e+07</td>\n",
       "      <td>1.328889e+08</td>\n",
       "      <td>27.476925</td>\n",
       "      <td>25.684098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7ce8aa4cc8eabfd8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>customer</td>\n",
       "      <td>c_phone</td>\n",
       "      <td>680683</td>\n",
       "      <td>190698</td>\n",
       "      <td>183656825</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (SUBSTR(c_...</td>\n",
       "      <td>1500000</td>\n",
       "      <td>419626</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>196605</td>\n",
       "      <td>0.279751</td>\n",
       "      <td>269.812563</td>\n",
       "      <td>963.076828</td>\n",
       "      <td>5.304650e+07</td>\n",
       "      <td>1.306103e+08</td>\n",
       "      <td>27.452437</td>\n",
       "      <td>25.660754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3bf533ddc6f54ed4</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>customer</td>\n",
       "      <td>c_phone</td>\n",
       "      <td>680526</td>\n",
       "      <td>190820</td>\n",
       "      <td>183580973</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (SUBSTR(c_...</td>\n",
       "      <td>1500000</td>\n",
       "      <td>420284</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>196605</td>\n",
       "      <td>0.280189</td>\n",
       "      <td>269.763349</td>\n",
       "      <td>962.063583</td>\n",
       "      <td>5.303682e+07</td>\n",
       "      <td>1.305441e+08</td>\n",
       "      <td>27.451841</td>\n",
       "      <td>25.660491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74335a369db42f54</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>customer</td>\n",
       "      <td>c_phone</td>\n",
       "      <td>682247</td>\n",
       "      <td>190532</td>\n",
       "      <td>183523699</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (SUBSTR(c_...</td>\n",
       "      <td>1500000</td>\n",
       "      <td>419794</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>196605</td>\n",
       "      <td>0.279863</td>\n",
       "      <td>268.998909</td>\n",
       "      <td>963.217197</td>\n",
       "      <td>5.288653e+07</td>\n",
       "      <td>1.306372e+08</td>\n",
       "      <td>27.451391</td>\n",
       "      <td>25.656397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aeebd3c094273d3e</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>customer</td>\n",
       "      <td>c_phone</td>\n",
       "      <td>681571</td>\n",
       "      <td>190524</td>\n",
       "      <td>182585251</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (SUBSTR(c_...</td>\n",
       "      <td>1500000</td>\n",
       "      <td>420242</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>196605</td>\n",
       "      <td>0.280161</td>\n",
       "      <td>267.888820</td>\n",
       "      <td>958.332026</td>\n",
       "      <td>5.266828e+07</td>\n",
       "      <td>1.299170e+08</td>\n",
       "      <td>27.443995</td>\n",
       "      <td>25.650431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6730c267d3eac48a</td>\n",
       "      <td>DATA</td>\n",
       "      <td>orders</td>\n",
       "      <td>o_orderstatus</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>88478994</td>\n",
       "      <td>TableScan Impl: ColumnVsValue o_orderstatus = 'F'</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7339920</td>\n",
       "      <td>0.487279</td>\n",
       "      <td>5.898600</td>\n",
       "      <td>12.105181</td>\n",
       "      <td>4.329525e+07</td>\n",
       "      <td>4.518374e+07</td>\n",
       "      <td>26.398832</td>\n",
       "      <td>25.367705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6730c267d3eac48a</td>\n",
       "      <td>DATA</td>\n",
       "      <td>nation</td>\n",
       "      <td>n_name</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>36669</td>\n",
       "      <td>TableScan Impl: ColumnVsValue n_name = 'IRAN'</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1466.760000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>9.612412e+07</td>\n",
       "      <td>-9.608745e+07</td>\n",
       "      <td>15.162273</td>\n",
       "      <td>26.518395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6ec3126b032024be</td>\n",
       "      <td>DATA</td>\n",
       "      <td>orders</td>\n",
       "      <td>o_orderstatus</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>89032941</td>\n",
       "      <td>TableScan Impl: ColumnVsValue o_orderstatus = 'F'</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7339920</td>\n",
       "      <td>0.487279</td>\n",
       "      <td>5.935529</td>\n",
       "      <td>12.180969</td>\n",
       "      <td>4.356631e+07</td>\n",
       "      <td>4.546663e+07</td>\n",
       "      <td>26.407836</td>\n",
       "      <td>25.376710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6ec3126b032024be</td>\n",
       "      <td>DATA</td>\n",
       "      <td>nation</td>\n",
       "      <td>n_name</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>35622</td>\n",
       "      <td>TableScan Impl: ColumnVsValue n_name = 'VIETNAM'</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1424.880000</td>\n",
       "      <td>35622.000000</td>\n",
       "      <td>9.337951e+07</td>\n",
       "      <td>-9.334389e+07</td>\n",
       "      <td>15.120481</td>\n",
       "      <td>26.476603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7324393c05ab5301</td>\n",
       "      <td>DATA</td>\n",
       "      <td>orders</td>\n",
       "      <td>o_orderstatus</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>93872414</td>\n",
       "      <td>TableScan Impl: ColumnVsValue o_orderstatus = 'F'</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7339920</td>\n",
       "      <td>0.487279</td>\n",
       "      <td>6.258161</td>\n",
       "      <td>12.843077</td>\n",
       "      <td>4.593440e+07</td>\n",
       "      <td>4.793801e+07</td>\n",
       "      <td>26.484198</td>\n",
       "      <td>25.453072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7324393c05ab5301</td>\n",
       "      <td>DATA</td>\n",
       "      <td>nation</td>\n",
       "      <td>n_name</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>36879</td>\n",
       "      <td>TableScan Impl: ColumnVsValue n_name = 'KENYA'</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1475.160000</td>\n",
       "      <td>36879.000000</td>\n",
       "      <td>9.667461e+07</td>\n",
       "      <td>-9.663773e+07</td>\n",
       "      <td>15.170512</td>\n",
       "      <td>26.526634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>37e2ba0a1c4e865f</td>\n",
       "      <td>DATA</td>\n",
       "      <td>orders</td>\n",
       "      <td>o_orderstatus</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>125510444</td>\n",
       "      <td>TableScan Impl: ColumnVsValue o_orderstatus = 'F'</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7339920</td>\n",
       "      <td>0.487279</td>\n",
       "      <td>8.367363</td>\n",
       "      <td>17.171608</td>\n",
       "      <td>6.141577e+07</td>\n",
       "      <td>6.409467e+07</td>\n",
       "      <td>26.903232</td>\n",
       "      <td>25.872106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>37e2ba0a1c4e865f</td>\n",
       "      <td>DATA</td>\n",
       "      <td>nation</td>\n",
       "      <td>n_name</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>37577</td>\n",
       "      <td>TableScan Impl: ColumnVsValue n_name = 'EGYPT'</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1503.080000</td>\n",
       "      <td>37577.000000</td>\n",
       "      <td>9.850435e+07</td>\n",
       "      <td>-9.846677e+07</td>\n",
       "      <td>15.197562</td>\n",
       "      <td>26.553684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a17cb368eadced8f</td>\n",
       "      <td>DATA</td>\n",
       "      <td>orders</td>\n",
       "      <td>o_orderstatus</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>105709732</td>\n",
       "      <td>TableScan Impl: ColumnVsValue o_orderstatus = 'F'</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7339920</td>\n",
       "      <td>0.487279</td>\n",
       "      <td>7.047315</td>\n",
       "      <td>14.462590</td>\n",
       "      <td>5.172673e+07</td>\n",
       "      <td>5.398300e+07</td>\n",
       "      <td>26.655533</td>\n",
       "      <td>25.624407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a17cb368eadced8f</td>\n",
       "      <td>DATA</td>\n",
       "      <td>nation</td>\n",
       "      <td>n_name</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>36320</td>\n",
       "      <td>TableScan Impl: ColumnVsValue n_name = 'ETHIOPIA'</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1452.800000</td>\n",
       "      <td>36320.000000</td>\n",
       "      <td>9.520925e+07</td>\n",
       "      <td>-9.517293e+07</td>\n",
       "      <td>15.148477</td>\n",
       "      <td>26.504598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bfb403aee0d212a</td>\n",
       "      <td>DATA</td>\n",
       "      <td>orders</td>\n",
       "      <td>o_orderstatus</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>109730123</td>\n",
       "      <td>TableScan Impl: ColumnVsValue o_orderstatus = 'F'</td>\n",
       "      <td>15000000</td>\n",
       "      <td>7309184</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7339920</td>\n",
       "      <td>0.487279</td>\n",
       "      <td>7.315342</td>\n",
       "      <td>15.012637</td>\n",
       "      <td>5.369402e+07</td>\n",
       "      <td>5.603610e+07</td>\n",
       "      <td>26.709384</td>\n",
       "      <td>25.678258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bfb403aee0d212a</td>\n",
       "      <td>DATA</td>\n",
       "      <td>nation</td>\n",
       "      <td>n_name</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>34154</td>\n",
       "      <td>TableScan Impl: ColumnVsValue n_name = 'CANADA'</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1366.160000</td>\n",
       "      <td>34154.000000</td>\n",
       "      <td>8.953130e+07</td>\n",
       "      <td>-8.949714e+07</td>\n",
       "      <td>15.059767</td>\n",
       "      <td>26.415889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98aa70b345defa5b</td>\n",
       "      <td>DATA</td>\n",
       "      <td>part</td>\n",
       "      <td>p_name</td>\n",
       "      <td>2000000</td>\n",
       "      <td>21569</td>\n",
       "      <td>4155194</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_name BETWEEN U...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>21569</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>2.077597</td>\n",
       "      <td>192.646576</td>\n",
       "      <td>1.361553e+05</td>\n",
       "      <td>4.019039e+06</td>\n",
       "      <td>21.986484</td>\n",
       "      <td>17.054904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>445e33c234f835dc</td>\n",
       "      <td>DATA</td>\n",
       "      <td>part</td>\n",
       "      <td>p_name</td>\n",
       "      <td>2000000</td>\n",
       "      <td>21871</td>\n",
       "      <td>3405469</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_name BETWEEN U...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>21871</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>1.702735</td>\n",
       "      <td>155.707055</td>\n",
       "      <td>1.115887e+05</td>\n",
       "      <td>3.293880e+06</td>\n",
       "      <td>21.699422</td>\n",
       "      <td>16.767844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b6e90b19f6849df0</td>\n",
       "      <td>DATA</td>\n",
       "      <td>region</td>\n",
       "      <td>r_name</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30593</td>\n",
       "      <td>TableScan Impl: ColumnVsValue r_name = 'AFRICA'</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6118.600000</td>\n",
       "      <td>30593.000000</td>\n",
       "      <td>4.009825e+08</td>\n",
       "      <td>-4.009519e+08</td>\n",
       "      <td>14.900914</td>\n",
       "      <td>28.578964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b6e90b19f6849df0</td>\n",
       "      <td>DATA</td>\n",
       "      <td>part</td>\n",
       "      <td>p_type</td>\n",
       "      <td>2000000</td>\n",
       "      <td>13225</td>\n",
       "      <td>2814924</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_type = 'STANDA...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>13225</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>1.407462</td>\n",
       "      <td>212.848696</td>\n",
       "      <td>9.223802e+04</td>\n",
       "      <td>2.722686e+06</td>\n",
       "      <td>21.424665</td>\n",
       "      <td>16.493090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39db4fdfc7ced3a8</td>\n",
       "      <td>DATA</td>\n",
       "      <td>orders</td>\n",
       "      <td>o_orderdate</td>\n",
       "      <td>15000000</td>\n",
       "      <td>575136</td>\n",
       "      <td>30926023</td>\n",
       "      <td>TableScan Impl: ColumnBetween o_orderdate BETW...</td>\n",
       "      <td>15000000</td>\n",
       "      <td>575136</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>589815</td>\n",
       "      <td>0.038342</td>\n",
       "      <td>2.061735</td>\n",
       "      <td>53.771670</td>\n",
       "      <td>1.216042e+06</td>\n",
       "      <td>2.970998e+07</td>\n",
       "      <td>24.882318</td>\n",
       "      <td>20.213763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2339c1c426815457</td>\n",
       "      <td>DATA</td>\n",
       "      <td>part</td>\n",
       "      <td>p_name</td>\n",
       "      <td>2000000</td>\n",
       "      <td>22047</td>\n",
       "      <td>3623248</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_name BETWEEN U...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>22047</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>1.811624</td>\n",
       "      <td>164.341997</td>\n",
       "      <td>1.187248e+05</td>\n",
       "      <td>3.504523e+06</td>\n",
       "      <td>21.788852</td>\n",
       "      <td>16.857274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2339c1c426815457</td>\n",
       "      <td>DATA</td>\n",
       "      <td>nation</td>\n",
       "      <td>n_name</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>46307</td>\n",
       "      <td>TableScan Impl: ColumnVsValue n_name = 'IRAQ'</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1852.280000</td>\n",
       "      <td>46307.000000</td>\n",
       "      <td>1.213892e+08</td>\n",
       "      <td>-1.213429e+08</td>\n",
       "      <td>15.498943</td>\n",
       "      <td>26.855064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7892b628f929217a</td>\n",
       "      <td>DATA</td>\n",
       "      <td>part</td>\n",
       "      <td>p_name</td>\n",
       "      <td>2000000</td>\n",
       "      <td>108577</td>\n",
       "      <td>121198168</td>\n",
       "      <td>TableScan Impl: ColumnLike p_name LIKE '%lace%'</td>\n",
       "      <td>2000000</td>\n",
       "      <td>108577</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.054289</td>\n",
       "      <td>60.599084</td>\n",
       "      <td>1116.241635</td>\n",
       "      <td>7.942722e+06</td>\n",
       "      <td>1.132554e+08</td>\n",
       "      <td>26.852793</td>\n",
       "      <td>22.921202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5ae3617d2dec126b</td>\n",
       "      <td>DATA</td>\n",
       "      <td>orders</td>\n",
       "      <td>o_orderdate</td>\n",
       "      <td>15000000</td>\n",
       "      <td>573330</td>\n",
       "      <td>30675417</td>\n",
       "      <td>TableScan Impl: ColumnBetween o_orderdate BETW...</td>\n",
       "      <td>15000000</td>\n",
       "      <td>573330</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>589815</td>\n",
       "      <td>0.038222</td>\n",
       "      <td>2.045028</td>\n",
       "      <td>53.503945</td>\n",
       "      <td>1.206188e+06</td>\n",
       "      <td>2.946923e+07</td>\n",
       "      <td>24.870580</td>\n",
       "      <td>20.202025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>eb783ae587a58416</td>\n",
       "      <td>DATA</td>\n",
       "      <td>part</td>\n",
       "      <td>p_name</td>\n",
       "      <td>2000000</td>\n",
       "      <td>108590</td>\n",
       "      <td>104152102</td>\n",
       "      <td>TableScan Impl: ColumnLike p_name LIKE '%beige%'</td>\n",
       "      <td>2000000</td>\n",
       "      <td>108590</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.054295</td>\n",
       "      <td>52.076051</td>\n",
       "      <td>959.131614</td>\n",
       "      <td>6.825608e+06</td>\n",
       "      <td>9.732649e+07</td>\n",
       "      <td>26.634117</td>\n",
       "      <td>22.702526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4cc582ea095e45e9</td>\n",
       "      <td>DATA</td>\n",
       "      <td>nation</td>\n",
       "      <td>n_name</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>24865</td>\n",
       "      <td>TableScan Impl: ColumnVsValue n_name = 'UNITED...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>994.600000</td>\n",
       "      <td>24865.000000</td>\n",
       "      <td>6.518111e+07</td>\n",
       "      <td>-6.515625e+07</td>\n",
       "      <td>14.601829</td>\n",
       "      <td>25.957951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>8dc3fd52eb6d3c3d</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>80123</td>\n",
       "      <td>4225738</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>80123</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.040061</td>\n",
       "      <td>2.112869</td>\n",
       "      <td>52.740636</td>\n",
       "      <td>2.769337e+05</td>\n",
       "      <td>3.948804e+06</td>\n",
       "      <td>22.010772</td>\n",
       "      <td>18.079187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>8dc3fd52eb6d3c3d</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>8159</td>\n",
       "      <td>1578</td>\n",
       "      <td>267160</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_size BETWEEN I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>399409</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.199705</td>\n",
       "      <td>32.744209</td>\n",
       "      <td>169.302915</td>\n",
       "      <td>2.145892e+06</td>\n",
       "      <td>-1.878732e+06</td>\n",
       "      <td>18.027344</td>\n",
       "      <td>21.033147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>8dc3fd52eb6d3c3d</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_container</td>\n",
       "      <td>79959</td>\n",
       "      <td>8159</td>\n",
       "      <td>8482348</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_contain...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>200893</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>106.083718</td>\n",
       "      <td>1039.630837</td>\n",
       "      <td>6.952196e+06</td>\n",
       "      <td>1.530152e+06</td>\n",
       "      <td>23.016032</td>\n",
       "      <td>22.729038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>8dc3fd52eb6d3c3d</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79959</td>\n",
       "      <td>3985259</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79959</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.039980</td>\n",
       "      <td>1.992630</td>\n",
       "      <td>49.841281</td>\n",
       "      <td>2.611739e+05</td>\n",
       "      <td>3.724085e+06</td>\n",
       "      <td>21.926242</td>\n",
       "      <td>17.994657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>8dc3fd52eb6d3c3d</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>7876</td>\n",
       "      <td>2325</td>\n",
       "      <td>274005</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_size BETWEEN I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>598661</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.299330</td>\n",
       "      <td>34.789868</td>\n",
       "      <td>117.851613</td>\n",
       "      <td>2.279954e+06</td>\n",
       "      <td>-2.005949e+06</td>\n",
       "      <td>18.063843</td>\n",
       "      <td>21.120574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>8dc3fd52eb6d3c3d</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_container</td>\n",
       "      <td>79669</td>\n",
       "      <td>7876</td>\n",
       "      <td>8220985</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_contain...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>200116</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.100058</td>\n",
       "      <td>103.189258</td>\n",
       "      <td>1043.802057</td>\n",
       "      <td>6.762508e+06</td>\n",
       "      <td>1.458477e+06</td>\n",
       "      <td>22.970880</td>\n",
       "      <td>22.689127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>8dc3fd52eb6d3c3d</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79669</td>\n",
       "      <td>3959277</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79669</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.039835</td>\n",
       "      <td>1.979639</td>\n",
       "      <td>49.696582</td>\n",
       "      <td>2.594712e+05</td>\n",
       "      <td>3.699806e+06</td>\n",
       "      <td>21.916806</td>\n",
       "      <td>17.985221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>7909</td>\n",
       "      <td>754</td>\n",
       "      <td>272328</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_size BETWEEN I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>199678</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>34.432672</td>\n",
       "      <td>361.177719</td>\n",
       "      <td>2.256545e+06</td>\n",
       "      <td>-1.984217e+06</td>\n",
       "      <td>18.054986</td>\n",
       "      <td>21.105685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_container</td>\n",
       "      <td>80170</td>\n",
       "      <td>7909</td>\n",
       "      <td>8818655</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_contain...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>199475</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.099738</td>\n",
       "      <td>109.999439</td>\n",
       "      <td>1115.015173</td>\n",
       "      <td>7.208813e+06</td>\n",
       "      <td>1.609842e+06</td>\n",
       "      <td>23.072127</td>\n",
       "      <td>22.781331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>80170</td>\n",
       "      <td>4230767</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>80170</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.040085</td>\n",
       "      <td>2.115384</td>\n",
       "      <td>52.772446</td>\n",
       "      <td>2.772633e+05</td>\n",
       "      <td>3.953504e+06</td>\n",
       "      <td>22.012488</td>\n",
       "      <td>18.080902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>8100</td>\n",
       "      <td>1683</td>\n",
       "      <td>273935</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_size BETWEEN I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>399409</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.199705</td>\n",
       "      <td>33.819136</td>\n",
       "      <td>162.765894</td>\n",
       "      <td>2.216337e+06</td>\n",
       "      <td>-1.942402e+06</td>\n",
       "      <td>18.063474</td>\n",
       "      <td>21.079747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_container</td>\n",
       "      <td>79878</td>\n",
       "      <td>8100</td>\n",
       "      <td>8518039</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_contain...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>200893</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>106.638111</td>\n",
       "      <td>1051.609753</td>\n",
       "      <td>6.988529e+06</td>\n",
       "      <td>1.529510e+06</td>\n",
       "      <td>23.022090</td>\n",
       "      <td>22.736558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79878</td>\n",
       "      <td>3967379</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79878</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>1.983690</td>\n",
       "      <td>49.667981</td>\n",
       "      <td>2.600022e+05</td>\n",
       "      <td>3.707377e+06</td>\n",
       "      <td>21.919755</td>\n",
       "      <td>17.988170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>7945</td>\n",
       "      <td>2424</td>\n",
       "      <td>294190</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_size BETWEEN I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>598661</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.299330</td>\n",
       "      <td>37.028320</td>\n",
       "      <td>121.365512</td>\n",
       "      <td>2.426651e+06</td>\n",
       "      <td>-2.132461e+06</td>\n",
       "      <td>18.166389</td>\n",
       "      <td>21.210536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_container</td>\n",
       "      <td>80260</td>\n",
       "      <td>7945</td>\n",
       "      <td>8346847</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_contain...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>200116</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.100058</td>\n",
       "      <td>103.997595</td>\n",
       "      <td>1050.578603</td>\n",
       "      <td>6.815482e+06</td>\n",
       "      <td>1.531365e+06</td>\n",
       "      <td>22.992800</td>\n",
       "      <td>22.700385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>65e8223a5ee91fb8</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>80260</td>\n",
       "      <td>3964026</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>80260</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.040130</td>\n",
       "      <td>1.982013</td>\n",
       "      <td>49.389808</td>\n",
       "      <td>2.597824e+05</td>\n",
       "      <td>3.704244e+06</td>\n",
       "      <td>21.918535</td>\n",
       "      <td>17.986950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>a61d21fbe175bdf5</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>1855440</td>\n",
       "      <td>297275</td>\n",
       "      <td>62462499</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_size) I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>320131</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>327675</td>\n",
       "      <td>0.160065</td>\n",
       "      <td>33.664521</td>\n",
       "      <td>210.116892</td>\n",
       "      <td>1.103102e+07</td>\n",
       "      <td>5.143148e+07</td>\n",
       "      <td>25.896487</td>\n",
       "      <td>23.395063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>a61d21fbe175bdf5</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_type</td>\n",
       "      <td>1919492</td>\n",
       "      <td>1152634</td>\n",
       "      <td>20819553</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_type &lt; 'PROMO ...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>1200947</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1179630</td>\n",
       "      <td>0.600473</td>\n",
       "      <td>10.846387</td>\n",
       "      <td>18.062588</td>\n",
       "      <td>1.279472e+07</td>\n",
       "      <td>8.024830e+06</td>\n",
       "      <td>24.311436</td>\n",
       "      <td>23.609046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>a61d21fbe175bdf5</td>\n",
       "      <td>DATA</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>1919492</td>\n",
       "      <td>10727190</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand != 'Bran...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>1919492</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1966050</td>\n",
       "      <td>0.959746</td>\n",
       "      <td>5.363595</td>\n",
       "      <td>5.588557</td>\n",
       "      <td>1.054510e+07</td>\n",
       "      <td>1.820941e+05</td>\n",
       "      <td>23.354769</td>\n",
       "      <td>23.330069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>a61d21fbe175bdf5</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_type</td>\n",
       "      <td>1919492</td>\n",
       "      <td>702806</td>\n",
       "      <td>17631234</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_type &gt;= 'PROMO...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>732351</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>720885</td>\n",
       "      <td>0.366175</td>\n",
       "      <td>9.185365</td>\n",
       "      <td>25.086914</td>\n",
       "      <td>6.621592e+06</td>\n",
       "      <td>1.100964e+07</td>\n",
       "      <td>24.071630</td>\n",
       "      <td>22.658747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>a61d21fbe175bdf5</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>supplier</td>\n",
       "      <td>s_comment</td>\n",
       "      <td>100000</td>\n",
       "      <td>56</td>\n",
       "      <td>6084054</td>\n",
       "      <td>TableScan Impl: ColumnLike s_comment LIKE '%Cu...</td>\n",
       "      <td>100000</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>60.840540</td>\n",
       "      <td>108643.821429</td>\n",
       "      <td>3.987185e+06</td>\n",
       "      <td>2.096869e+06</td>\n",
       "      <td>22.536602</td>\n",
       "      <td>21.926939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>8078</td>\n",
       "      <td>826</td>\n",
       "      <td>289162</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_size BETWEEN I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>199678</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>35.796237</td>\n",
       "      <td>350.075061</td>\n",
       "      <td>2.345906e+06</td>\n",
       "      <td>-2.056744e+06</td>\n",
       "      <td>18.141518</td>\n",
       "      <td>21.161715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_container</td>\n",
       "      <td>80013</td>\n",
       "      <td>8078</td>\n",
       "      <td>9486520</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_contain...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>199475</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.099738</td>\n",
       "      <td>118.562234</td>\n",
       "      <td>1174.364942</td>\n",
       "      <td>7.769976e+06</td>\n",
       "      <td>1.716544e+06</td>\n",
       "      <td>23.177448</td>\n",
       "      <td>22.889479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>80013</td>\n",
       "      <td>4177684</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>80013</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.040007</td>\n",
       "      <td>2.088842</td>\n",
       "      <td>52.212565</td>\n",
       "      <td>2.737845e+05</td>\n",
       "      <td>3.903899e+06</td>\n",
       "      <td>21.994272</td>\n",
       "      <td>18.062687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>8135</td>\n",
       "      <td>1618</td>\n",
       "      <td>272119</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_size BETWEEN I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>399409</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.199705</td>\n",
       "      <td>33.450400</td>\n",
       "      <td>168.182324</td>\n",
       "      <td>2.192172e+06</td>\n",
       "      <td>-1.920053e+06</td>\n",
       "      <td>18.053878</td>\n",
       "      <td>21.063930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_container</td>\n",
       "      <td>79721</td>\n",
       "      <td>8135</td>\n",
       "      <td>8501834</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_contain...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>200893</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>106.644849</td>\n",
       "      <td>1045.093301</td>\n",
       "      <td>6.988970e+06</td>\n",
       "      <td>1.512864e+06</td>\n",
       "      <td>23.019343</td>\n",
       "      <td>22.736649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79721</td>\n",
       "      <td>3948101</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79721</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.039861</td>\n",
       "      <td>1.974050</td>\n",
       "      <td>49.523977</td>\n",
       "      <td>2.587388e+05</td>\n",
       "      <td>3.689362e+06</td>\n",
       "      <td>21.912727</td>\n",
       "      <td>17.981142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_size</td>\n",
       "      <td>8051</td>\n",
       "      <td>2385</td>\n",
       "      <td>277148</td>\n",
       "      <td>TableScan Impl: ColumnBetween p_size BETWEEN I...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>598661</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.299330</td>\n",
       "      <td>34.424047</td>\n",
       "      <td>116.204612</td>\n",
       "      <td>2.255980e+06</td>\n",
       "      <td>-1.978832e+06</td>\n",
       "      <td>18.080297</td>\n",
       "      <td>21.105323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_container</td>\n",
       "      <td>79878</td>\n",
       "      <td>8051</td>\n",
       "      <td>8227830</td>\n",
       "      <td>TableScan Impl: ExpressionEvaluator (p_contain...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>200116</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65535</td>\n",
       "      <td>0.100058</td>\n",
       "      <td>103.004958</td>\n",
       "      <td>1021.963731</td>\n",
       "      <td>6.750430e+06</td>\n",
       "      <td>1.477400e+06</td>\n",
       "      <td>22.972081</td>\n",
       "      <td>22.686548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>af04794535660bfb</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>part</td>\n",
       "      <td>p_brand</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79878</td>\n",
       "      <td>3958997</td>\n",
       "      <td>TableScan Impl: ColumnVsValue p_brand = 'Brand...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>79878</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>131070</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>1.979499</td>\n",
       "      <td>49.563046</td>\n",
       "      <td>2.594529e+05</td>\n",
       "      <td>3.699544e+06</td>\n",
       "      <td>21.916704</td>\n",
       "      <td>17.985119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           QUERY_HASH COLUMN_TYPE TABLE_NAME    COLUMN_NAME  INPUT_ROWS  \\\n",
       "0     bac00c0bdbf62ea   REFERENCE   customer        c_phone      681435   \n",
       "1    2687bf4da454552b   REFERENCE   customer        c_phone      681352   \n",
       "2    2bd757c748d34189   REFERENCE   customer        c_phone      681223   \n",
       "3    7ce8aa4cc8eabfd8   REFERENCE   customer        c_phone      680683   \n",
       "4    3bf533ddc6f54ed4   REFERENCE   customer        c_phone      680526   \n",
       "5    74335a369db42f54   REFERENCE   customer        c_phone      682247   \n",
       "6    aeebd3c094273d3e   REFERENCE   customer        c_phone      681571   \n",
       "7    6730c267d3eac48a        DATA     orders  o_orderstatus    15000000   \n",
       "8    6730c267d3eac48a        DATA     nation         n_name          25   \n",
       "9    6ec3126b032024be        DATA     orders  o_orderstatus    15000000   \n",
       "10   6ec3126b032024be        DATA     nation         n_name          25   \n",
       "11   7324393c05ab5301        DATA     orders  o_orderstatus    15000000   \n",
       "12   7324393c05ab5301        DATA     nation         n_name          25   \n",
       "13   37e2ba0a1c4e865f        DATA     orders  o_orderstatus    15000000   \n",
       "14   37e2ba0a1c4e865f        DATA     nation         n_name          25   \n",
       "15   a17cb368eadced8f        DATA     orders  o_orderstatus    15000000   \n",
       "16   a17cb368eadced8f        DATA     nation         n_name          25   \n",
       "17    bfb403aee0d212a        DATA     orders  o_orderstatus    15000000   \n",
       "18    bfb403aee0d212a        DATA     nation         n_name          25   \n",
       "19   98aa70b345defa5b        DATA       part         p_name     2000000   \n",
       "20   445e33c234f835dc        DATA       part         p_name     2000000   \n",
       "21   b6e90b19f6849df0        DATA     region         r_name           5   \n",
       "22   b6e90b19f6849df0        DATA       part         p_type     2000000   \n",
       "23   39db4fdfc7ced3a8        DATA     orders    o_orderdate    15000000   \n",
       "24   2339c1c426815457        DATA       part         p_name     2000000   \n",
       "25   2339c1c426815457        DATA     nation         n_name          25   \n",
       "26   7892b628f929217a        DATA       part         p_name     2000000   \n",
       "27   5ae3617d2dec126b        DATA     orders    o_orderdate    15000000   \n",
       "28   eb783ae587a58416        DATA       part         p_name     2000000   \n",
       "29   4cc582ea095e45e9        DATA     nation         n_name          25   \n",
       "..                ...         ...        ...            ...         ...   \n",
       "405  8dc3fd52eb6d3c3d   REFERENCE       part        p_brand     2000000   \n",
       "406  8dc3fd52eb6d3c3d   REFERENCE       part         p_size        8159   \n",
       "407  8dc3fd52eb6d3c3d   REFERENCE       part    p_container       79959   \n",
       "408  8dc3fd52eb6d3c3d   REFERENCE       part        p_brand     2000000   \n",
       "409  8dc3fd52eb6d3c3d   REFERENCE       part         p_size        7876   \n",
       "410  8dc3fd52eb6d3c3d   REFERENCE       part    p_container       79669   \n",
       "411  8dc3fd52eb6d3c3d   REFERENCE       part        p_brand     2000000   \n",
       "412  65e8223a5ee91fb8   REFERENCE       part         p_size        7909   \n",
       "413  65e8223a5ee91fb8   REFERENCE       part    p_container       80170   \n",
       "414  65e8223a5ee91fb8   REFERENCE       part        p_brand     2000000   \n",
       "415  65e8223a5ee91fb8   REFERENCE       part         p_size        8100   \n",
       "416  65e8223a5ee91fb8   REFERENCE       part    p_container       79878   \n",
       "417  65e8223a5ee91fb8   REFERENCE       part        p_brand     2000000   \n",
       "418  65e8223a5ee91fb8   REFERENCE       part         p_size        7945   \n",
       "419  65e8223a5ee91fb8   REFERENCE       part    p_container       80260   \n",
       "420  65e8223a5ee91fb8   REFERENCE       part        p_brand     2000000   \n",
       "421  a61d21fbe175bdf5   REFERENCE       part         p_size     1855440   \n",
       "422  a61d21fbe175bdf5   REFERENCE       part         p_type     1919492   \n",
       "423  a61d21fbe175bdf5        DATA       part        p_brand     2000000   \n",
       "424  a61d21fbe175bdf5   REFERENCE       part         p_type     1919492   \n",
       "425  a61d21fbe175bdf5   REFERENCE   supplier      s_comment      100000   \n",
       "426  af04794535660bfb   REFERENCE       part         p_size        8078   \n",
       "427  af04794535660bfb   REFERENCE       part    p_container       80013   \n",
       "428  af04794535660bfb   REFERENCE       part        p_brand     2000000   \n",
       "429  af04794535660bfb   REFERENCE       part         p_size        8135   \n",
       "430  af04794535660bfb   REFERENCE       part    p_container       79721   \n",
       "431  af04794535660bfb   REFERENCE       part        p_brand     2000000   \n",
       "432  af04794535660bfb   REFERENCE       part         p_size        8051   \n",
       "433  af04794535660bfb   REFERENCE       part    p_container       79878   \n",
       "434  af04794535660bfb   REFERENCE       part        p_brand     2000000   \n",
       "\n",
       "     OUTPUT_ROWS  RUNTIME_NS  \\\n",
       "0         190499   182312504   \n",
       "1         190434   184210492   \n",
       "2         190942   186800722   \n",
       "3         190698   183656825   \n",
       "4         190820   183580973   \n",
       "5         190532   183523699   \n",
       "6         190524   182585251   \n",
       "7        7309184    88478994   \n",
       "8              1       36669   \n",
       "9        7309184    89032941   \n",
       "10             1       35622   \n",
       "11       7309184    93872414   \n",
       "12             1       36879   \n",
       "13       7309184   125510444   \n",
       "14             1       37577   \n",
       "15       7309184   105709732   \n",
       "16             1       36320   \n",
       "17       7309184   109730123   \n",
       "18             1       34154   \n",
       "19         21569     4155194   \n",
       "20         21871     3405469   \n",
       "21             1       30593   \n",
       "22         13225     2814924   \n",
       "23        575136    30926023   \n",
       "24         22047     3623248   \n",
       "25             1       46307   \n",
       "26        108577   121198168   \n",
       "27        573330    30675417   \n",
       "28        108590   104152102   \n",
       "29             1       24865   \n",
       "..           ...         ...   \n",
       "405        80123     4225738   \n",
       "406         1578      267160   \n",
       "407         8159     8482348   \n",
       "408        79959     3985259   \n",
       "409         2325      274005   \n",
       "410         7876     8220985   \n",
       "411        79669     3959277   \n",
       "412          754      272328   \n",
       "413         7909     8818655   \n",
       "414        80170     4230767   \n",
       "415         1683      273935   \n",
       "416         8100     8518039   \n",
       "417        79878     3967379   \n",
       "418         2424      294190   \n",
       "419         7945     8346847   \n",
       "420        80260     3964026   \n",
       "421       297275    62462499   \n",
       "422      1152634    20819553   \n",
       "423      1919492    10727190   \n",
       "424       702806    17631234   \n",
       "425           56     6084054   \n",
       "426          826      289162   \n",
       "427         8078     9486520   \n",
       "428        80013     4177684   \n",
       "429         1618      272119   \n",
       "430         8135     8501834   \n",
       "431        79721     3948101   \n",
       "432         2385      277148   \n",
       "433         8051     8227830   \n",
       "434        79878     3958997   \n",
       "\n",
       "                                           DESCRIPTION  SINGLE_INPUT_ROWS  \\\n",
       "0    TableScan Impl: ExpressionEvaluator (SUBSTR(c_...            1500000   \n",
       "1    TableScan Impl: ExpressionEvaluator (SUBSTR(c_...            1500000   \n",
       "2    TableScan Impl: ExpressionEvaluator (SUBSTR(c_...            1500000   \n",
       "3    TableScan Impl: ExpressionEvaluator (SUBSTR(c_...            1500000   \n",
       "4    TableScan Impl: ExpressionEvaluator (SUBSTR(c_...            1500000   \n",
       "5    TableScan Impl: ExpressionEvaluator (SUBSTR(c_...            1500000   \n",
       "6    TableScan Impl: ExpressionEvaluator (SUBSTR(c_...            1500000   \n",
       "7    TableScan Impl: ColumnVsValue o_orderstatus = 'F'           15000000   \n",
       "8        TableScan Impl: ColumnVsValue n_name = 'IRAN'                 25   \n",
       "9    TableScan Impl: ColumnVsValue o_orderstatus = 'F'           15000000   \n",
       "10    TableScan Impl: ColumnVsValue n_name = 'VIETNAM'                 25   \n",
       "11   TableScan Impl: ColumnVsValue o_orderstatus = 'F'           15000000   \n",
       "12      TableScan Impl: ColumnVsValue n_name = 'KENYA'                 25   \n",
       "13   TableScan Impl: ColumnVsValue o_orderstatus = 'F'           15000000   \n",
       "14      TableScan Impl: ColumnVsValue n_name = 'EGYPT'                 25   \n",
       "15   TableScan Impl: ColumnVsValue o_orderstatus = 'F'           15000000   \n",
       "16   TableScan Impl: ColumnVsValue n_name = 'ETHIOPIA'                 25   \n",
       "17   TableScan Impl: ColumnVsValue o_orderstatus = 'F'           15000000   \n",
       "18     TableScan Impl: ColumnVsValue n_name = 'CANADA'                 25   \n",
       "19   TableScan Impl: ColumnBetween p_name BETWEEN U...            2000000   \n",
       "20   TableScan Impl: ColumnBetween p_name BETWEEN U...            2000000   \n",
       "21     TableScan Impl: ColumnVsValue r_name = 'AFRICA'                  5   \n",
       "22   TableScan Impl: ColumnVsValue p_type = 'STANDA...            2000000   \n",
       "23   TableScan Impl: ColumnBetween o_orderdate BETW...           15000000   \n",
       "24   TableScan Impl: ColumnBetween p_name BETWEEN U...            2000000   \n",
       "25       TableScan Impl: ColumnVsValue n_name = 'IRAQ'                 25   \n",
       "26     TableScan Impl: ColumnLike p_name LIKE '%lace%'            2000000   \n",
       "27   TableScan Impl: ColumnBetween o_orderdate BETW...           15000000   \n",
       "28    TableScan Impl: ColumnLike p_name LIKE '%beige%'            2000000   \n",
       "29   TableScan Impl: ColumnVsValue n_name = 'UNITED...                 25   \n",
       "..                                                 ...                ...   \n",
       "405  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "406  TableScan Impl: ColumnBetween p_size BETWEEN I...            2000000   \n",
       "407  TableScan Impl: ExpressionEvaluator (p_contain...            2000000   \n",
       "408  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "409  TableScan Impl: ColumnBetween p_size BETWEEN I...            2000000   \n",
       "410  TableScan Impl: ExpressionEvaluator (p_contain...            2000000   \n",
       "411  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "412  TableScan Impl: ColumnBetween p_size BETWEEN I...            2000000   \n",
       "413  TableScan Impl: ExpressionEvaluator (p_contain...            2000000   \n",
       "414  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "415  TableScan Impl: ColumnBetween p_size BETWEEN I...            2000000   \n",
       "416  TableScan Impl: ExpressionEvaluator (p_contain...            2000000   \n",
       "417  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "418  TableScan Impl: ColumnBetween p_size BETWEEN I...            2000000   \n",
       "419  TableScan Impl: ExpressionEvaluator (p_contain...            2000000   \n",
       "420  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "421  TableScan Impl: ExpressionEvaluator (p_size) I...            2000000   \n",
       "422  TableScan Impl: ColumnVsValue p_type < 'PROMO ...            2000000   \n",
       "423  TableScan Impl: ColumnVsValue p_brand != 'Bran...            2000000   \n",
       "424  TableScan Impl: ColumnVsValue p_type >= 'PROMO...            2000000   \n",
       "425  TableScan Impl: ColumnLike s_comment LIKE '%Cu...             100000   \n",
       "426  TableScan Impl: ColumnBetween p_size BETWEEN I...            2000000   \n",
       "427  TableScan Impl: ExpressionEvaluator (p_contain...            2000000   \n",
       "428  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "429  TableScan Impl: ColumnBetween p_size BETWEEN I...            2000000   \n",
       "430  TableScan Impl: ExpressionEvaluator (p_contain...            2000000   \n",
       "431  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "432  TableScan Impl: ColumnBetween p_size BETWEEN I...            2000000   \n",
       "433  TableScan Impl: ExpressionEvaluator (p_contain...            2000000   \n",
       "434  TableScan Impl: ColumnVsValue p_brand = 'Brand...            2000000   \n",
       "\n",
       "     SINGLE_OUTPUT_ROWS  ...  benefits_from_sorting useful_for_pruning  \\\n",
       "0                419123  ...                  False              False   \n",
       "1                419793  ...                  False              False   \n",
       "2                419992  ...                  False              False   \n",
       "3                419626  ...                  False              False   \n",
       "4                420284  ...                  False              False   \n",
       "5                419794  ...                  False              False   \n",
       "6                420242  ...                  False              False   \n",
       "7               7309184  ...                   True               True   \n",
       "8                     1  ...                   True               True   \n",
       "9               7309184  ...                   True               True   \n",
       "10                    1  ...                   True               True   \n",
       "11              7309184  ...                   True               True   \n",
       "12                    1  ...                   True               True   \n",
       "13              7309184  ...                   True               True   \n",
       "14                    1  ...                   True               True   \n",
       "15              7309184  ...                   True               True   \n",
       "16                    1  ...                   True               True   \n",
       "17              7309184  ...                   True               True   \n",
       "18                    1  ...                   True               True   \n",
       "19                21569  ...                   True               True   \n",
       "20                21871  ...                   True               True   \n",
       "21                    1  ...                   True               True   \n",
       "22                13225  ...                   True               True   \n",
       "23               575136  ...                   True               True   \n",
       "24                22047  ...                   True               True   \n",
       "25                    1  ...                   True               True   \n",
       "26               108577  ...                  False              False   \n",
       "27               573330  ...                   True               True   \n",
       "28               108590  ...                  False              False   \n",
       "29                    1  ...                   True               True   \n",
       "..                  ...  ...                    ...                ...   \n",
       "405               80123  ...                   True              False   \n",
       "406              399409  ...                   True              False   \n",
       "407              200893  ...                  False              False   \n",
       "408               79959  ...                   True              False   \n",
       "409              598661  ...                   True              False   \n",
       "410              200116  ...                  False              False   \n",
       "411               79669  ...                   True              False   \n",
       "412              199678  ...                   True              False   \n",
       "413              199475  ...                  False              False   \n",
       "414               80170  ...                   True              False   \n",
       "415              399409  ...                   True              False   \n",
       "416              200893  ...                  False              False   \n",
       "417               79878  ...                   True              False   \n",
       "418              598661  ...                   True              False   \n",
       "419              200116  ...                  False              False   \n",
       "420               80260  ...                   True              False   \n",
       "421              320131  ...                  False              False   \n",
       "422             1200947  ...                   True              False   \n",
       "423             1919492  ...                   True               True   \n",
       "424              732351  ...                   True              False   \n",
       "425                  56  ...                  False              False   \n",
       "426              199678  ...                   True              False   \n",
       "427              199475  ...                  False              False   \n",
       "428               80013  ...                   True              False   \n",
       "429              399409  ...                   True              False   \n",
       "430              200893  ...                  False              False   \n",
       "431               79721  ...                   True              False   \n",
       "432              598661  ...                   True              False   \n",
       "433              200116  ...                  False              False   \n",
       "434               79878  ...                   True              False   \n",
       "\n",
       "     pruned_minimum_input_rows  actual_selectivity  time_per_ir  \\\n",
       "0                       196605            0.279415   267.542031   \n",
       "1                       196605            0.279862   270.360243   \n",
       "2                       196605            0.279995   274.213763   \n",
       "3                       196605            0.279751   269.812563   \n",
       "4                       196605            0.280189   269.763349   \n",
       "5                       196605            0.279863   268.998909   \n",
       "6                       196605            0.280161   267.888820   \n",
       "7                      7339920            0.487279     5.898600   \n",
       "8                        65535            0.040000  1466.760000   \n",
       "9                      7339920            0.487279     5.935529   \n",
       "10                       65535            0.040000  1424.880000   \n",
       "11                     7339920            0.487279     6.258161   \n",
       "12                       65535            0.040000  1475.160000   \n",
       "13                     7339920            0.487279     8.367363   \n",
       "14                       65535            0.040000  1503.080000   \n",
       "15                     7339920            0.487279     7.047315   \n",
       "16                       65535            0.040000  1452.800000   \n",
       "17                     7339920            0.487279     7.315342   \n",
       "18                       65535            0.040000  1366.160000   \n",
       "19                       65535            0.010785     2.077597   \n",
       "20                       65535            0.010936     1.702735   \n",
       "21                       65535            0.200000  6118.600000   \n",
       "22                       65535            0.006613     1.407462   \n",
       "23                      589815            0.038342     2.061735   \n",
       "24                       65535            0.011024     1.811624   \n",
       "25                       65535            0.040000  1852.280000   \n",
       "26                      131070            0.054289    60.599084   \n",
       "27                      589815            0.038222     2.045028   \n",
       "28                      131070            0.054295    52.076051   \n",
       "29                       65535            0.040000   994.600000   \n",
       "..                         ...                 ...          ...   \n",
       "405                     131070            0.040061     2.112869   \n",
       "406                      65535            0.199705    32.744209   \n",
       "407                      65535            0.100446   106.083718   \n",
       "408                     131070            0.039980     1.992630   \n",
       "409                      65535            0.299330    34.789868   \n",
       "410                      65535            0.100058   103.189258   \n",
       "411                     131070            0.039835     1.979639   \n",
       "412                      65535            0.099839    34.432672   \n",
       "413                      65535            0.099738   109.999439   \n",
       "414                     131070            0.040085     2.115384   \n",
       "415                      65535            0.199705    33.819136   \n",
       "416                      65535            0.100446   106.638111   \n",
       "417                     131070            0.039939     1.983690   \n",
       "418                      65535            0.299330    37.028320   \n",
       "419                      65535            0.100058   103.997595   \n",
       "420                     131070            0.040130     1.982013   \n",
       "421                     327675            0.160065    33.664521   \n",
       "422                    1179630            0.600473    10.846387   \n",
       "423                    1966050            0.959746     5.363595   \n",
       "424                     720885            0.366175     9.185365   \n",
       "425                      65535            0.000560    60.840540   \n",
       "426                      65535            0.099839    35.796237   \n",
       "427                      65535            0.099738   118.562234   \n",
       "428                     131070            0.040007     2.088842   \n",
       "429                      65535            0.199705    33.450400   \n",
       "430                      65535            0.100446   106.644849   \n",
       "431                     131070            0.039861     1.974050   \n",
       "432                      65535            0.299330    34.424047   \n",
       "433                      65535            0.100058   103.004958   \n",
       "434                     131070            0.039939     1.979499   \n",
       "\n",
       "       time_per_or  optimal_runtime  runtime_gain  log_runtime  \\\n",
       "0       957.026042     5.260010e+07  1.297124e+08    27.441838   \n",
       "1       967.319344     5.315418e+07  1.310563e+08    27.456780   \n",
       "2       978.311330     5.391180e+07  1.328889e+08    27.476925   \n",
       "3       963.076828     5.304650e+07  1.306103e+08    27.452437   \n",
       "4       962.063583     5.303682e+07  1.305441e+08    27.451841   \n",
       "5       963.217197     5.288653e+07  1.306372e+08    27.451391   \n",
       "6       958.332026     5.266828e+07  1.299170e+08    27.443995   \n",
       "7        12.105181     4.329525e+07  4.518374e+07    26.398832   \n",
       "8     36669.000000     9.612412e+07 -9.608745e+07    15.162273   \n",
       "9        12.180969     4.356631e+07  4.546663e+07    26.407836   \n",
       "10    35622.000000     9.337951e+07 -9.334389e+07    15.120481   \n",
       "11       12.843077     4.593440e+07  4.793801e+07    26.484198   \n",
       "12    36879.000000     9.667461e+07 -9.663773e+07    15.170512   \n",
       "13       17.171608     6.141577e+07  6.409467e+07    26.903232   \n",
       "14    37577.000000     9.850435e+07 -9.846677e+07    15.197562   \n",
       "15       14.462590     5.172673e+07  5.398300e+07    26.655533   \n",
       "16    36320.000000     9.520925e+07 -9.517293e+07    15.148477   \n",
       "17       15.012637     5.369402e+07  5.603610e+07    26.709384   \n",
       "18    34154.000000     8.953130e+07 -8.949714e+07    15.059767   \n",
       "19      192.646576     1.361553e+05  4.019039e+06    21.986484   \n",
       "20      155.707055     1.115887e+05  3.293880e+06    21.699422   \n",
       "21    30593.000000     4.009825e+08 -4.009519e+08    14.900914   \n",
       "22      212.848696     9.223802e+04  2.722686e+06    21.424665   \n",
       "23       53.771670     1.216042e+06  2.970998e+07    24.882318   \n",
       "24      164.341997     1.187248e+05  3.504523e+06    21.788852   \n",
       "25    46307.000000     1.213892e+08 -1.213429e+08    15.498943   \n",
       "26     1116.241635     7.942722e+06  1.132554e+08    26.852793   \n",
       "27       53.503945     1.206188e+06  2.946923e+07    24.870580   \n",
       "28      959.131614     6.825608e+06  9.732649e+07    26.634117   \n",
       "29    24865.000000     6.518111e+07 -6.515625e+07    14.601829   \n",
       "..             ...              ...           ...          ...   \n",
       "405      52.740636     2.769337e+05  3.948804e+06    22.010772   \n",
       "406     169.302915     2.145892e+06 -1.878732e+06    18.027344   \n",
       "407    1039.630837     6.952196e+06  1.530152e+06    23.016032   \n",
       "408      49.841281     2.611739e+05  3.724085e+06    21.926242   \n",
       "409     117.851613     2.279954e+06 -2.005949e+06    18.063843   \n",
       "410    1043.802057     6.762508e+06  1.458477e+06    22.970880   \n",
       "411      49.696582     2.594712e+05  3.699806e+06    21.916806   \n",
       "412     361.177719     2.256545e+06 -1.984217e+06    18.054986   \n",
       "413    1115.015173     7.208813e+06  1.609842e+06    23.072127   \n",
       "414      52.772446     2.772633e+05  3.953504e+06    22.012488   \n",
       "415     162.765894     2.216337e+06 -1.942402e+06    18.063474   \n",
       "416    1051.609753     6.988529e+06  1.529510e+06    23.022090   \n",
       "417      49.667981     2.600022e+05  3.707377e+06    21.919755   \n",
       "418     121.365512     2.426651e+06 -2.132461e+06    18.166389   \n",
       "419    1050.578603     6.815482e+06  1.531365e+06    22.992800   \n",
       "420      49.389808     2.597824e+05  3.704244e+06    21.918535   \n",
       "421     210.116892     1.103102e+07  5.143148e+07    25.896487   \n",
       "422      18.062588     1.279472e+07  8.024830e+06    24.311436   \n",
       "423       5.588557     1.054510e+07  1.820941e+05    23.354769   \n",
       "424      25.086914     6.621592e+06  1.100964e+07    24.071630   \n",
       "425  108643.821429     3.987185e+06  2.096869e+06    22.536602   \n",
       "426     350.075061     2.345906e+06 -2.056744e+06    18.141518   \n",
       "427    1174.364942     7.769976e+06  1.716544e+06    23.177448   \n",
       "428      52.212565     2.737845e+05  3.903899e+06    21.994272   \n",
       "429     168.182324     2.192172e+06 -1.920053e+06    18.053878   \n",
       "430    1045.093301     6.988970e+06  1.512864e+06    23.019343   \n",
       "431      49.523977     2.587388e+05  3.689362e+06    21.912727   \n",
       "432     116.204612     2.255980e+06 -1.978832e+06    18.080297   \n",
       "433    1021.963731     6.750430e+06  1.477400e+06    22.972081   \n",
       "434      49.563046     2.594529e+05  3.699544e+06    21.916704   \n",
       "\n",
       "     optimal_log_runtime  \n",
       "0              25.648562  \n",
       "1              25.663680  \n",
       "2              25.684098  \n",
       "3              25.660754  \n",
       "4              25.660491  \n",
       "5              25.656397  \n",
       "6              25.650431  \n",
       "7              25.367705  \n",
       "8              26.518395  \n",
       "9              25.376710  \n",
       "10             26.476603  \n",
       "11             25.453072  \n",
       "12             26.526634  \n",
       "13             25.872106  \n",
       "14             26.553684  \n",
       "15             25.624407  \n",
       "16             26.504598  \n",
       "17             25.678258  \n",
       "18             26.415889  \n",
       "19             17.054904  \n",
       "20             16.767844  \n",
       "21             28.578964  \n",
       "22             16.493090  \n",
       "23             20.213763  \n",
       "24             16.857274  \n",
       "25             26.855064  \n",
       "26             22.921202  \n",
       "27             20.202025  \n",
       "28             22.702526  \n",
       "29             25.957951  \n",
       "..                   ...  \n",
       "405            18.079187  \n",
       "406            21.033147  \n",
       "407            22.729038  \n",
       "408            17.994657  \n",
       "409            21.120574  \n",
       "410            22.689127  \n",
       "411            17.985221  \n",
       "412            21.105685  \n",
       "413            22.781331  \n",
       "414            18.080902  \n",
       "415            21.079747  \n",
       "416            22.736558  \n",
       "417            17.988170  \n",
       "418            21.210536  \n",
       "419            22.700385  \n",
       "420            17.986950  \n",
       "421            23.395063  \n",
       "422            23.609046  \n",
       "423            23.330069  \n",
       "424            22.658747  \n",
       "425            21.926939  \n",
       "426            21.161715  \n",
       "427            22.889479  \n",
       "428            18.062687  \n",
       "429            21.063930  \n",
       "430            22.736649  \n",
       "431            17.981142  \n",
       "432            21.105323  \n",
       "433            22.686548  \n",
       "434            17.985119  \n",
       "\n",
       "[435 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store additional statistics\n",
    "# TODO keep?\n",
    "\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def round_up_to_chunksize(row):\n",
    "    if row['OUTPUT_ROWS'] % CHUNK_SIZE == 0:\n",
    "        return row['OUTPUT_ROWS']\n",
    "    else:\n",
    "        return row['OUTPUT_ROWS'] + (CHUNK_SIZE - (row['OUTPUT_ROWS'] % CHUNK_SIZE))\n",
    "\n",
    "scans['pruned_minimum_input_rows'] = scans.apply(round_up_to_chunksize, axis=1)\n",
    "\n",
    "scans['selectivity'] = scans['OUTPUT_ROWS'] / scans['INPUT_ROWS']\n",
    "scans['actual_selectivity'] = scans['SINGLE_OUTPUT_ROWS'] / scans['SINGLE_INPUT_ROWS']\n",
    "\n",
    "scans['time_per_ir'] = scans['RUNTIME_NS'] / scans['INPUT_ROWS']\n",
    "scans['time_per_or'] = scans['RUNTIME_NS'] / scans['OUTPUT_ROWS']\n",
    "\n",
    "# optimal runtime assuming perfect pruning, but not sortedness\n",
    "scans['optimal_runtime'] = scans['time_per_ir'] * scans['pruned_minimum_input_rows']\n",
    "scans['runtime_gain'] = scans['RUNTIME_NS'] - scans['optimal_runtime']\n",
    "\n",
    "\n",
    "# log runtime for sorted columns\n",
    "scans['log_runtime'] = np.log2(scans['RUNTIME_NS'])\n",
    "scans['optimal_log_runtime'] = np.log2(1+scans['optimal_runtime'])\n",
    "scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>runtime_gain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">customer</th>\n",
       "      <th>c_phone</th>\n",
       "      <td>1.308860e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_mktsegment</th>\n",
       "      <td>3.706238e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lineitem</th>\n",
       "      <th>l_shipdate</th>\n",
       "      <td>3.668620e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_receiptdate</th>\n",
       "      <td>1.472151e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_shipmode</th>\n",
       "      <td>1.250315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_discount</th>\n",
       "      <td>6.457192e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_quantity</th>\n",
       "      <td>2.105635e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nation</th>\n",
       "      <th>n_name</th>\n",
       "      <td>-7.202164e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">orders</th>\n",
       "      <th>o_orderdate</th>\n",
       "      <td>1.378964e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o_orderstatus</th>\n",
       "      <td>3.127022e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o_comment</th>\n",
       "      <td>6.264567e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">part</th>\n",
       "      <th>p_name</th>\n",
       "      <td>9.838932e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_size</th>\n",
       "      <td>4.687991e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_type</th>\n",
       "      <td>1.393602e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_brand</th>\n",
       "      <td>1.142984e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_container</th>\n",
       "      <td>7.330176e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>r_name</th>\n",
       "      <td>-1.412730e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supplier</th>\n",
       "      <th>s_comment</th>\n",
       "      <td>2.116965e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          runtime_gain\n",
       "TABLE_NAME COLUMN_NAME                \n",
       "customer   c_phone        1.308860e+09\n",
       "           c_mktsegment   3.706238e+07\n",
       "lineitem   l_shipdate     3.668620e+09\n",
       "           l_receiptdate  1.472151e+09\n",
       "           l_shipmode     1.250315e+09\n",
       "           l_discount     6.457192e+08\n",
       "           l_quantity     2.105635e+08\n",
       "nation     n_name        -7.202164e+09\n",
       "orders     o_orderdate    1.378964e+09\n",
       "           o_orderstatus  3.127022e+08\n",
       "           o_comment      6.264567e+07\n",
       "part       p_name         9.838932e+08\n",
       "           p_size         4.687991e+08\n",
       "           p_type         1.393602e+08\n",
       "           p_brand        1.142984e+08\n",
       "           p_container    7.330176e+07\n",
       "region     r_name        -1.412730e+10\n",
       "supplier   s_comment      2.116965e+07"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAIN_COLUMN = 'runtime_gain'\n",
    "\n",
    "scans_groupby_columnname = scans.groupby(['TABLE_NAME', 'COLUMN_NAME'])\n",
    "sum_of_gains = pd.DataFrame(scans_groupby_columnname[GAIN_COLUMN].sum())\n",
    "sum_of_gains.sort_values(by=['TABLE_NAME', GAIN_COLUMN], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(l_receiptdate, l_shipdate)</td>\n",
       "      <td>2.966448e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(l_shipdate, l_shipdate)</td>\n",
       "      <td>3.019390e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(l_shipmode, l_shipdate)</td>\n",
       "      <td>3.188283e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(l_discount, l_shipdate)</td>\n",
       "      <td>3.792880e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(l_quantity, l_shipdate)</td>\n",
       "      <td>4.228035e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(l_shipdate, l_shipmode)</td>\n",
       "      <td>6.154668e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(l_shipdate, l_discount)</td>\n",
       "      <td>6.791128e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(l_receiptdate, l_shipmode)</td>\n",
       "      <td>7.020858e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(l_shipdate, l_quantity)</td>\n",
       "      <td>7.197625e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(l_shipdate, l_receiptdate)</td>\n",
       "      <td>7.297399e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(l_receiptdate, l_discount)</td>\n",
       "      <td>7.657319e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(l_receiptdate, l_quantity)</td>\n",
       "      <td>8.063815e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(l_receiptdate, l_receiptdate)</td>\n",
       "      <td>8.216531e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(l_shipmode, l_receiptdate)</td>\n",
       "      <td>9.715703e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(l_discount, l_receiptdate)</td>\n",
       "      <td>1.032030e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(l_discount, l_shipmode)</td>\n",
       "      <td>1.059678e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(l_shipmode, l_discount)</td>\n",
       "      <td>1.062864e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(l_quantity, l_receiptdate)</td>\n",
       "      <td>1.075545e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(l_quantity, l_shipmode)</td>\n",
       "      <td>1.103193e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(l_shipmode, l_quantity)</td>\n",
       "      <td>1.103514e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(l_shipmode, l_shipmode)</td>\n",
       "      <td>1.124250e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(l_discount, l_quantity)</td>\n",
       "      <td>1.163973e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(l_quantity, l_discount)</td>\n",
       "      <td>1.166839e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(l_discount, l_discount)</td>\n",
       "      <td>1.187896e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(l_quantity, l_quantity)</td>\n",
       "      <td>1.228545e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           columns          time\n",
       "20     (l_receiptdate, l_shipdate)  2.966448e+09\n",
       "0         (l_shipdate, l_shipdate)  3.019390e+09\n",
       "15        (l_shipmode, l_shipdate)  3.188283e+09\n",
       "10        (l_discount, l_shipdate)  3.792880e+09\n",
       "5         (l_quantity, l_shipdate)  4.228035e+09\n",
       "3         (l_shipdate, l_shipmode)  6.154668e+09\n",
       "2         (l_shipdate, l_discount)  6.791128e+09\n",
       "23     (l_receiptdate, l_shipmode)  7.020858e+09\n",
       "1         (l_shipdate, l_quantity)  7.197625e+09\n",
       "4      (l_shipdate, l_receiptdate)  7.297399e+09\n",
       "22     (l_receiptdate, l_discount)  7.657319e+09\n",
       "21     (l_receiptdate, l_quantity)  8.063815e+09\n",
       "24  (l_receiptdate, l_receiptdate)  8.216531e+09\n",
       "19     (l_shipmode, l_receiptdate)  9.715703e+09\n",
       "14     (l_discount, l_receiptdate)  1.032030e+10\n",
       "13        (l_discount, l_shipmode)  1.059678e+10\n",
       "17        (l_shipmode, l_discount)  1.062864e+10\n",
       "9      (l_quantity, l_receiptdate)  1.075545e+10\n",
       "8         (l_quantity, l_shipmode)  1.103193e+10\n",
       "16        (l_shipmode, l_quantity)  1.103514e+10\n",
       "18        (l_shipmode, l_shipmode)  1.124250e+10\n",
       "11        (l_discount, l_quantity)  1.163973e+10\n",
       "7         (l_quantity, l_discount)  1.166839e+10\n",
       "12        (l_discount, l_discount)  1.187896e+10\n",
       "6         (l_quantity, l_quantity)  1.228545e+10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "if BENCHMARK == \"TPCH\":\n",
    "    TABLE = \"lineitem\"\n",
    "else:    \n",
    "    TABLE = \"customer_demographics\"\n",
    "\n",
    "import itertools\n",
    "\n",
    "def extract_single_table(table_name):\n",
    "    return scans[scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def extract_interesting_columns(df):\n",
    "    return list(df['COLUMN_NAME'].unique())\n",
    "\n",
    "\n",
    "correlations = {\n",
    "    'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "    'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "    'l_commitdate': ['l_receiptdate', 'l_shipdate']\n",
    "}\n",
    "#correlations = {}\n",
    "def table_sorting_options(table_name):\n",
    "    single_table = extract_single_table(table_name)\n",
    "    interesting_cols = extract_interesting_columns(single_table)\n",
    "    pairs = itertools.product(interesting_cols, interesting_cols)\n",
    "    \n",
    "    total_times = []\n",
    "    for pair in pairs:\n",
    "        pruning_col = pair[0]\n",
    "        sorted_col = pair[1]\n",
    "\n",
    "        def compute_runtime(row):\n",
    "            col_name = row['COLUMN_NAME']\n",
    "            if pruning_col == sorted_col:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_log_runtime']\n",
    "                else:\n",
    "                    if col_name in correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "            else:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_runtime']\n",
    "                elif col_name == sorted_col:\n",
    "                    # TODO: should this be affected by correlation?\n",
    "                    # we will get less chunks, so a linear scan should be close to optimal_runtime,\n",
    "                    # but log time should beat it anyway\n",
    "                    return row['log_runtime']\n",
    "                else:\n",
    "                    if col_name in correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "        effective_runtime = single_table.apply(compute_runtime, axis=1)\n",
    "        total_times.append([pair, effective_runtime.sum()])    \n",
    "    total_times = pd.DataFrame(total_times, columns=['columns', 'time'])    \n",
    "    return total_times\n",
    "\n",
    "options = table_sorting_options(TABLE)\n",
    "options.sort_values(by=['time'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_HASH</th>\n",
       "      <th>AGGREGATE_HASH</th>\n",
       "      <th>COLUMN_TYPE</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>GROUP_BY_COLUMN_COUNT</th>\n",
       "      <th>AGGREGATE_COLUMN_COUNT</th>\n",
       "      <th>INPUT_ROWS</th>\n",
       "      <th>OUTPUT_ROWS</th>\n",
       "      <th>RUNTIME_NS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [QUERY_HASH, AGGREGATE_HASH, COLUMN_TYPE, TABLE_NAME, COLUMN_NAME, GROUP_BY_COLUMN_COUNT, AGGREGATE_COLUMN_COUNT, INPUT_ROWS, OUTPUT_ROWS, RUNTIME_NS, DESCRIPTION]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregates = pd.read_csv(f\"{STATISTICS_PATH}/aggregates.csv\", sep=',')\n",
    "\n",
    "# it looks like column names are mixed up.\n",
    "# COLUMN_NAME -> actually GROUP_BY_COLUMN_COUNT\n",
    "# GROUP_BY_COLUMN_COUNT -> actually AGGREGATE_COLUMN_COUNT\n",
    "# AGGREGATE_COLUMN_COUNT -> actually COLUMN_NAME\n",
    "\n",
    "COL_NAME = 'AGGREGATE_COLUMN_COUNT'\n",
    "GROUPBY_COL = 'COLUMN_NAME'\n",
    "AGG_COL = 'GROUP_BY_COLUMN_COUNT'\n",
    "\n",
    "# All aggregates have to read the entire table, so we cannot skip chunks.\n",
    "# But getting all groups consecutive could provide a speedup\n",
    "# As a result, we care only about aggregates with group by columns\n",
    "\n",
    "interesting_aggregates = aggregates[aggregates[GROUPBY_COL] > 0]\n",
    "stats = interesting_aggregates.groupby(['TABLE_NAME', COL_NAME])\n",
    "out_columns = pd.DataFrame(stats['OUTPUT_ROWS'].max())\n",
    "out_columns.sort_values(by=['TABLE_NAME', 'OUTPUT_ROWS'], ascending=[True, False])\n",
    "aggregates[aggregates['COLUMN_TYPE'] == 'DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total scan runtime: 27362435625\n",
      "total prunable scan runtime: 14034972749\n",
      "51.2928488580044% of scan runtime amount to prunable scans\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUNTIME_NS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l_shipdate</th>\n",
       "      <td>8264282387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o_comment</th>\n",
       "      <td>7605398277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o_orderdate</th>\n",
       "      <td>1909147688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_phone</th>\n",
       "      <td>1839853863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_receiptdate</th>\n",
       "      <td>1736861963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_shipmode</th>\n",
       "      <td>1460384674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_name</th>\n",
       "      <td>1051621410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_discount</th>\n",
       "      <td>823923974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_size</th>\n",
       "      <td>649871849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o_orderstatus</th>\n",
       "      <td>612334648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_quantity</th>\n",
       "      <td>417427206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_type</th>\n",
       "      <td>350048128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_container</th>\n",
       "      <td>293561909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_brand</th>\n",
       "      <td>235045976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_comment</th>\n",
       "      <td>61423614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_mktsegment</th>\n",
       "      <td>47421635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_name</th>\n",
       "      <td>2748498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_name</th>\n",
       "      <td>1077926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RUNTIME_NS\n",
       "COLUMN_NAME              \n",
       "l_shipdate     8264282387\n",
       "o_comment      7605398277\n",
       "o_orderdate    1909147688\n",
       "c_phone        1839853863\n",
       "l_receiptdate  1736861963\n",
       "l_shipmode     1460384674\n",
       "p_name         1051621410\n",
       "l_discount      823923974\n",
       "p_size          649871849\n",
       "o_orderstatus   612334648\n",
       "l_quantity      417427206\n",
       "p_type          350048128\n",
       "p_container     293561909\n",
       "p_brand         235045976\n",
       "s_comment        61423614\n",
       "c_mktsegment     47421635\n",
       "n_name            2748498\n",
       "r_name            1077926"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_time_per_column = scans.groupby(['COLUMN_NAME'])\n",
    "accumulated_scan_times = pd.DataFrame(scan_time_per_column['RUNTIME_NS'].sum())\n",
    "total_scan_runtime = accumulated_scan_times['RUNTIME_NS'].sum()\n",
    "assert total_scan_runtime == scans['RUNTIME_NS'].sum(), f\"{total_scan_runtime}, {scans['RUNTIME_NS'].sum()}\"\n",
    "print(f\"total scan runtime: {total_scan_runtime}\")\n",
    "\n",
    "scan_time_per_column_prunable = scans[scans['useful_for_pruning']].groupby(['COLUMN_NAME'])\n",
    "accumulated_prunable_scan_times = pd.DataFrame(scan_time_per_column_prunable['RUNTIME_NS'].sum())\n",
    "total_prunable_scan_runtime = accumulated_prunable_scan_times['RUNTIME_NS'].sum()\n",
    "print(f\"total prunable scan runtime: {total_prunable_scan_runtime}\")\n",
    "print(f\"{100*total_prunable_scan_runtime/total_scan_runtime}% of scan runtime amount to prunable scans\")\n",
    "\n",
    "accumulated_scan_times.sort_values(['RUNTIME_NS'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c_custkey' 's_nationkey' 'l_suppkey' 'l_orderkey' 'o_orderkey'\n",
      " 'ps_partkey' 'l_partkey' 's_suppkey' 'n_nationkey' 'n_regionkey'\n",
      " 'c_nationkey' 'ps_suppkey' 'p_partkey' 'o_custkey' 'ps_supplycost' nan]\n",
      "15\n",
      "total join runtime: 437246611576\n",
      "for TPCH, joins take about 15.979813258162759 times longer than table scans\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUNTIME_NS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROBE_COLUMN</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l_orderkey</th>\n",
       "      <td>164621073876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_partkey</th>\n",
       "      <td>82724758653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o_orderkey</th>\n",
       "      <td>56692008431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_custkey</th>\n",
       "      <td>47987057536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_suppkey</th>\n",
       "      <td>39474563381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o_custkey</th>\n",
       "      <td>18614106082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_partkey</th>\n",
       "      <td>13457584606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_partkey</th>\n",
       "      <td>9783801497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_suppkey</th>\n",
       "      <td>2330858192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_nationkey</th>\n",
       "      <td>921856448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_suppkey</th>\n",
       "      <td>392410277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_nationkey</th>\n",
       "      <td>188182127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_supplycost</th>\n",
       "      <td>34597116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_nationkey</th>\n",
       "      <td>18208229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_regionkey</th>\n",
       "      <td>5545125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RUNTIME_NS\n",
       "PROBE_COLUMN               \n",
       "l_orderkey     164621073876\n",
       "l_partkey       82724758653\n",
       "o_orderkey      56692008431\n",
       "c_custkey       47987057536\n",
       "l_suppkey       39474563381\n",
       "o_custkey       18614106082\n",
       "ps_partkey      13457584606\n",
       "p_partkey        9783801497\n",
       "ps_suppkey       2330858192\n",
       "c_nationkey       921856448\n",
       "s_suppkey         392410277\n",
       "s_nationkey       188182127\n",
       "ps_supplycost      34597116\n",
       "n_nationkey        18208229\n",
       "n_regionkey         5545125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joins = load_join_statistics()\n",
    "\n",
    "print(joins['PROBE_COLUMN'].unique())\n",
    "\n",
    "join_time_per_column = joins.groupby(['PROBE_COLUMN'])\n",
    "\n",
    "accumulated_join_times = pd.DataFrame(join_time_per_column['RUNTIME_NS'].sum())\n",
    "print(len(accumulated_join_times))\n",
    "total_join_runtime = accumulated_join_times['RUNTIME_NS'].sum()\n",
    "#assert total_join_runtime == joins['RUNTIME_NS'].sum(), f\"{total_join_runtime},{joins['RUNTIME_NS'].sum()}\"\n",
    "print(f\"total join runtime: {total_join_runtime}\")\n",
    "\n",
    "joins[joins.apply(lambda x : x['PROBE_COLUMN'] not in ['o_custkey' ,'n_nationkey' ,'s_nationkey' ,'l_suppkey', 's_suppkey',\n",
    " 'l_orderkey', 'o_orderkey', 'p_partkey' ,'l_partkey' ,'ps_suppkey',\n",
    " 'c_nationkey' ,'r_regionkey' ,'c_custkey' ,'ps_partkey'] ,axis=1)]\n",
    "\n",
    "print(f\"for {BENCHMARK}, joins take about {total_join_runtime / total_scan_runtime} times longer than table scans\")\n",
    "accumulated_join_times.sort_values(['RUNTIME_NS'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
