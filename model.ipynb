{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import math\n",
    "import operator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is configured for TPCDS (chunk size 65535) with scale factor 1, 60 seconds runtime, and at most 1 runs per query\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "\n",
    "BENCHMARK = \"TPCDS\"\n",
    "CHUNK_SIZE = 65535\n",
    "\n",
    "if BENCHMARK == \"TPCH\":\n",
    "    SCALE_FACTOR = 1\n",
    "    RUNS = 10\n",
    "    TIME = 60\n",
    "    STATISTICS_PATH = f\"~/Dokumente/repos/example_plugin/TPC-H__SF_{SCALE_FACTOR}.000000__RUNS_{RUNS}__TIME_{TIME}\"\n",
    "elif BENCHMARK == \"TPCDS\":\n",
    "    SCALE_FACTOR = 1\n",
    "    RUNS = 1\n",
    "    TIME = 60\n",
    "    STATISTICS_PATH = f\"~/Dokumente/repos/example_plugin/TPC-DS__SF_{SCALE_FACTOR}.000000__RUNS_{RUNS}__TIME_{TIME}\"\n",
    "else:\n",
    "    raise Exception(\"Unknown benchmark: \" + BENCHMARK)\n",
    "\n",
    "print(f\"Model is configured for {BENCHMARK} (chunk size {CHUNK_SIZE}) with scale factor {SCALE_FACTOR}, {TIME} seconds runtime, and at most {RUNS} runs per query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ~/Dokumente/repos/example_plugin/TPC-DS__SF_1.000000__RUNS_1__TIME_60/table_scans.csv\n"
     ]
    }
   ],
   "source": [
    "# Load table scan statistics\n",
    "\n",
    "path = f\"{STATISTICS_PATH}/table_scans.csv\"\n",
    "scans = pd.read_csv(path, sep='|')\n",
    "EXPECTED_SCAN_COUNT = len(scans)\n",
    "LOADED_CHUNK_SIZE = CHUNK_SIZE\n",
    "LOADED_BENCHMARK = BENCHMARK\n",
    "LOADED_SCALE_FACTOR = SCALE_FACTOR\n",
    "LOADED_RUNS = RUNS\n",
    "LOADED_TIME = TIME\n",
    "\n",
    "print(f\"Successfully loaded {path}\")\n",
    "\n",
    "def assert_correct_statistics_loaded():\n",
    "    assert BENCHMARK == LOADED_BENCHMARK, f\"The model is configured to use {BENCHMARK}, but {LOADED_BENCHMARK} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert SCALE_FACTOR == LOADED_SCALE_FACTOR, f\"The model is configured to use {SCALE_FACTOR} as scale factor, but data for a scale factor of {LOADED_SCALE_FACTOR} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert RUNS == LOADED_RUNS, f\"The model is configured to perform at most {RUNS} runs, but the currently loaded data had at most {LOADED_RUNS} runs.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert TIME == LOADED_TIME, f\"The model is configured to run for {TIME} seconds, but the currently data had a runtime of {LOADED_TIME} seconds.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert CHUNK_SIZE == LOADED_CHUNK_SIZE, f\"The model is configured to use {CHUNK_SIZE} as chunk_size, but data for a chunk size of {LOADED_CHUNK_SIZE} is currently loaded.\\nEither change the benchmark or re-run all cells\"\n",
    "    assert EXPECTED_SCAN_COUNT == len(scans), f\"There should be {EXPECTED_SCAN_COUNT} table scans, but there are only {len(scans)}\\nProbably one of the last commands reassigned it unintentionally\"\n",
    "    \n",
    "    assert 'GET_TABLE_HASH' in scans.columns, f\"the statistics in {STATISTICS_PATH} are outdated (column 'GET_TABLE_HASH' in table_scans.csv is missing). Please create them again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - looks like pruning was deactivated while the statistics were created\n"
     ]
    }
   ],
   "source": [
    "# Validate table scans\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "# To make sure pruning was not active,\n",
    "# first fetch table sizes,\n",
    "table_statistics = pd.read_csv(f\"{STATISTICS_PATH}/table_meta_data.csv\", sep='|')\n",
    "table_sizes = dict(zip(table_statistics.TABLE_NAME, table_statistics.ROW_COUNT))\n",
    "\n",
    "# then make sure INPUT_ROWS == table_size\n",
    "def input_size_matches(row):\n",
    "    #print(row)\n",
    "    \n",
    "    actual_row_count = row['INPUT_ROWS']\n",
    "    table = row['TABLE_NAME']\n",
    "    expected_row_count = table_sizes[table]\n",
    "    return expected_row_count == actual_row_count\n",
    "\n",
    "data_scans = scans[scans['COLUMN_TYPE'] == 'DATA']\n",
    "input_size_matches = data_scans.apply(input_size_matches, axis=1)\n",
    "all_sizes_match = reduce(np.logical_and, input_size_matches) #input_size_matches.apply()\n",
    "\n",
    "if not all_sizes_match:\n",
    "    raise Exception(\"The given statistics were probably created while pruning was active\")\n",
    "else:\n",
    "    print(\"OK - looks like pruning was deactivated while the statistics were created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for TPCDS contain 216 table scans\n",
      "Of those, only 70 are useful for pruning\n",
      "TODO: For now, filtering on scans is deactivated. This is because all scans are needed to recognize OR-Chains. Models have to take care themselves whether a scan can contribute to pruning or not\n"
     ]
    }
   ],
   "source": [
    "# Append additional information to the table scans\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "print(f\"Statistics for {BENCHMARK} contain {len(scans)} table scans\")\n",
    "\n",
    "\n",
    "# Add statistics about selectivity and speed for each operator\n",
    "scans['selectivity'] = scans['OUTPUT_ROWS'] / scans['INPUT_ROWS']\n",
    "\n",
    "# TODO: Assumption that reading and writing a row have the same cost\n",
    "scans['time_per_row'] = scans['RUNTIME_NS'] / (scans['INPUT_ROWS'] + scans['OUTPUT_ROWS'])\n",
    "scans['time_per_input_row'] = scans['time_per_row']\n",
    "scans['time_per_output_row'] = scans['time_per_row']\n",
    "\n",
    "\n",
    "def determine_or_chains(table_scans):\n",
    "    table_scans['part_of_or_chain'] = False\n",
    "    \n",
    "    single_table_scans = table_scans.groupby(['QUERY_HASH', 'TABLE_NAME', 'GET_TABLE_HASH'])\n",
    "    \n",
    "    for _, scans in single_table_scans:            \n",
    "        input_row_frequencies = Counter(scans.INPUT_ROWS)\n",
    "        or_input_sizes = set([input_size for input_size, frequency in input_row_frequencies.items() if frequency > 1])\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df['INPUT_ROWS'] = scans['INPUT_ROWS']\n",
    "        df['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "        df['part_of_or_chain'] = scans.apply(lambda row: row['INPUT_ROWS'] in or_input_sizes, axis=1)\n",
    "\n",
    "        for _ in range(len(scans)):\n",
    "            or_input_sizes |= set(df[df['part_of_or_chain']].OUTPUT_ROWS.unique())\n",
    "            df['part_of_or_chain'] = df.apply(lambda row: row['INPUT_ROWS'] in or_input_sizes, axis=1)\n",
    "\n",
    "        or_chains = list(df[df['part_of_or_chain']].index)\n",
    "        table_scans.iloc[or_chains, table_scans.columns.get_loc('part_of_or_chain')] = True\n",
    "    \n",
    "    return table_scans\n",
    "\n",
    "# Hyrise does not use scans that are part of an OR-chain for pruning\n",
    "scans = determine_or_chains(scans)\n",
    "\n",
    "\n",
    "# Like scans are not useful if they start with %\n",
    "# TODO what if they dont start with % and contain more than one % ? -> up to first % prunable, but is it used?\n",
    "def benefits_from_sorting(row):    \n",
    "    description = row['DESCRIPTION']\n",
    "    if \"ColumnLike\" in description:\n",
    "        words = description.split()\n",
    "        like_criteria = words[-1]\n",
    "        assert \"%\" in like_criteria, f\"LIKE operators should have an %, but found none in {like_criteria}\"\n",
    "        return like_criteria[1] != '%'\n",
    "    elif \"ExpressionEvaluator\" in description and \" IN \" in description:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "scans['benefits_from_sorting'] = scans.apply(benefits_from_sorting, axis=1)\n",
    "# TODO: valid atm, but feels a bit hacky to assume not benefitting from sorted segments -> not benefitting from pruning\n",
    "scans['useful_for_pruning'] = scans.apply(lambda row: not row['part_of_or_chain'] and row['benefits_from_sorting'] , axis=1)\n",
    "EXPECTED_SCAN_COUNT = len(scans)\n",
    "print(f\"Of those, only {len(scans[scans['useful_for_pruning']])} are useful for pruning\")\n",
    "\n",
    "print(\"TODO: For now, filtering on scans is deactivated. This is because all scans are needed to recognize OR-Chains. Models have to take care themselves whether a scan can contribute to pruning or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test OK\n"
     ]
    }
   ],
   "source": [
    "def test_determine_or_chains():\n",
    "    test = pd.DataFrame()\n",
    "    test['QUERY_HASH'] = pd.Series(['1']*3  + ['2']*4)\n",
    "    test['TABLE_NAME'] = pd.Series(['lineitem']*3  + ['part']*4)\n",
    "    test['GET_TABLE_HASH'] = pd.Series(['0x1'] + ['0x2']*2 + ['0x3']*4)\n",
    "    test['COLUMN_NAME'] = pd.Series(['l_shipdate', 'l_shipdate', 'l_discount', 'p_brand', 'p_type', 'p_type', 'p_size'])\n",
    "    test['INPUT_ROWS'] = pd.Series( [6001215, 6001215, 200000, 200000, 199000, 199000, 50000])\n",
    "    test['OUTPUT_ROWS'] = pd.Series([ 400000,  300000, 200000, 199000,      0,  50000, 20000])\n",
    "    test_result = determine_or_chains(test)\n",
    "    assert len(test_result) == 7, \"should not filter out any rows\"    \n",
    "    assert len(test_result[test_result['part_of_or_chain']]) == 3, \"expected 3 scans, got\\n\" + str(test_result)\n",
    "    assert list(test_result['part_of_or_chain']) == [False]*4 + [True]*3\n",
    "    print(\"Test OK\")\n",
    "\n",
    "test_determine_or_chains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load query frequency information\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def get_query_frequencies():\n",
    "    plan_cache = pd.read_csv(f\"{STATISTICS_PATH}/plan_cache.csv\", sep='|')\n",
    "    return dict(zip(plan_cache.QUERY_HASH, plan_cache.EXECUTION_COUNT))\n",
    "\n",
    "#get_query_frequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load column statistics - especially interesting: number of distinct values, and columns sorted during statistics creation\n",
    "\n",
    "# Returns a 2-level-dictionary: distinct_values[TABLE][COLUMN] = number_of_distinct_values\n",
    "def get_distinct_values_count():        \n",
    "    # Code\n",
    "    column_statistics_df = pd.read_csv(f\"{STATISTICS_PATH}/column_meta_data.csv\", sep='|')\n",
    "    column_statistics_df['DISTINCT_VALUES'] = np.int32(column_statistics_df['DISTINCT_VALUES'])\n",
    "    tables_and_columns = column_statistics_df.groupby('TABLE_NAME')\n",
    "    distinct_values = {table: dict(zip(column_df.COLUMN_NAME, column_df.DISTINCT_VALUES)) for table, column_df in tables_and_columns }\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    num_tables = len(distinct_values)\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        assert num_tables == 8, f\"TPCH has 8 tables, but got {num_tables}\"\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        assert num_tables == 24, f\"TPCDS has 24 tables, but got {num_tables}\"\n",
    "    else:\n",
    "        assert False, \"Insert a benchmark specific check here\"\n",
    "    \n",
    "    return distinct_values\n",
    "\n",
    "# Returns a dictionary: sorted_columns_during_creation[TABLE] = [column1, column2, ...]\n",
    "def get_sorted_columns_during_creation():\n",
    "    # Code\n",
    "    column_statistics_df = pd.read_csv(f\"{STATISTICS_PATH}/column_meta_data.csv\", sep='|')\n",
    "    globally_sorted_columns = column_statistics_df[column_statistics_df['IS_GLOBALLY_SORTED'] == 1]\n",
    "    \n",
    "    tables_and_columns = globally_sorted_columns.groupby('TABLE_NAME')\n",
    "    globally_sorted_columns = {table: list(column_df.COLUMN_NAME) for table, column_df in tables_and_columns }\n",
    "    \n",
    "    return globally_sorted_columns\n",
    "\n",
    "#get_distinct_values_count()\n",
    "#get_sorted_columns_during_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOINS ###\n",
    "\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def load_join_statistics():\n",
    "    def line_looks_suspicious(row):\n",
    "        right_table_name = row['RIGHT_TABLE_NAME']    \n",
    "        if pd.isnull(right_table_name):\n",
    "            pass\n",
    "        elif row['RIGHT_TABLE_ROW_COUNT'] > table_sizes[row['RIGHT_TABLE_NAME']]:\n",
    "            return True\n",
    "\n",
    "        left_table_name = row['LEFT_TABLE_NAME']\n",
    "        if pd.isnull(left_table_name):\n",
    "            pass\n",
    "        elif row['LEFT_TABLE_ROW_COUNT'] > table_sizes[row['LEFT_TABLE_NAME']]:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def validate_joins(joins):\n",
    "        is_suspicious = joins.apply(line_looks_suspicious, axis=1)\n",
    "        suspicious_joins = joins[is_suspicious]\n",
    "        assert len(suspicious_joins) < 3, f\"there are {len(suspicious_joins)} suspicious joins:\\n{suspicious_joins[['JOIN_MODE', 'LEFT_TABLE_NAME', 'LEFT_COLUMN_NAME', 'LEFT_TABLE_ROW_COUNT', 'RIGHT_TABLE_NAME', 'RIGHT_COLUMN_NAME', 'RIGHT_TABLE_ROW_COUNT', 'OUTPUT_ROWS']]}\"\n",
    "    \n",
    "    joins = pd.read_csv(f\"{STATISTICS_PATH}/joins.csv\", sep='|')\n",
    "    joins = joins.fillna(\"NULL\")\n",
    "    joins['PROBE_TABLE'] = joins.apply(lambda x: x[x['PROBE_SIDE'] + \"_TABLE_NAME\"] if not x['PROBE_SIDE'] == \"NULL\" else \"NULL\", axis=1)\n",
    "    joins['PROBE_COLUMN'] = joins.apply(lambda x: x[x['PROBE_SIDE'] + \"_COLUMN_NAME\"] if not x['PROBE_SIDE'] == \"NULL\" else \"NULL\", axis=1)\n",
    "    joins['PROBE_TABLE_ROW_COUNT'] = joins.apply(lambda x: x[x['PROBE_SIDE'] + \"_TABLE_ROW_COUNT\"]if not x['PROBE_SIDE'] == \"NULL\" else \"NULL\" , axis=1)\n",
    "    joins['BUILD_TABLE'] = joins.apply(lambda x: x[x['BUILD_SIDE'] + \"_TABLE_NAME\"] if not x['BUILD_SIDE'] == \"NULL\" else \"NULL\", axis=1)\n",
    "    joins['BUILD_COLUMN'] = joins.apply(lambda x: x[x['BUILD_SIDE'] + \"_COLUMN_NAME\"] if not x['BUILD_SIDE'] == \"NULL\" else \"NULL\", axis=1)\n",
    "    joins['BUILD_TABLE_ROW_COUNT'] = joins.apply(lambda x: x[x['BUILD_SIDE'] + \"_TABLE_ROW_COUNT\"] if not x['BUILD_SIDE'] == \"NULL\" else \"NULL\", axis=1)\n",
    "    validate_joins(joins)\n",
    "    \n",
    "    \n",
    "    # TODOS\n",
    "    \n",
    "    # code: export which side is probe\n",
    "    # model: add columns for probe and build table size\n",
    "    # model: use more precise values for build and probe materialization\n",
    "        \n",
    "    \n",
    "    \n",
    "    #TODO code: activate higher cache size    \n",
    "                                                                                           \n",
    "    return joins\n",
    "\n",
    "#load_join_statistics()#.iloc[9:10][['JOIN_MODE', 'LEFT_TABLE_NAME', 'LEFT_COLUMN_NAME', 'LEFT_TABLE_ROW_COUNT', 'RIGHT_TABLE_NAME', 'RIGHT_COLUMN_NAME', 'RIGHT_TABLE_ROW_COUNT', 'OUTPUT_ROWS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractModel:\n",
    "    \n",
    "    def __init__(self, query_frequencies, table_name, table_scans, correlations={}):\n",
    "        self.query_frequencies = query_frequencies\n",
    "        self.table_name = table_name\n",
    "        self.table_scans = table_scans\n",
    "        self.correlations = correlations\n",
    "        \n",
    "    def query_frequency(self, query_hash):\n",
    "        return self.query_frequencies[query_hash]\n",
    "        \n",
    "    def extract_scan_columns(self):\n",
    "        useful_scans = self.table_scans[self.table_scans['useful_for_pruning']]\n",
    "        interesting_scan_columns = list(useful_scans['COLUMN_NAME'].unique())\n",
    "        \n",
    "        return interesting_scan_columns\n",
    "    \n",
    "    def extract_join_columns(self):\n",
    "        interesting_join_probe_columns = list(self.joins[self.joins['PROBE_TABLE'] == self.table_name]['PROBE_COLUMN'].unique())\n",
    "        interesting_join_build_columns = list(self.joins[self.joins['BUILD_TABLE'] == self.table_name]['BUILD_COLUMN'].unique())        \n",
    "        \n",
    "        return self.uniquify(interesting_join_probe_columns + interesting_join_build_columns)\n",
    "    \n",
    "    def extract_interesting_columns(self):        \n",
    "        return self.uniquify(self.extract_scan_columns() + self.extract_join_columns())\n",
    "    \n",
    "    def round_up_to_next_multiple(self, number_to_round, base_for_multiple):\n",
    "        quotient = number_to_round // base_for_multiple\n",
    "        if number_to_round % base_for_multiple != 0:\n",
    "            quotient += 1\n",
    "        return quotient * base_for_multiple        \n",
    "\n",
    "    def uniquify(self, seq):\n",
    "            seen = set()\n",
    "            return [x for x in seq if not (x in seen or seen.add(x))]    \n",
    "    \n",
    "    # return a list of possible clusterings\n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Old partitioner model.\n",
    "# TODO: refactor to inherit from SingleTableMDCModel (further below). Not sure how much effort should go into this model, since it is not designed for the \"main clustering algorithm\"\n",
    "\n",
    "class PartitionerModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, query_frequencies, table_name, table_scans, table_size, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation):\n",
    "        super().__init__(query_frequencies, table_name, table_scans, correlations)\n",
    "        self.table_size = table_size\n",
    "        self.distinct_values = distinct_values\n",
    "        self.target_chunksize = target_chunksize\n",
    "        self.joins = joins\n",
    "        self.sorted_columns_during_creation = sorted_columns_during_creation\n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        print(interesting_columns)\n",
    "        \n",
    "        clustering_columns = itertools.product(interesting_columns, interesting_columns)\n",
    "        #clustering_columns = itertools.product(interesting_columns, interesting_columns, interesting_columns)\n",
    "        clustering_columns = filter(lambda x: x[0] <= x[1], clustering_columns)\n",
    "        #clustering_columns = filter(lambda x: x[1] <= x[2], clustering_columns)\n",
    "        clustering_columns = [self.uniquify(clustering) for clustering in clustering_columns]\n",
    "        sort_columns = interesting_columns        \n",
    "        clusterings_with_runtimes = reduce(lambda x,y: x+y,[self.estimate_total_runtime(clustering_cols, sort_columns) for clustering_cols in clustering_columns])\n",
    "        clusterings_with_runtimes.sort(key=lambda x: x[2], reverse=False)\n",
    "        \n",
    "        return clusterings_with_runtimes[0:first_k]\n",
    "        \n",
    "    def estimate_table_scan_runtimes(self, clustering_columns, sorting_columns, split_factors, total_runtimes):        \n",
    "        def compute_unprunable_parts(row, split_factors):\n",
    "            def clustering_columns_correlated_to(column):\n",
    "                return [clustering_column for clustering_column in clustering_columns if column in self.correlations.get(clustering_column, {})]\n",
    "            \n",
    "            def correlates_to_clustering_column(column):\n",
    "                return len(clustering_columns_correlated_to(column)) > 0\n",
    "\n",
    "            column_name = row['COLUMN_NAME']\n",
    "\n",
    "            if not row['useful_for_pruning']:\n",
    "                selectivity = 1\n",
    "            elif column_name in clustering_columns:\n",
    "                scan_selectivity = row['selectivity']\n",
    "                split_factor = split_factors[clustering_columns.index(column_name)]\n",
    "                selectivity =  self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor)\n",
    "            elif correlates_to_clustering_column(column_name):\n",
    "                scan_selectivity = row['selectivity']\n",
    "                correlated_clustering_columns = clustering_columns_correlated_to(column_name)\n",
    "                \n",
    "                # ToDo this is hacky, but for now assume there is just one correlated column\n",
    "                assert len(correlated_clustering_columns) == 1, f\"expected just 1 correlated clustering column, but got {len(correlated_clustering_columns)}\"\n",
    "                \n",
    "                split_factor = split_factors[clustering_columns.index(correlated_clustering_columns[0])]\n",
    "                selectivity = min(1, 1.2 * self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor))\n",
    "            else:\n",
    "                selectivity = 1\n",
    "            \n",
    "            return selectivity\n",
    "        \n",
    "        def compute_runtimes(row, sorting_column):\n",
    "            assert row['estimated_input_rows'] > 1, row\n",
    "            assert row['runtime_per_input_row'] > 0, row\n",
    "            assert row['runtime_per_output_row'] > 0, row\n",
    "            input_row_count = row['estimated_input_rows']\n",
    "            \n",
    "            if row['COLUMN_NAME'] == sorting_column and row['benefits_from_sorting']:\n",
    "                # TODO is this the best way to simulate sorted access?\n",
    "                input_row_count = np.log2(input_row_count)\n",
    "\n",
    "            runtime = input_row_count * row['runtime_per_input_row'] + row['OUTPUT_ROWS'] * row['runtime_per_output_row']\n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        scans_per_query = self.table_scans.sort_values(['INPUT_ROWS'], ascending=False).groupby(['QUERY_HASH', 'GET_TABLE_HASH'])\n",
    "        for _, scans in scans_per_query:\n",
    "            number_of_scans = len(scans)\n",
    "            assert number_of_scans > 0 and number_of_scans < 25, f\"weird scan length: {number_of_scans}\\nScans:\\n{scans}\"\n",
    "            # TODO: kinda unrealistic assumption: everything not in the table scan result can be pruned\n",
    "                          \n",
    "            unprunable_parts = scans.apply(compute_unprunable_parts, axis=1, args=(split_factors,))            \n",
    "            unprunable_part = unprunable_parts.product()\n",
    "            assert unprunable_part > 0, \"no unprunable part\"\n",
    "            \n",
    "            estimated_pruned_table_size = self.round_up_to_next_multiple(unprunable_part * self.table_size, CHUNK_SIZE)\n",
    "            \n",
    "            runtimes = pd.DataFrame()\n",
    "            runtimes['QUERY_HASH'] = scans['QUERY_HASH']\n",
    "            runtimes['runtime_per_input_row'] = scans['time_per_input_row']\n",
    "            runtimes['runtime_per_output_row'] = scans['time_per_output_row']\n",
    "            runtimes['COLUMN_NAME'] = scans['COLUMN_NAME']\n",
    "            runtimes['benefits_from_sorting'] = scans['benefits_from_sorting']\n",
    "            # the pruned table inputs should be reflected in 'estimated_input_rows'\n",
    "            runtimes['estimated_input_rows'] = scans.apply(lambda x: x['INPUT_ROWS'], axis=1)\n",
    "            runtimes['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "\n",
    "            runtimes.iloc[0, runtimes.columns.get_loc('estimated_input_rows')] = estimated_pruned_table_size                                    \n",
    "            assert runtimes['estimated_input_rows'].iloc[0] == estimated_pruned_table_size, f\"value is {runtimes.iloc[0]['estimated_input_rows']}, but should be {estimated_pruned_table_size}\"\n",
    "            # TODO modify input sizes of subsequent scans\n",
    "            \n",
    "            for sorting_column in sorting_columns:\n",
    "                scan_runtimes = runtimes.apply(compute_runtimes, axis=1, args=(sorting_column,))\n",
    "                total_runtimes[sorting_column] += scan_runtimes.sum()\n",
    "\n",
    "    def estimate_join_runtimes(self, clustering_columns, sorting_columns, total_runtimes):                \n",
    "        def estimate_join_runtime(row, sorting_column):\n",
    "                        \n",
    "            if \"JoinHash\" in row['DESCRIPTION']:\n",
    "                probe_column = row['PROBE_COLUMN']\n",
    "                if row['PROBE_TABLE'] == self.table_name:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    probe_column_is_sorted = row['PROBE_SORTED'] and probe_column == sorting_column\n",
    "                    probe_column_is_clustered = row['PROBE_SORTED'] and probe_column in clustering_columns\n",
    "                else:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(row['PROBE_TABLE'], {})\n",
    "                    probe_column_is_sorted = probe_column_was_sorted\n",
    "                    probe_column_is_clustered = probe_column_was_sorted\n",
    "                    \n",
    "                build_column = row['BUILD_COLUMN']\n",
    "                if row['BUILD_TABLE'] == self.table_name:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    build_column_is_sorted = row['BUILD_SORTED'] and build_column == sorting_column\n",
    "                    build_column_is_clustered = row['BUILD_SORTED'] and build_column in clustering_columns\n",
    "                else:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(row['BUILD_TABLE'], {})\n",
    "                    build_column_is_sorted = build_column_was_sorted\n",
    "                    build_column_is_clustered = build_column_was_sorted\n",
    "\n",
    "                time_materialize = row['BUILD_SIDE_MATERIALIZING_NS'] + row['PROBE_SIDE_MATERIALIZING_NS']\n",
    "                \n",
    "                probe_weight = 2\n",
    "                build_weight = 2\n",
    "                if probe_column_was_sorted:\n",
    "                    probe_weight = 1\n",
    "                if build_column_was_sorted:\n",
    "                    build_weight = 1\n",
    "                \n",
    "                \n",
    "                probe_table_size = row['PROBE_TABLE_ROW_COUNT']\n",
    "                build_table_size = row['BUILD_TABLE_ROW_COUNT']\n",
    "                total_table_size = probe_weight * probe_table_size + build_weight * build_table_size\n",
    "                \n",
    "                time_materialize_probe = time_materialize * (probe_weight * probe_table_size / total_table_size)\n",
    "                time_materialize_build = time_materialize - time_materialize_probe\n",
    "                \n",
    "                \n",
    "                def get_materialize_factor(was_sorted, is_sorted, is_clustered):\n",
    "                    materialize_factor = 1\n",
    "                    if is_sorted and is_clustered:\n",
    "                        if not was_sorted:\n",
    "                            materialize_factor = 0.5\n",
    "                        else:\n",
    "                            materialize_factor = 1\n",
    "                    elif is_sorted or is_clustered:\n",
    "                        if not was_sorted:\n",
    "                            materialize_factor = 0.55\n",
    "                        else:\n",
    "                            materialize_factor = 1.1\n",
    "                    elif was_sorted:\n",
    "                        # probe column is now neither sorted nor clustered\n",
    "                        materialize_factor = 2\n",
    "                    else:\n",
    "                        # default case: was not sorted before, and is neither sorted nor clustered now. No change\n",
    "                        materialize_factor = 1\n",
    "                        \n",
    "                    return materialize_factor\n",
    "                \n",
    "                materialize_probe_factor = get_materialize_factor(probe_column_was_sorted, probe_column_is_sorted, probe_column_is_clustered)\n",
    "                materialize_build_factor = get_materialize_factor(build_column_was_sorted, build_column_is_sorted, build_column_is_clustered)\n",
    "                \n",
    "                time_materialize = time_materialize_probe * materialize_probe_factor + time_materialize_build *  materialize_build_factor\n",
    "                \n",
    "\n",
    "                # unchanged\n",
    "                time_cluster = row['CLUSTERING_NS']\n",
    "                \n",
    "                # unchanged\n",
    "                time_build = row['BUILDING_NS']\n",
    "                \n",
    "                            \n",
    "                time_probe = row['PROBING_NS']\n",
    "                probe_factor = 1\n",
    "                if probe_column_is_sorted and probe_column_is_clustered:\n",
    "                    if not probe_column_was_sorted:\n",
    "                        probe_factor = 0.7\n",
    "                    else:\n",
    "                        probe_factor = 1\n",
    "                elif probe_column_is_sorted or probe_column_is_clustered:\n",
    "                    if not probe_column_was_sorted:\n",
    "                        probe_factor = 0.9\n",
    "                    else:\n",
    "                        probe_factor = 1.1\n",
    "                elif probe_column_was_sorted:\n",
    "                    # probe column is now neither sorted nor clustered\n",
    "                    probe_factor = 1.4\n",
    "                \n",
    "                time_probe *= probe_factor                \n",
    "                \n",
    "                # unchanged\n",
    "                time_write_output = row['OUTPUT_WRITING_NS']\n",
    "                \n",
    "                \n",
    "                \n",
    "                # TODO: how to deal with the difference between RUNTIME_NS and sum(stage_runtimes)?\n",
    "                runtime = time_materialize + time_cluster + time_build + time_probe + time_write_output\n",
    "            else:\n",
    "                runtime = row['RUNTIME_NS']\n",
    "                \n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        for sorting_column in sorting_columns:\n",
    "            join_runtimes = self.joins.apply(estimate_join_runtime, axis=1, args=(sorting_column,))\n",
    "            total_runtimes[sorting_column] += join_runtimes.sum()\n",
    "                \n",
    "    def estimate_total_runtime(self, clustering_columns, sorting_columns):\n",
    "        #print(f\"testing clustering {clustering_columns} with sorting columns {sorting_columns}\")\n",
    "        split_factors = self.determine_split_factors(clustering_columns)            \n",
    "        total_runtimes = {sorting_column: 0 for sorting_column in sorting_columns}\n",
    "        self.estimate_table_scan_runtimes(clustering_columns, sorting_columns, split_factors, total_runtimes)\n",
    "        self.estimate_join_runtimes(clustering_columns, sorting_columns, total_runtimes)\n",
    "        \n",
    "        clusterings = [[list(zip(clustering_columns, split_factors)), sorting_column, np.int64(total_runtimes[sorting_column])] for sorting_column in sorting_columns]\n",
    "        return clusterings\n",
    "    \n",
    "    def determine_split_factors(self, clustering_columns):\n",
    "        approximate_split_factor = self.table_size / self.target_chunksize\n",
    "        individual_distinct_values = [self.distinct_values[column] for column in clustering_columns]        \n",
    "        log_distinct_values = [math.ceil(0.5+np.log2(x)) for x in individual_distinct_values]\n",
    "        log_distinct_values_product = reduce(operator.mul, log_distinct_values, 1)\n",
    "        assert log_distinct_values_product > 0, \"cannot have a distinct value count of 0\"\n",
    "        \n",
    "        global_modification_factor = approximate_split_factor / log_distinct_values_product\n",
    "        num_dimensions = len(clustering_columns)\n",
    "        individual_modification_factor = np.power(global_modification_factor, 1.0 / num_dimensions)    \n",
    "        split_factors = [math.ceil(x * individual_modification_factor) for x in log_distinct_values]\n",
    "        \n",
    "        # testing\n",
    "        actual_split_factor = reduce(operator.mul, split_factors, 1)\n",
    "        assert actual_split_factor > 0, \"there was a split up factor of 0\"\n",
    "        estimated_chunksize = self.table_size / actual_split_factor\n",
    "        assert estimated_chunksize <= self.target_chunksize, \"chunks should be smaller, not larger than target_chunksize\"\n",
    "        allowed_percentage = 0.55\n",
    "        if estimated_chunksize < allowed_percentage * self.target_chunksize:\n",
    "            print(f\"Warning: chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\")\n",
    "        #assert estimated_chunksize >= allowed_percentage * self.target_chunksize, f\"chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\"\n",
    "        \n",
    "        return split_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "def extract_probe_side_joins(joins, table_name):\n",
    "    return joins[joins['PROBE_TABLE'] == table_name]\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 92 * SCALE_FACTOR]],\n",
    "            'orders': [['o_orderdate', 23 * SCALE_FACTOR]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_benchmark_configs():\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    clusterings = {\"default\" : default_benchmark_config()}\n",
    "    query_frequencies = get_query_frequencies()\n",
    "    \n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    for table_name in table_names:\n",
    "        start_time_table = datetime.now()\n",
    "        single_table_scans = extract_single_table(scans, table_name)\n",
    "        probe_side_joins = joins#extract_probe_side_joins(joins, table_name)\n",
    "        table_size = table_sizes[table_name]\n",
    "        if table_size <= 3 * CHUNK_SIZE:\n",
    "            print(f\"Not computing clustering for {table_name}, as it has only {table_size} rows\")\n",
    "            continue\n",
    "\n",
    "        model = PartitionerModel(query_frequencies, table_name, single_table_scans, table_size, distinct_values[table_name], CHUNK_SIZE, correlations.get(table_name, {}), probe_side_joins, sorted_columns_during_creation)\n",
    "        table_clusterings = model.suggest_clustering(3)\n",
    "        for table_clustering in table_clusterings:\n",
    "            config = default_benchmark_config()\n",
    "            config[table_name] = format_table_clustering(table_clustering)\n",
    "            config_name = get_config_name(config)\n",
    "            clusterings[config_name] = config\n",
    "        end_time_table = datetime.now()\n",
    "        print(f\"Done computing clustering for {table_name} ({end_time_table - start_time_table})\")\n",
    "\n",
    "            \n",
    "    end_time = datetime.now()\n",
    "    print(f\"Computed all clusterings in {end_time - start_time}\")\n",
    "    \n",
    "    return clusterings\n",
    "\n",
    "#create_benchmark_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTableMdcModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, max_dimensions, query_frequencies, table_name, table_scans, table_sizes, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation):\n",
    "        super().__init__(query_frequencies, table_name, table_scans, correlations)\n",
    "        self.max_dimensions = max_dimensions\n",
    "        self.table_sizes = table_sizes       \n",
    "        self.table_size = table_sizes[table_name]\n",
    "        self.distinct_values = distinct_values\n",
    "        self.target_chunksize = target_chunksize\n",
    "        self.joins = joins\n",
    "        self.sorted_columns_during_creation = sorted_columns_during_creation\n",
    "        \n",
    "        self.join_column_names = self.extract_join_columns()\n",
    "        self.scan_column_names = self.extract_scan_columns()\n",
    "        \n",
    "    def is_join_column(self, column_name):\n",
    "        return column_name in self.join_column_names\n",
    "    \n",
    "    def is_scan_column(self, column_name):\n",
    "        return column_name in self.scan_column_names\n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        print(interesting_columns)\n",
    "        clustering_columns = itertools.combinations_with_replacement(interesting_columns, self.max_dimensions)\n",
    "        clustering_columns = [self.uniquify(clustering) for clustering in clustering_columns]\n",
    "        sort_columns = interesting_columns        \n",
    "        clusterings_with_runtimes = reduce(lambda x,y: x+y,[self.estimate_total_runtimes(clustering_cols, sort_columns) for clustering_cols in clustering_columns])\n",
    "        clusterings_with_runtimes.sort(key=lambda x: x[2], reverse=False)\n",
    "        \n",
    "        return clusterings_with_runtimes[0:first_k]\n",
    "    \n",
    "    \n",
    "    def estimate_distinct_values_per_chunk(self, column, clustering_columns, sorting_column, dimension_cardinalities):\n",
    "        raise NotImplementedError(\"Each model should provide this function\")\n",
    "        \n",
    "    def estimate_distinct_values_per_chunk_at_statistics_time(self, column, table):        \n",
    "        if column in self.sorted_columns_during_creation.get(table, {}):\n",
    "            # Column was globally sorted\n",
    "            average_count_per_distinct_value = self.table_sizes[table] / self.distinct_values[table][column]\n",
    "            return math.ceil(self.target_chunksize / average_count_per_distinct_value)\n",
    "        else:\n",
    "            # Column was not globally sorted\n",
    "            total_distinct_values = self.distinct_values[table][column]\n",
    "            return min(total_distinct_values, self.target_chunksize)        \n",
    "    \n",
    "    def estimate_table_scan_runtime(self, clustering_columns, sorting_column, split_factors):\n",
    "        def compute_unprunable_parts(row, split_factors):\n",
    "            def clustering_columns_correlated_to(column):\n",
    "                return [clustering_column for clustering_column in clustering_columns if column in self.correlations.get(clustering_column, {})]\n",
    "            \n",
    "            def correlates_to_clustering_column(column):\n",
    "                return len(clustering_columns_correlated_to(column)) > 0\n",
    "\n",
    "            column_name = row['COLUMN_NAME']\n",
    "\n",
    "            if not row['useful_for_pruning']:\n",
    "                selectivity = 1\n",
    "            elif column_name in clustering_columns:\n",
    "                scan_selectivity = row['selectivity']\n",
    "                split_factor = split_factors[clustering_columns.index(column_name)]\n",
    "                selectivity =  self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor)\n",
    "            elif correlates_to_clustering_column(column_name):\n",
    "                scan_selectivity = row['selectivity']\n",
    "                correlated_clustering_columns = clustering_columns_correlated_to(column_name)\n",
    "                \n",
    "                # ToDo this is hacky, but for now assume there is just one correlated column\n",
    "                assert len(correlated_clustering_columns) == 1, f\"expected just 1 correlated clustering column, but got {len(correlated_clustering_columns)}\"\n",
    "                \n",
    "                split_factor = split_factors[clustering_columns.index(correlated_clustering_columns[0])]\n",
    "                selectivity = min(1, 1.2 * self.round_up_to_next_multiple(scan_selectivity, 1 / split_factor))\n",
    "            else:\n",
    "                selectivity = 1\n",
    "            \n",
    "            return selectivity\n",
    "        \n",
    "        def compute_tablescan_runtime(row, sorting_column):\n",
    "            assert row['estimated_input_rows'] > 1, row\n",
    "            assert row['runtime_per_input_row'] > 0, row\n",
    "            assert row['runtime_per_output_row'] > 0, row\n",
    "            input_row_count = row['estimated_input_rows']\n",
    "            \n",
    "            if row['COLUMN_NAME'] == sorting_column and row['benefits_from_sorting']:\n",
    "                # TODO is this the best way to simulate sorted access?\n",
    "                input_row_count = np.log2(input_row_count)\n",
    "\n",
    "            runtime = input_row_count * row['runtime_per_input_row'] + row['OUTPUT_ROWS'] * row['runtime_per_output_row']\n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        runtime = 0\n",
    "        scans_per_query = self.table_scans.sort_values(['INPUT_ROWS'], ascending=False).groupby(['QUERY_HASH', 'GET_TABLE_HASH'])\n",
    "        for _, scans in scans_per_query:\n",
    "            number_of_scans = len(scans)\n",
    "            assert number_of_scans > 0 and number_of_scans < 25, f\"weird scan length: {number_of_scans}\\nScans:\\n{scans}\"\n",
    "            # TODO: kinda unrealistic assumption: everything not in the table scan result can be pruned\n",
    "                          \n",
    "            unprunable_parts = scans.apply(compute_unprunable_parts, axis=1, args=(split_factors,))            \n",
    "            unprunable_part = unprunable_parts.product()\n",
    "            assert unprunable_part > 0, \"no unprunable part\"\n",
    "            \n",
    "            estimated_pruned_table_size = self.round_up_to_next_multiple(unprunable_part * self.table_size, CHUNK_SIZE)\n",
    "            \n",
    "            runtimes = pd.DataFrame()\n",
    "            runtimes['QUERY_HASH'] = scans['QUERY_HASH']\n",
    "            runtimes['runtime_per_input_row'] = scans['time_per_input_row']\n",
    "            runtimes['runtime_per_output_row'] = scans['time_per_output_row']\n",
    "            runtimes['COLUMN_NAME'] = scans['COLUMN_NAME']\n",
    "            runtimes['benefits_from_sorting'] = scans['benefits_from_sorting']\n",
    "            # the pruned table inputs should be reflected in 'estimated_input_rows'\n",
    "            runtimes['estimated_input_rows'] = scans['INPUT_ROWS']\n",
    "            runtimes['OUTPUT_ROWS'] = scans['OUTPUT_ROWS']\n",
    "\n",
    "            runtimes.iloc[0, runtimes.columns.get_loc('estimated_input_rows')] = estimated_pruned_table_size                                    \n",
    "            assert runtimes['estimated_input_rows'].iloc[0] == estimated_pruned_table_size, f\"value is {runtimes.iloc[0]['estimated_input_rows']}, but should be {estimated_pruned_table_size}\"\n",
    "            # TODO modify input sizes of subsequent scans\n",
    "            \n",
    "            scan_runtimes = runtimes.apply(compute_tablescan_runtime, axis=1, args=(sorting_column,))\n",
    "            runtime += scan_runtimes.sum()\n",
    "        return runtime\n",
    "\n",
    "    def estimate_chunk_count(self, scans, clustering_columns, dimension_cardinalities):\n",
    "        raise NotImplementedError(\"Subclass responsibility\")\n",
    "    \n",
    "    def get_chunk_count_factor(self, row, side, clustering_columns, dimension_cardinalities):\n",
    "        query_hash = row['QUERY_HASH']\n",
    "        if side == \"PROBE\":\n",
    "            input_rows = row['PROBE_TABLE_ROW_COUNT']\n",
    "            assert row['PROBE_TABLE'] == self.table_name, \"Call this function only for the own table\"\n",
    "        elif side == \"BUILD\":\n",
    "            input_rows = row['BUILD_TABLE_ROW_COUNT']\n",
    "            assert row['BUILD_TABLE'] == self.table_name, \"Call this function only for the own table\"\n",
    "        else:\n",
    "            raise ValueError(\"side must be PROBE or BUILD\")\n",
    "\n",
    "        expected_chunk_count = self.estimate_chunk_count(query_hash, input_rows, clustering_columns, dimension_cardinalities)\n",
    "        min_chunk_count = math.ceil(input_rows / self.target_chunksize)\n",
    "        max_chunk_count = math.ceil(self.table_size / self.target_chunksize)\n",
    "\n",
    "        CHUNK_COUNT_SPEEDUP_LOW = 3\n",
    "        CHUNK_COUNT_SPEEDUP_HIGH = 1\n",
    "\n",
    "        current_speedup = self.interpolate(CHUNK_COUNT_SPEEDUP_LOW, CHUNK_COUNT_SPEEDUP_HIGH, (expected_chunk_count - min_chunk_count) / max_chunk_count)\n",
    "        #print(f\"current speedup: {current_speedup}\")\n",
    "\n",
    "        old_clustering_columns = self.sorted_columns_during_creation[self.table_name]\n",
    "        old_dimension_cardinalities = [self.statistic_time_dimension_cardinalities()] * len(old_clustering_columns)\n",
    "        old_expected_chunk_count = self.estimate_chunk_count(query_hash, input_rows, old_clustering_columns, old_dimension_cardinalities)\n",
    "        old_speedup = self.interpolate(CHUNK_COUNT_SPEEDUP_LOW, CHUNK_COUNT_SPEEDUP_HIGH, (old_expected_chunk_count - min_chunk_count) / max_chunk_count)\n",
    "        #print(f\"old speedup: {old_speedup}\")\n",
    "\n",
    "        return 1 * old_speedup / current_speedup\n",
    "    \n",
    "    def estimate_join_runtime(self, clustering_columns, sorting_column, dimension_cardinalities):\n",
    "        def compute_join_runtime(row, sorting_column):\n",
    "            if \"JoinHash\" in row['DESCRIPTION']:\n",
    "                probe_column = row['PROBE_COLUMN']\n",
    "                if row['PROBE_TABLE'] == self.table_name:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    probe_column_is_sorted = row['PROBE_SORTED'] and probe_column == sorting_column\n",
    "                    materialize_probe_factor = self.get_chunk_count_factor(row, \"PROBE\", clustering_columns, dimension_cardinalities)\n",
    "                else:\n",
    "                    probe_column_was_sorted = row['PROBE_SORTED'] and probe_column in self.sorted_columns_during_creation.get(row['PROBE_TABLE'], {})\n",
    "                    probe_column_is_sorted = probe_column_was_sorted\n",
    "                    materialize_probe_factor = 1\n",
    "                    \n",
    "                build_column = row['BUILD_COLUMN']\n",
    "                if row['BUILD_TABLE'] == self.table_name:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(self.table_name, {})\n",
    "                    build_column_is_sorted = row['BUILD_SORTED'] and build_column == sorting_column\n",
    "                    materialize_build_factor = self.get_chunk_count_factor(row, \"BUILD\", clustering_columns, dimension_cardinalities)\n",
    "                else:\n",
    "                    build_column_was_sorted = row['BUILD_SORTED'] and build_column in self.sorted_columns_during_creation.get(row['BUILD_TABLE'], {})\n",
    "                    build_column_is_sorted = build_column_was_sorted\n",
    "                    materialize_build_factor = 1\n",
    "\n",
    "                time_materialize_probe = row['PROBE_SIDE_MATERIALIZING_NS']\n",
    "                time_materialize_build = row['BUILD_SIDE_MATERIALIZING_NS']                \n",
    "                \n",
    "                def get_materialize_factor(column, was_globally_sorted, is_sorted, expected_distinct_value_count):\n",
    "                    # Assumption: \"was_sorted\" implies global sortedness, i.e., both clustering and chunkwise sorting\n",
    "                    # This is true when the clustering produced by the table generator is used by the plan cache exporter\n",
    "                    # If the data has been re-clustered before the plan cache exporter runs, there has to be some system inside Hyrise which tracks the current clustering config\n",
    "                    \n",
    "                    # Sortedness seems to yield a speed up of approx. 1.6, regardless of the number of distinct values\n",
    "                    SORT_SPEEDUP = 1.6\n",
    "                    sortedness_factor = 1                    \n",
    "                    was_sorted = was_globally_sorted\n",
    "                    if was_sorted:\n",
    "                        sortedness_factor *= SORT_SPEEDUP\n",
    "                    if is_sorted:\n",
    "                        sortedness_factor /= SORT_SPEEDUP\n",
    "                    \n",
    "\n",
    "                    # The influence of clustering depends on the number of distinct values\n",
    "                    CLUSTERING_SPEEDUP_LOW = 1.84\n",
    "                    CLUSTERING_SPEEDUP_HIGH = 1\n",
    "                    clustering_factor = 1\n",
    "                    statistics_time_distinct_value_count = self.estimate_distinct_values_per_chunk_at_statistics_time(column, self.table_name);\n",
    "                    clustering_factor *= self.interpolate(CLUSTERING_SPEEDUP_LOW, CLUSTERING_SPEEDUP_HIGH, statistics_time_distinct_value_count / self.target_chunksize)\n",
    "                    clustering_factor /= self.interpolate(CLUSTERING_SPEEDUP_LOW, CLUSTERING_SPEEDUP_HIGH, expected_distinct_value_count / self.target_chunksize)\n",
    "                        \n",
    "                    return sortedness_factor * clustering_factor                \n",
    "                \n",
    "                if row['PROBE_TABLE'] == self.table_name and row['PROBE_SORTED']:\n",
    "                    expected_distinct_values_probe = self.estimate_distinct_values_per_chunk(probe_column, clustering_columns, sorting_column, dimension_cardinalities)\n",
    "                    materialize_probe_factor *= get_materialize_factor(probe_column, probe_column_was_sorted, probe_column_is_sorted, expected_distinct_values_probe)\n",
    "                    \n",
    "                if row['BUILD_TABLE'] == self.table_name and row['BUILD_SORTED']:\n",
    "                    expected_distinct_values_build = self.estimate_distinct_values_per_chunk(build_column, clustering_columns, sorting_column, dimension_cardinalities)\n",
    "                    materialize_build_factor *= get_materialize_factor(build_column, build_column_was_sorted, build_column_is_sorted, expected_distinct_values_build)                \n",
    "                \n",
    "                time_materialize = time_materialize_probe * materialize_probe_factor + time_materialize_build *  materialize_build_factor\n",
    "\n",
    "\n",
    "                # unchanged\n",
    "                time_cluster = row['CLUSTERING_NS']\n",
    "                \n",
    "                # unchanged\n",
    "                time_build = row['BUILDING_NS']\n",
    "                \n",
    "                            \n",
    "                time_probe = row['PROBING_NS']\n",
    "                probe_factor = 1\n",
    "                #if probe_column_is_sorted and probe_column_is_clustered:\n",
    "                #    if not probe_column_was_sorted:\n",
    "                #        probe_factor = 0.7\n",
    "                #    else:\n",
    "                #        probe_factor = 1\n",
    "                #elif probe_column_is_sorted or probe_column_is_clustered:\n",
    "                #    if not probe_column_was_sorted:\n",
    "                #        probe_factor = 0.9\n",
    "                #    else:\n",
    "                #        probe_factor = 1.1\n",
    "                #elif probe_column_was_sorted:\n",
    "                #    # probe column is now neither sorted nor clustered\n",
    "                #    probe_factor = 1.4\n",
    "                \n",
    "                time_probe *= probe_factor                \n",
    "                \n",
    "                # unchanged\n",
    "                time_write_output = row['OUTPUT_WRITING_NS']\n",
    "                \n",
    "                \n",
    "                \n",
    "                # TODO: how to deal with the difference between RUNTIME_NS and sum(stage_runtimes)?\n",
    "                runtime = time_materialize + time_cluster + time_build + time_probe + time_write_output\n",
    "            else:\n",
    "                runtime = row['RUNTIME_NS']\n",
    "                \n",
    "            return runtime * self.query_frequency(row['QUERY_HASH'])\n",
    "        \n",
    "        join_runtimes = self.joins.apply(compute_join_runtime, axis=1, args=(sorting_column,))\n",
    "        return join_runtimes.sum()\n",
    "                \n",
    "    def estimate_total_runtimes(self, clustering_columns, sorting_columns):\n",
    "        #print(f\"testing clustering {clustering_columns} with sorting columns {sorting_columns}\")\n",
    "        dimension_cardinalities = self.get_dimension_cardinalities(clustering_columns)\n",
    "        total_runtimes = {sorting_column: 0 for sorting_column in sorting_columns}\n",
    "        clusterings = []\n",
    "        for sorting_column in sorting_columns:\n",
    "            runtime = self.estimate_total_runtime(clustering_columns, sorting_column, dimension_cardinalities)\n",
    "            clusterings.append([list(zip(clustering_columns, dimension_cardinalities)), sorting_column, runtime])\n",
    "        \n",
    "        #clusterings = [[list(zip(clustering_columns, dimension_cardinalities)), sorting_column, np.int64(total_runtimes[sorting_column])] for sorting_column in sorting_columns]\n",
    "        return clusterings\n",
    "    \n",
    "    def estimate_total_runtime(self, clustering_columns, sorting_column, dimension_cardinalities):\n",
    "        runtime = 0\n",
    "        runtime += self.estimate_table_scan_runtime(clustering_columns, sorting_column, dimension_cardinalities)\n",
    "        runtime += self.estimate_join_runtime(clustering_columns, sorting_column, dimension_cardinalities)\n",
    "        \n",
    "        return runtime\n",
    "    \n",
    "    def get_dimension_cardinalities(self, clustering_columns):\n",
    "        raise NotImplementedError(\"Subclasses must override this function\")\n",
    "        \n",
    "    def statistic_time_dimension_cardinalities(self):\n",
    "        raise NotImplementedError(\"Subclasses must override this function\")\n",
    "        \n",
    "    def interpolate(self, low, high, percentage):\n",
    "        assert percentage >= 0 and percentage <= 1, f\"percentage must between 0 and 1, but is {percentage}\"\n",
    "        return (1 - percentage) * low + (percentage * high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisjointClustersModel(SingleTableMdcModel):\n",
    "    \n",
    "    def __init__(self, max_dimensions, query_frequencies, table_name, table_scans, table_sizes, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation):\n",
    "        super().__init__(max_dimensions, query_frequencies, table_name, table_scans, table_sizes, distinct_values, target_chunksize, correlations, joins, sorted_columns_during_creation)\n",
    "        \n",
    "    # This function should only be called for the own table, not for others\n",
    "    def estimate_distinct_values_per_chunk(self, column, clustering_columns, chunk_sorting_column, dimension_cardinalities):\n",
    "        total_distinct_values = self.distinct_values[self.table_name][column]\n",
    "        \n",
    "        if column in clustering_columns:\n",
    "            index = clustering_columns.index(column)\n",
    "            clusters_for_column = dimension_cardinalities[index]\n",
    "            return min(self.target_chunksize, total_distinct_values / clusters_for_column)\n",
    "        else:\n",
    "            # TODO cluster wise sorting\n",
    "            return min(self.target_chunksize, total_distinct_values)\n",
    "        \n",
    "    # This function should only be called for the own table, not for others\n",
    "    def estimate_chunk_count(self, query_hash, join_input_rows, clustering_columns, dimension_cardinalities):        \n",
    "        # TODO include or exclude scans that do not benefit from pruning? Included for now        \n",
    "        table_scans = self.table_scans[self.table_scans['QUERY_HASH'] == query_hash]        \n",
    "        table_scans = table_scans[table_scans['useful_for_pruning']]\n",
    "        \n",
    "        if len(table_scans) > 0:\n",
    "            #print(f\"For query hash {query_hash}, there are {len(table_scans)} scans on {self.table_name}\")\n",
    "            def get_denseness_factor(row):\n",
    "                column = row['COLUMN_NAME']\n",
    "                if column in clustering_columns:\n",
    "                    # TODO more precise estimate\n",
    "                    denseness_factor = 1\n",
    "                else:\n",
    "                    denseness_factor = row['selectivity']\n",
    "\n",
    "                return denseness_factor\n",
    "\n",
    "            denseness_factors = table_scans.apply(get_denseness_factor, axis=1)\n",
    "            denseness_factor = denseness_factors.product()\n",
    "            #print(f\"denseness factor is {denseness_factor}\")\n",
    "        else:\n",
    "            denseness_factor = 1        \n",
    "        \n",
    "        chunk_count = math.ceil(join_input_rows / (self.target_chunksize * denseness_factor))\n",
    "        max_chunks = math.ceil(self.table_size / self.target_chunksize)\n",
    "        assert chunk_count <= max_chunks, f\"estimated {chunk_count} chunks, but {self.table_name} got only {max_chunks}\\nDenseness: {denseness_factor}\"\n",
    "        \n",
    "        return chunk_count\n",
    "    \n",
    "    def statistic_time_dimension_cardinalities(self):\n",
    "        return math.ceil(self.table_size / self.target_chunksize)\n",
    "            \n",
    "    def get_dimension_cardinalities(self, clustering_columns):\n",
    "        # ToDo what if we aim at less than number of chunks clusters, i.e. multiple chunks per cluster?\n",
    "        target_cluster_count = int(1.1 * self.table_size / self.target_chunksize)\n",
    "        # idea: fixed size for join columns, variable amount for scan columns\n",
    "        \n",
    "        join_columns = list(filter(lambda x: self.is_join_column(x), clustering_columns))\n",
    "        scan_columns = list(filter(lambda x: self.is_scan_column(x), clustering_columns))\n",
    "        intersecting_columns = set(join_columns).intersection(set(scan_columns))\n",
    "        assert len(intersecting_columns) == 0, f\"The following columns are used as both join and scan column: {intersecting_columns}\"\n",
    "        \n",
    "        if len(scan_columns) == 0:\n",
    "            CLUSTERS_PER_JOIN_COLUMN = math.ceil(math.pow(target_cluster_count, 1/len(join_columns)))\n",
    "        else: \n",
    "            CLUSTERS_PER_JOIN_COLUMN = 3;\n",
    "        # Assumption: uniform distribution (in the sense that every cluster actually exists)\n",
    "        num_join_clusters = math.pow(CLUSTERS_PER_JOIN_COLUMN, len(join_columns))\n",
    "        assert num_join_clusters <= 1.5 * target_cluster_count, f\"Would get {num_join_clusters} clusters for join columns, but aimed at at most {target_cluster_count} clusters\"\n",
    "    \n",
    "        # only applies to scan columns\n",
    "        desired_scan_clusters_count = math.ceil(target_cluster_count / num_join_clusters)\n",
    "        individual_distinct_values = [self.distinct_values[self.table_name][column] for column in scan_columns]\n",
    "        log_distinct_values = [math.ceil(0.5+np.log2(x)) for x in individual_distinct_values]\n",
    "        log_distinct_values_product = reduce(operator.mul, log_distinct_values, 1)\n",
    "        assert log_distinct_values_product > 0, \"cannot have a distinct value count of 0\"\n",
    "\n",
    "        global_modification_factor = desired_scan_clusters_count / log_distinct_values_product\n",
    "        num_scan_dimensions = len(scan_columns)\n",
    "        individual_modification_factor = np.power(global_modification_factor, 1.0 / max(1, num_scan_dimensions))\n",
    "        \n",
    "        join_column_cluster_counts = [CLUSTERS_PER_JOIN_COLUMN] * len(join_columns)\n",
    "        scan_column_cluster_counts = [math.ceil(x * individual_modification_factor) for x in log_distinct_values]\n",
    "        \n",
    "        \n",
    "        # Merge join and scan columns\n",
    "        join_index = 0\n",
    "        scan_index = 0\n",
    "        cluster_counts = []\n",
    "        for clustering_column in clustering_columns:\n",
    "            if clustering_column in join_columns:\n",
    "                cluster_counts.append(join_column_cluster_counts[join_index])\n",
    "                join_index += 1\n",
    "            elif clustering_column in scan_columns:\n",
    "                cluster_counts.append(scan_column_cluster_counts[scan_index])\n",
    "                scan_index += 1\n",
    "        assert join_index == len(join_columns), f\"Processed the wrong number of join columns: {join_index} instead of {len(join_column_cluster_counts)}\"\n",
    "        assert scan_index == len(scan_columns), f\"Processed the wrong number of scan columns: {scan_index} instead of {len(scan_column_cluster_counts)}\"\n",
    "        assert len(cluster_counts) == len(clustering_columns), f\"Expected {len(clustering_columns)} cluster counts, but got {len(cluster_counts)}\"\n",
    "        \n",
    "        # testing\n",
    "        actual_cluster_count = reduce(operator.mul, cluster_counts, 1)\n",
    "        assert actual_cluster_count > 0, \"there was a split up factor of 0\"\n",
    "        assert actual_cluster_count <= 1.5 * target_cluster_count, f\"Wanted at most {target_cluster_count} clusters, but got {actual_cluster_count}\\nConfig: {clustering_columns}\\nCluster sizes: {cluster_counts}\"\n",
    "        estimated_chunksize = self.table_size / actual_cluster_count\n",
    "        assert estimated_chunksize <= self.target_chunksize, \"chunks should be smaller, not larger than target_chunksize\"\n",
    "        allowed_percentage = 0.55\n",
    "        if estimated_chunksize < allowed_percentage * self.target_chunksize:\n",
    "            print(f\"Warning: chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\")\n",
    "        #assert estimated_chunksize >= allowed_percentage * self.target_chunksize, f\"chunks should not be too much smaller than target_chunksize: {estimated_chunksize} < {allowed_percentage} * {self.target_chunksize}\"\n",
    "        \n",
    "        return cluster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 2]],\n",
    "            'orders': [['o_orderdate', 2]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_model(table_name, max_dimensions=2):    \n",
    "    query_frequencies = get_query_frequencies()\n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    start_time_table = datetime.now()\n",
    "    single_table_scans = extract_single_table(scans, table_name)\n",
    "\n",
    "    model = DisjointClustersModel(max_dimensions, query_frequencies, table_name, single_table_scans, table_sizes, distinct_values, CHUNK_SIZE, correlations.get(table_name, {}), joins, sorted_columns_during_creation)\n",
    "    return model\n",
    "\n",
    "model = create_model(\"store_sales\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.suggest_clustering(20)\n",
    "#model.estimate_distinct_values_per_chunk_at_statistics_time(\"l_orderkey\", \"lineitem\")\n",
    "#print(model.estimate_distinct_values_per_chunk(\"l_orderkey\", [\"l_orderkey\", \"l_partkey\"], \"l_orderkey\", [20,5]))\n",
    "\n",
    "#model.estimate_chunk_count(\"9762c3a887e47469\", 77313, [\"l_orderkey\"], [92])\n",
    "#row = model.joins.iloc[140]\n",
    "#model.get_chunk_count_factor(row, \"BUILD\", [\"l_orderkey\", \"l_shipdate\"], [5, 20])\n",
    "\n",
    "if BENCHMARK == \"TPCH\":\n",
    "    time0 = model.estimate_total_runtime([\"l_orderkey\"], \"l_orderkey\", [100])\n",
    "    time1 = model.estimate_total_runtime([\"l_shipdate\", \"l_orderkey\"], \"l_orderkey\", [20, 5])\n",
    "    print(f\"nosort: {time0}\")\n",
    "    print(f\"best: {time1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ss_sold_date_sk', 'ss_item_sk', 'ss_store_sk', 'ss_hdemo_sk', 'ss_customer_sk', 'ss_addr_sk', 'ss_promo_sk', 'ss_cdemo_sk', 'ss_sold_time_sk', 'ss_ticket_number']\n",
      "Execution time: 0:05:58.548003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[('ss_sold_time_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2829390158.8607645],\n",
       " [[('ss_ticket_number', 48)], 'ss_sold_date_sk', 2847072689.2445374],\n",
       " [[('ss_addr_sk', 7), ('ss_sold_time_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2848963504.471651],\n",
       " [[('ss_item_sk', 7), ('ss_sold_time_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2850495520.5673],\n",
       " [[('ss_sold_time_sk', 48)], 'ss_sold_date_sk', 2850735004.9067926],\n",
       " [[('ss_sold_date_sk', 7), ('ss_sold_time_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2851683046.8463097],\n",
       " [[('ss_cdemo_sk', 7), ('ss_sold_time_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2851835323.4158993],\n",
       " [[('ss_customer_sk', 7), ('ss_sold_time_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2853284608.0004454],\n",
       " [[('ss_hdemo_sk', 7), ('ss_sold_time_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2853688203.135888],\n",
       " [[('ss_store_sk', 7), ('ss_sold_time_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2853716991.8882627],\n",
       " [[('ss_promo_sk', 7), ('ss_sold_time_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2853718105.215734],\n",
       " [[('ss_addr_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2855156157.557379],\n",
       " [[('ss_item_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2856688173.6530275],\n",
       " [[('ss_sold_date_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2857875699.932037],\n",
       " [[('ss_cdemo_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2858027976.501627],\n",
       " [[('ss_customer_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2859477261.086173],\n",
       " [[('ss_hdemo_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2859880856.221616],\n",
       " [[('ss_store_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2859909644.9739904],\n",
       " [[('ss_promo_sk', 7), ('ss_ticket_number', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2859910758.3014617],\n",
       " [[('ss_item_sk', 7), ('ss_addr_sk', 7)],\n",
       "  'ss_sold_date_sk',\n",
       "  2876261519.2639146]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "clusterings = model.suggest_clustering(20)\n",
    "end_time = datetime.now()\n",
    "print(f\"Execution time: {end_time - start_time}\")\n",
    "clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not computing clustering for date_dim, as it has only 73049 rows\n",
      "Not computing clustering for item, as it has only 18000 rows\n",
      "Not computing clustering for store, as it has only 12 rows\n",
      "Not computing clustering for household_demographics, as it has only 7200 rows\n",
      "['cd_gender', 'cd_marital_status', 'cd_education_status', 'cd_demo_sk']\n",
      "Done computing clustering for customer_demographics (0:00:05.625876)\n",
      "Not computing clustering for promotion, as it has only 300 rows\n",
      "Not computing clustering for time_dim, as it has only 86400 rows\n",
      "['ss_sold_date_sk', 'ss_item_sk', 'ss_store_sk', 'ss_hdemo_sk', 'ss_customer_sk', 'ss_addr_sk', 'ss_promo_sk', 'ss_cdemo_sk', 'ss_sold_time_sk', 'ss_ticket_number']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cc6dd943aed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclusterings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mcreate_benchmark_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-cc6dd943aed5>\u001b[0m in \u001b[0;36mcreate_benchmark_configs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mmax_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDisjointClustersModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_table_scans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistinct_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_columns_during_creation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtable_clusterings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtable_clustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable_clusterings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_benchmark_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-02ee6545c704>\u001b[0m in \u001b[0;36msuggest_clustering\u001b[0;34m(self, first_k)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mclustering_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniquify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msort_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteresting_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mclusterings_with_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_total_runtimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering_cols\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mclusterings_with_runtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-02ee6545c704>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mclustering_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniquify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msort_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteresting_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mclusterings_with_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_total_runtimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclustering_cols\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mclusterings_with_runtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-02ee6545c704>\u001b[0m in \u001b[0;36mestimate_total_runtimes\u001b[0;34m(self, clustering_columns, sorting_columns)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mclusterings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msorting_column\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorting_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_total_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_cardinalities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mclusterings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_cardinalities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-02ee6545c704>\u001b[0m in \u001b[0;36mestimate_total_runtime\u001b[0;34m(self, clustering_columns, sorting_column, dimension_cardinalities)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mruntime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_table_scan_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_cardinalities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mruntime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_join_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_cardinalities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-02ee6545c704>\u001b[0m in \u001b[0;36mestimate_join_runtime\u001b[0;34m(self, clustering_columns, sorting_column, dimension_cardinalities)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUERY_HASH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mjoin_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_join_runtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorting_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjoin_runtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6485\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6486\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                                           \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                                           labels=labels)\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-02ee6545c704>\u001b[0m in \u001b[0;36mcompute_join_runtime\u001b[0;34m(row, sorting_column)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mprobe_column_was_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROBE_SORTED'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mprobe_column\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_columns_during_creation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0mprobe_column_is_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROBE_SORTED'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mprobe_column\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msorting_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0mmaterialize_probe_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk_count_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PROBE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_cardinalities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mprobe_column_was_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROBE_SORTED'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mprobe_column\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_columns_during_creation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROBE_TABLE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-02ee6545c704>\u001b[0m in \u001b[0;36mget_chunk_count_factor\u001b[0;34m(self, row, side, clustering_columns, dimension_cardinalities)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mold_clustering_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_columns_during_creation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mold_dimension_cardinalities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistic_time_dimension_cardinalities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_clustering_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mold_expected_chunk_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_chunk_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_hash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_clustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_dimension_cardinalities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mold_speedup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNK_COUNT_SPEEDUP_LOW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_COUNT_SPEEDUP_HIGH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mold_expected_chunk_count\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_chunk_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax_chunk_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m#print(f\"old speedup: {old_speedup}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-14a80aeed477>\u001b[0m in \u001b[0;36mestimate_chunk_count\u001b[0;34m(self, query_hash, join_input_rows, clustering_columns, dimension_cardinalities)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mestimate_chunk_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_hash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_input_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclustering_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_cardinalities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# TODO include or exclude scans that do not benefit from pruning? Included for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtable_scans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUERY_HASH'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mquery_hash\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtable_scans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'useful_for_pruning'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   3357\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   3358\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3359\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   3360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 1350\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1238\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute clustering configs for all relevant tables\n",
    "# Currently deactivated, but working\n",
    "\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def extract_single_table(table_scans, table_name):\n",
    "    return table_scans[table_scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def get_table_names(table_scans, joins):\n",
    "    return table_scans['TABLE_NAME'].unique()\n",
    "\n",
    "\n",
    "def default_benchmark_config():    \n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        config = {\n",
    "            'lineitem': [['l_shipdate', 2]],\n",
    "            'orders': [['o_orderdate', 2]]\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        config = dict()\n",
    "    else:        \n",
    "        raise Exception(\"unknown benchmark, please provide a default config\")\n",
    "    return config\n",
    "\n",
    "def get_correlations():\n",
    "    if BENCHMARK == \"TPCH\":\n",
    "        correlations = {\n",
    "            'lineitem': {\n",
    "                'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "                'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "            }\n",
    "        }\n",
    "    elif BENCHMARK == \"TPCDS\":\n",
    "        correlations = dict()\n",
    "    else:\n",
    "        raise Exception(\"unknown benchmark, please provide correlation information\")\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def format_table_clustering(clustering_config):\n",
    "    # input format: List of [ [(column, split)+ ], sorting_column, runtime ]\n",
    "    # output format: List of [ (column, split)+ ] - sorting column integrated if necessary\n",
    "    \n",
    "    assert len(clustering_config) == 3, \"config should have exactly three entries: clustering columns, sort column, runtime\"\n",
    "    clustering_columns = clustering_config[0]\n",
    "    assert len(clustering_columns) <= 3, \"atm the model is at most 3-dimensional\"\n",
    "    #print(f\"clustering columns are {clustering_columns}\")\n",
    "    last_clustering_column = clustering_columns[-1]\n",
    "    last_clustering_column_name = last_clustering_column[0]\n",
    "    #print(f\"last column is {last_clustering_column_name}\")\n",
    "    sorting_column = clustering_config[1]\n",
    "    #print(f\"sort column is {sorting_column}\")\n",
    "    \n",
    "    result = clustering_columns\n",
    "    if last_clustering_column_name != sorting_column:\n",
    "        result = clustering_columns + [(sorting_column, 1)]\n",
    "        \n",
    "    #print(f\"in: {clustering_config}\")\n",
    "    #print(f\"out: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_config_name(clustering_config):\n",
    "    # Input: config-dict\n",
    "    \n",
    "    # List of lists. Each secondary list contains clustering information for a table\n",
    "    table_configs = [clustering_config[table] for table in clustering_config]\n",
    "    config_entries = [[f\"{config_entry[0]}-{config_entry[1]}\" for config_entry in config] for config in table_configs]\n",
    "    table_entries = [\"_\".join(config) for config in config_entries]\n",
    "    return \"_\".join(table_entries)\n",
    "\n",
    "\n",
    "def create_benchmark_configs():    \n",
    "    start_time = datetime.now()\n",
    "    clusterings = {\"default\" : default_benchmark_config()}\n",
    "    query_frequencies = get_query_frequencies()\n",
    "    \n",
    "    distinct_values = get_distinct_values_count()\n",
    "    joins = load_join_statistics()    \n",
    "    sorted_columns_during_creation = get_sorted_columns_during_creation()\n",
    "    correlations = get_correlations()\n",
    "    table_names = get_table_names(scans)\n",
    "    for table_name in table_names:\n",
    "        start_time_table = datetime.now()\n",
    "        single_table_scans = extract_single_table(scans, table_name)\n",
    "        table_size = table_sizes[table_name]\n",
    "        if table_size <= 3 * CHUNK_SIZE:\n",
    "            print(f\"Not computing clustering for {table_name}, as it has only {table_size} rows\")\n",
    "            continue\n",
    "\n",
    "        max_dimensions = 2\n",
    "        model = DisjointClustersModel(max_dimensions, query_frequencies, table_name, single_table_scans, table_sizes, distinct_values, CHUNK_SIZE, correlations.get(table_name, {}), joins, sorted_columns_during_creation)\n",
    "        table_clusterings = model.suggest_clustering(3)\n",
    "        for table_clustering in table_clusterings:\n",
    "            config = default_benchmark_config()\n",
    "            config[table_name] = format_table_clustering(table_clustering)\n",
    "            config_name = get_config_name(config)\n",
    "            clusterings[config_name] = config\n",
    "        end_time_table = datetime.now()\n",
    "        print(f\"Done computing clustering for {table_name} ({end_time_table - start_time_table})\")\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print(f\"Computed all clusterings in {end_time - start_time}\")\n",
    "    \n",
    "    return clusterings\n",
    "\n",
    "create_benchmark_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outdated code fragments (older model versions) are kept below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"This assertion failure only serves to stop execution here when clicking Cells->Run all. You can safely ignore it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(AbstractModel):\n",
    "    \n",
    "    def __init__(self, table_scans, correlations = {}):\n",
    "        super().__init__(table_scans, correlations)        \n",
    "    \n",
    "    def suggest_clustering(self, first_k=1):\n",
    "        interesting_columns = self.extract_interesting_columns()\n",
    "\n",
    "        pairs = itertools.product(interesting_columns, interesting_columns)                \n",
    "        total_runtimes = [self.estimate_total_runtime(self.table_scans, clustering_columns) for clustering_columns in pairs]\n",
    "        total_runtimes.sort(key=lambda x: x[1], reverse=False)\n",
    "        \n",
    "        return total_runtimes[0:first_k]\n",
    "        \n",
    "    \n",
    "    def estimate_total_runtime(self, single_table, clustering_columns):\n",
    "        total_runtime = 0\n",
    "        \n",
    "        pruning_col = clustering_columns[0]\n",
    "        sorted_col = clustering_columns[1]\n",
    "        def compute_runtime(row):\n",
    "            col_name = row['COLUMN_NAME']\n",
    "            if pruning_col == sorted_col:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_log_runtime']\n",
    "                else:\n",
    "                    if col_name in self.correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "            else:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_runtime']\n",
    "                elif col_name == sorted_col:\n",
    "                    # TODO: should this be affected by correlation?\n",
    "                    # we will get less chunks, so a linear scan should be close to optimal_runtime,\n",
    "                    # but log time should beat it anyway\n",
    "                    return row['log_runtime']\n",
    "                else:\n",
    "                    if col_name in self.correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "                    \n",
    "        effective_runtime = single_table.apply(compute_runtime, axis=1)\n",
    "        return [clustering_columns, effective_runtime.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store additional statistics\n",
    "# TODO keep?\n",
    "\n",
    "assert_correct_statistics_loaded()\n",
    "\n",
    "def round_up_to_chunksize(row):\n",
    "    if row['OUTPUT_ROWS'] % CHUNK_SIZE == 0:\n",
    "        return row['OUTPUT_ROWS']\n",
    "    else:\n",
    "        return row['OUTPUT_ROWS'] + (CHUNK_SIZE - (row['OUTPUT_ROWS'] % CHUNK_SIZE))\n",
    "\n",
    "scans['pruned_minimum_input_rows'] = scans.apply(round_up_to_chunksize, axis=1)\n",
    "\n",
    "scans['selectivity'] = scans['OUTPUT_ROWS'] / scans['INPUT_ROWS']\n",
    "scans['actual_selectivity'] = scans['SINGLE_OUTPUT_ROWS'] / scans['SINGLE_INPUT_ROWS']\n",
    "\n",
    "scans['time_per_ir'] = scans['RUNTIME_NS'] / scans['INPUT_ROWS']\n",
    "scans['time_per_or'] = scans['RUNTIME_NS'] / scans['OUTPUT_ROWS']\n",
    "\n",
    "# optimal runtime assuming perfect pruning, but not sortedness\n",
    "scans['optimal_runtime'] = scans['time_per_ir'] * scans['pruned_minimum_input_rows']\n",
    "scans['runtime_gain'] = scans['RUNTIME_NS'] - scans['optimal_runtime']\n",
    "\n",
    "\n",
    "# log runtime for sorted columns\n",
    "scans['log_runtime'] = np.log2(scans['RUNTIME_NS'])\n",
    "scans['optimal_log_runtime'] = np.log2(1+scans['optimal_runtime'])\n",
    "scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAIN_COLUMN = 'runtime_gain'\n",
    "\n",
    "scans_groupby_columnname = scans.groupby(['TABLE_NAME', 'COLUMN_NAME'])\n",
    "sum_of_gains = pd.DataFrame(scans_groupby_columnname[GAIN_COLUMN].sum())\n",
    "sum_of_gains.sort_values(by=['TABLE_NAME', GAIN_COLUMN], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_correct_statistics_loaded()\n",
    "\n",
    "if BENCHMARK == \"TPCH\":\n",
    "    TABLE = \"lineitem\"\n",
    "else:    \n",
    "    TABLE = \"customer_demographics\"\n",
    "\n",
    "import itertools\n",
    "\n",
    "def extract_single_table(table_name):\n",
    "    return scans[scans['TABLE_NAME'] == table_name]\n",
    "\n",
    "def extract_interesting_columns(df):\n",
    "    return list(df['COLUMN_NAME'].unique())\n",
    "\n",
    "\n",
    "correlations = {\n",
    "    'l_shipdate': ['l_receiptdate', 'l_commitdate'],\n",
    "    'l_receiptdate': ['l_shipdate', 'l_commitdate'],\n",
    "    'l_commitdate': ['l_receiptdate', 'l_shipdate']\n",
    "}\n",
    "#correlations = {}\n",
    "def table_sorting_options(table_name):\n",
    "    single_table = extract_single_table(table_name)\n",
    "    interesting_cols = extract_interesting_columns(single_table)\n",
    "    pairs = itertools.product(interesting_cols, interesting_cols)\n",
    "    \n",
    "    total_times = []\n",
    "    for pair in pairs:\n",
    "        pruning_col = pair[0]\n",
    "        sorted_col = pair[1]\n",
    "\n",
    "        def compute_runtime(row):\n",
    "            col_name = row['COLUMN_NAME']\n",
    "            if pruning_col == sorted_col:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_log_runtime']\n",
    "                else:\n",
    "                    if col_name in correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "            else:\n",
    "                if col_name == pruning_col:\n",
    "                    return row['optimal_runtime']\n",
    "                elif col_name == sorted_col:\n",
    "                    # TODO: should this be affected by correlation?\n",
    "                    # we will get less chunks, so a linear scan should be close to optimal_runtime,\n",
    "                    # but log time should beat it anyway\n",
    "                    return row['log_runtime']\n",
    "                else:\n",
    "                    if col_name in correlations.get(pruning_col, []):\n",
    "                        # correlated to pruning column -> a lot of pruning, no sortedness\n",
    "                        # TODO: better measure correlation\n",
    "                        return 1.2 * row['optimal_runtime']\n",
    "                    else:\n",
    "                        return row['RUNTIME_NS']\n",
    "\n",
    "        effective_runtime = single_table.apply(compute_runtime, axis=1)\n",
    "        total_times.append([pair, effective_runtime.sum()])    \n",
    "    total_times = pd.DataFrame(total_times, columns=['columns', 'time'])    \n",
    "    return total_times\n",
    "\n",
    "options = table_sorting_options(TABLE)\n",
    "options.sort_values(by=['time'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates = pd.read_csv(f\"{STATISTICS_PATH}/aggregates.csv\", sep=',')\n",
    "\n",
    "# it looks like column names are mixed up.\n",
    "# COLUMN_NAME -> actually GROUP_BY_COLUMN_COUNT\n",
    "# GROUP_BY_COLUMN_COUNT -> actually AGGREGATE_COLUMN_COUNT\n",
    "# AGGREGATE_COLUMN_COUNT -> actually COLUMN_NAME\n",
    "\n",
    "COL_NAME = 'AGGREGATE_COLUMN_COUNT'\n",
    "GROUPBY_COL = 'COLUMN_NAME'\n",
    "AGG_COL = 'GROUP_BY_COLUMN_COUNT'\n",
    "\n",
    "# All aggregates have to read the entire table, so we cannot skip chunks.\n",
    "# But getting all groups consecutive could provide a speedup\n",
    "# As a result, we care only about aggregates with group by columns\n",
    "\n",
    "interesting_aggregates = aggregates[aggregates[GROUPBY_COL] > 0]\n",
    "stats = interesting_aggregates.groupby(['TABLE_NAME', COL_NAME])\n",
    "out_columns = pd.DataFrame(stats['OUTPUT_ROWS'].max())\n",
    "out_columns.sort_values(by=['TABLE_NAME', 'OUTPUT_ROWS'], ascending=[True, False])\n",
    "aggregates[aggregates['COLUMN_TYPE'] == 'DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_time_per_column = scans.groupby(['COLUMN_NAME'])\n",
    "accumulated_scan_times = pd.DataFrame(scan_time_per_column['RUNTIME_NS'].sum())\n",
    "total_scan_runtime = accumulated_scan_times['RUNTIME_NS'].sum()\n",
    "assert total_scan_runtime == scans['RUNTIME_NS'].sum(), f\"{total_scan_runtime}, {scans['RUNTIME_NS'].sum()}\"\n",
    "print(f\"total scan runtime: {total_scan_runtime}\")\n",
    "\n",
    "scan_time_per_column_prunable = scans[scans['useful_for_pruning']].groupby(['COLUMN_NAME'])\n",
    "accumulated_prunable_scan_times = pd.DataFrame(scan_time_per_column_prunable['RUNTIME_NS'].sum())\n",
    "total_prunable_scan_runtime = accumulated_prunable_scan_times['RUNTIME_NS'].sum()\n",
    "print(f\"total prunable scan runtime: {total_prunable_scan_runtime}\")\n",
    "print(f\"{100*total_prunable_scan_runtime/total_scan_runtime}% of scan runtime amount to prunable scans\")\n",
    "\n",
    "accumulated_scan_times.sort_values(['RUNTIME_NS'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "joins = load_join_statistics()\n",
    "\n",
    "print(joins['PROBE_COLUMN'].unique())\n",
    "\n",
    "join_time_per_column = joins.groupby(['PROBE_COLUMN'])\n",
    "\n",
    "accumulated_join_times = pd.DataFrame(join_time_per_column['RUNTIME_NS'].sum())\n",
    "print(len(accumulated_join_times))\n",
    "total_join_runtime = accumulated_join_times['RUNTIME_NS'].sum()\n",
    "#assert total_join_runtime == joins['RUNTIME_NS'].sum(), f\"{total_join_runtime},{joins['RUNTIME_NS'].sum()}\"\n",
    "print(f\"total join runtime: {total_join_runtime}\")\n",
    "\n",
    "joins[joins.apply(lambda x : x['PROBE_COLUMN'] not in ['o_custkey' ,'n_nationkey' ,'s_nationkey' ,'l_suppkey', 's_suppkey',\n",
    " 'l_orderkey', 'o_orderkey', 'p_partkey' ,'l_partkey' ,'ps_suppkey',\n",
    " 'c_nationkey' ,'r_regionkey' ,'c_custkey' ,'ps_partkey'] ,axis=1)]\n",
    "\n",
    "print(f\"for {BENCHMARK}, joins take about {total_join_runtime / total_scan_runtime} times longer than table scans\")\n",
    "accumulated_join_times.sort_values(['RUNTIME_NS'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
